1
00:00:00,960 --> 00:00:08,179
welcome to lesson 13 where we're going

2
00:00:05,639 --> 00:00:12,599
to be talking about image enhancement

3
00:00:08,179 --> 00:00:14,400
and image enhancement we'll cover things

4
00:00:12,599 --> 00:00:17,368
like this painting that you might be

5
00:00:14,400 --> 00:00:19,310
familiar with however you might not have

6
00:00:17,368 --> 00:00:22,019
noticed before that this painting

7
00:00:19,309 --> 00:00:23,759
actually has a picture of an eagle in it

8
00:00:22,019 --> 00:00:25,528
the reason you may not have noticed that

9
00:00:23,760 --> 00:00:28,650
before is this painting actually didn't

10
00:00:25,528 --> 00:00:30,300
used to have an eagle in it by the same

11
00:00:28,649 --> 00:00:31,829
token actually on that first page this

12
00:00:30,300 --> 00:00:34,620
painting did not used to have Captain

13
00:00:31,829 --> 00:00:36,119
America's shield on it either and this

14
00:00:34,619 --> 00:00:37,738
painting did not used to have a clock in

15
00:00:36,119 --> 00:00:40,199
it either

16
00:00:37,738 --> 00:00:42,119
this is a cool new paper actually that

17
00:00:40,200 --> 00:00:44,160
just came out a couple of days ago

18
00:00:42,119 --> 00:00:46,859
called deep painterly harmonization and

19
00:00:44,159 --> 00:00:49,949
it uses almost exactly the technique

20
00:00:46,859 --> 00:00:52,109
we're going to learn in this lesson with

21
00:00:49,950 --> 00:00:55,379
some minor tweaks but you can see the

22
00:00:52,109 --> 00:00:58,259
basic idea is take one picture pasted on

23
00:00:55,378 --> 00:01:01,320
top of another picture and then use some

24
00:00:58,259 --> 00:01:02,909
kind of approach to combine the two and

25
00:01:01,320 --> 00:01:08,819
the basic approach is something called a

26
00:01:02,909 --> 00:01:13,079
style transfer before we talk about that

27
00:01:08,819 --> 00:01:15,679
though I wanted to mention this really

28
00:01:13,079 --> 00:01:18,719
cool contribution by William Horton who

29
00:01:15,680 --> 00:01:20,640
added this stochastic weight averaging

30
00:01:18,719 --> 00:01:24,329
technique to the first library that is

31
00:01:20,640 --> 00:01:25,920
now all merged and ready to go and he's

32
00:01:24,329 --> 00:01:27,390
written a whole post about that which I

33
00:01:25,920 --> 00:01:30,079
strongly recommend you check out not

34
00:01:27,390 --> 00:01:32,609
just because stochastic weight averaging

35
00:01:30,078 --> 00:01:34,849
actually lets you get higher performance

36
00:01:32,609 --> 00:01:37,978
from your existing neural networks with

37
00:01:34,849 --> 00:01:39,959
basically no extra work it's as simple

38
00:01:37,978 --> 00:01:43,019
as adding these two parameters to your

39
00:01:39,959 --> 00:01:45,569
fit function but also he's described his

40
00:01:43,019 --> 00:01:47,188
process of building this and how he

41
00:01:45,569 --> 00:01:49,798
tested it and how it contributed to the

42
00:01:47,188 --> 00:01:51,539
library so I think it's interesting you

43
00:01:49,799 --> 00:01:55,560
know if you're interested in doing

44
00:01:51,540 --> 00:01:57,899
something like this I think William had

45
00:01:55,560 --> 00:02:01,070
not built this kind of library before so

46
00:01:57,899 --> 00:02:05,759
he describes how he did it

47
00:02:01,069 --> 00:02:08,609
another very cool contribution to the

48
00:02:05,759 --> 00:02:12,598
faster a library is a new train phase

49
00:02:08,610 --> 00:02:13,740
API and I'm going to do something I've

50
00:02:12,598 --> 00:02:14,939
never done before which are

51
00:02:13,740 --> 00:02:18,180
actually going to present somebody

52
00:02:14,939 --> 00:02:20,129
else's notebook and the reason I haven't

53
00:02:18,180 --> 00:02:21,930
done it before is because I haven't

54
00:02:20,129 --> 00:02:23,609
liked any notebooks enough to think

55
00:02:21,930 --> 00:02:25,740
they're worth presenting but so has done

56
00:02:23,610 --> 00:02:28,800
a fantastic job here of not just

57
00:02:25,740 --> 00:02:31,230
creating this new API but also creating

58
00:02:28,800 --> 00:02:33,510
a beautiful notebook describing what it

59
00:02:31,229 --> 00:02:37,560
is and how it works and so forth and the

60
00:02:33,509 --> 00:02:41,039
background here is as as you guys know

61
00:02:37,560 --> 00:02:43,319
we've been trying to train networks

62
00:02:41,039 --> 00:02:45,810
faster partly as part of this dawn bench

63
00:02:43,319 --> 00:02:50,930
competition and also for a reason that

64
00:02:45,810 --> 00:02:53,909
you'll learn about next week and I

65
00:02:50,930 --> 00:02:55,500
mentioned on the forums last week it

66
00:02:53,909 --> 00:02:57,799
would be really handy for our

67
00:02:55,500 --> 00:02:59,699
experiments if we had an easier way to

68
00:02:57,800 --> 00:03:01,439
try out different learning rate

69
00:02:59,699 --> 00:03:05,459
schedules and stuff and I basically laid

70
00:03:01,439 --> 00:03:07,460
out an API that I had in mind as it'd be

71
00:03:05,460 --> 00:03:09,719
really cool if somebody could write this

72
00:03:07,460 --> 00:03:12,840
because I'm going to bed now

73
00:03:09,719 --> 00:03:15,569
and I kind of need it by tomorrow and so

74
00:03:12,840 --> 00:03:19,620
when I replied on the forum well that

75
00:03:15,569 --> 00:03:22,319
sounds like a good challenge and by 24

76
00:03:19,620 --> 00:03:24,060
hours later it was done and it's been

77
00:03:22,319 --> 00:03:27,120
super cool I wanna I want to take you

78
00:03:24,060 --> 00:03:30,509
through it because it's it's going to

79
00:03:27,120 --> 00:03:33,330
allow you to do research into things

80
00:03:30,509 --> 00:03:35,370
that nobody's tried before so it's

81
00:03:33,330 --> 00:03:37,290
called the Train phase API and the

82
00:03:35,370 --> 00:03:41,039
easiest way to show it is to show an

83
00:03:37,289 --> 00:03:45,000
example of what it does which is here

84
00:03:41,039 --> 00:03:47,340
here is a iteration against learning

85
00:03:45,000 --> 00:03:50,340
rate chart as you're familiar with

86
00:03:47,340 --> 00:03:52,140
seeing and it this is one where we train

87
00:03:50,340 --> 00:03:54,150
for a while at the learning rate of 0.01

88
00:03:52,139 --> 00:03:56,269
and then we train for a while a learning

89
00:03:54,150 --> 00:03:59,789
rate of 0.001

90
00:03:56,270 --> 00:04:01,320
I actually wanted to create something

91
00:03:59,789 --> 00:04:03,179
very much like that learning rate chart

92
00:04:01,319 --> 00:04:06,900
because most people that trained

93
00:04:03,180 --> 00:04:10,319
imagenet use this stepwise approach and

94
00:04:06,900 --> 00:04:12,780
it's actually not something that's built

95
00:04:10,319 --> 00:04:14,400
into fast AI because it's not generally

96
00:04:12,780 --> 00:04:16,560
something we recommend but in order to

97
00:04:14,400 --> 00:04:18,840
replicate existing papers I wanted to do

98
00:04:16,560 --> 00:04:20,870
it the same way and so rather than

99
00:04:18,839 --> 00:04:23,189
writing a number of fit-- fit-- fit--

100
00:04:20,870 --> 00:04:24,959
calls with different learning rates so

101
00:04:23,189 --> 00:04:27,069
it'd be nice to be able to basically say

102
00:04:24,959 --> 00:04:28,989
train for n

103
00:04:27,069 --> 00:04:31,599
at this learning rate and then M epochs

104
00:04:28,990 --> 00:04:33,759
at that learning rate and so here's how

105
00:04:31,600 --> 00:04:37,120
you do that you can say phases so a

106
00:04:33,759 --> 00:04:39,279
phase is a period of training with you

107
00:04:37,120 --> 00:04:41,350
know particular optimizer parameters and

108
00:04:39,279 --> 00:04:43,809
it consists of a number of training

109
00:04:41,350 --> 00:04:47,200
phase objects a training phase objects

110
00:04:43,810 --> 00:04:51,129
is how many epochs to train for what

111
00:04:47,199 --> 00:04:53,259
optimization function to use and what

112
00:04:51,129 --> 00:04:55,649
learning rate amongst other things that

113
00:04:53,259 --> 00:04:58,480
we'll see and so here you'll see the two

114
00:04:55,649 --> 00:05:01,329
training phases that you just saw on

115
00:04:58,480 --> 00:05:05,860
that graph so now rather than calling

116
00:05:01,329 --> 00:05:09,719
were not fit you say low n dot fit with

117
00:05:05,860 --> 00:05:12,189
an optimizer scheduler with these phases

118
00:05:09,720 --> 00:05:14,620
get op

119
00:05:12,189 --> 00:05:16,629
and then from there most of the things

120
00:05:14,620 --> 00:05:18,579
you pass in can just get sent across to

121
00:05:16,629 --> 00:05:22,569
the fit function as per usual so most of

122
00:05:18,579 --> 00:05:24,789
the usual parameters will work fine but

123
00:05:22,569 --> 00:05:27,009
in this case generally speaking actually

124
00:05:24,790 --> 00:05:28,720
we can just use these training phases

125
00:05:27,009 --> 00:05:31,959
and you'll see it fits in the usual way

126
00:05:28,720 --> 00:05:34,540
and then when you say plot LR there it

127
00:05:31,959 --> 00:05:37,839
is alright and not only does it plot the

128
00:05:34,540 --> 00:05:40,450
learning rate it also plots momentum and

129
00:05:37,839 --> 00:05:43,659
for each phase it tells you what

130
00:05:40,449 --> 00:05:45,430
optimizer it used you can turn off the

131
00:05:43,660 --> 00:05:49,210
printing of the optimizers you can turn

132
00:05:45,430 --> 00:05:50,650
off the printing of momentum x' and you

133
00:05:49,209 --> 00:05:53,560
can do other little things like a

134
00:05:50,649 --> 00:05:56,259
training phase could have an LR decay

135
00:05:53,560 --> 00:05:58,480
parameter so here's a fixed learning

136
00:05:56,259 --> 00:05:59,879
rate and then a linear decay learning

137
00:05:58,480 --> 00:06:04,450
rate and then a fixed learning rate

138
00:05:59,879 --> 00:06:07,959
which gives us that picture and this is

139
00:06:04,449 --> 00:06:09,250
like might be quite a good way to Train

140
00:06:07,959 --> 00:06:12,009
actually because we know at high

141
00:06:09,250 --> 00:06:14,019
learning rates you get to kind of

142
00:06:12,009 --> 00:06:15,550
explore better and they're not low

143
00:06:14,019 --> 00:06:17,439
learning rates you get to fine-tune

144
00:06:15,550 --> 00:06:20,410
better and it's probably better to

145
00:06:17,439 --> 00:06:22,990
gradually slide between the two so you

146
00:06:20,410 --> 00:06:28,090
know this actually isn't a bad approach

147
00:06:22,990 --> 00:06:30,460
I suspect you can use other decay types

148
00:06:28,089 --> 00:06:33,279
not as linear so cosine this probably

149
00:06:30,459 --> 00:06:36,039
makes even more sense as a genuinely

150
00:06:33,279 --> 00:06:40,389
potentially useful and learning rate an

151
00:06:36,040 --> 00:06:40,960
ailing shape exponential which is super

152
00:06:40,389 --> 00:06:44,800
popular

153
00:06:40,959 --> 00:06:46,978
approach polynomial which isn't terribly

154
00:06:44,800 --> 00:06:49,240
popular but actually in the literature

155
00:06:46,978 --> 00:06:50,859
works better than just about anything

156
00:06:49,240 --> 00:06:53,918
else but seems to have been largely

157
00:06:50,860 --> 00:06:55,629
ignored so polynomials could to be aware

158
00:06:53,918 --> 00:06:57,418
of and what surveillance done is he's

159
00:06:55,629 --> 00:07:01,240
given us the formula for each of these

160
00:06:57,418 --> 00:07:11,019
curves and so with a polynomial you get

161
00:07:01,240 --> 00:07:15,759
to pick what polynomial to use so here

162
00:07:11,019 --> 00:07:19,629
it is with a different size and I

163
00:07:15,759 --> 00:07:27,340
believe a P of 0.9 is the one that I've

164
00:07:19,629 --> 00:07:29,288
seen really good results for fYI if you

165
00:07:27,339 --> 00:07:31,719
don't give a couple of learning rates

166
00:07:29,288 --> 00:07:34,389
when there's an LR decay then it will

167
00:07:31,720 --> 00:07:39,310
decay all the way down to zero right and

168
00:07:34,389 --> 00:07:44,500
as you can see you can happily start the

169
00:07:39,310 --> 00:07:47,560
next cycle at a different point so the

170
00:07:44,500 --> 00:07:49,839
cool thing is now we can replicate all

171
00:07:47,560 --> 00:07:52,538
of our existing schedules using nothing

172
00:07:49,839 --> 00:07:55,269
but these training phases so here's a

173
00:07:52,538 --> 00:07:59,259
function called phases s JDR which does

174
00:07:55,269 --> 00:08:01,769
SJD are using the new training phase api

175
00:07:59,259 --> 00:08:04,870
and so you can see if he runs this

176
00:08:01,769 --> 00:08:06,788
schedule and here's what it looks like

177
00:08:04,870 --> 00:08:07,750
but he's even done the little trick I

178
00:08:06,788 --> 00:08:09,279
have where you're training a little

179
00:08:07,750 --> 00:08:10,779
really low learning rate just for a

180
00:08:09,279 --> 00:08:12,579
little bit and then pop up and do a few

181
00:08:10,779 --> 00:08:17,519
cycles and the cycles are increasing in

182
00:08:12,579 --> 00:08:22,478
length and that's all done in a single

183
00:08:17,519 --> 00:08:26,069
in a single function so the new one

184
00:08:22,478 --> 00:08:29,199
cycle we can now implement with again a

185
00:08:26,069 --> 00:08:33,000
single little function alright and so if

186
00:08:29,199 --> 00:08:34,839
we run if we fit with that we get this

187
00:08:33,000 --> 00:08:37,179
triangle all followed by a little

188
00:08:34,839 --> 00:08:44,160
flatter bit and the momentum is a cool

189
00:08:37,179 --> 00:08:47,528
thing the momentum has a momentum decay

190
00:08:44,159 --> 00:08:49,689
right and then here we've got a fixed

191
00:08:47,528 --> 00:08:51,159
momentum at the end so it's doing the

192
00:08:49,690 --> 00:08:53,490
momentum and the learning rate at the

193
00:08:51,159 --> 00:08:53,490
same time

194
00:08:53,860 --> 00:08:58,209
so something that I haven't tried yet

195
00:08:55,720 --> 00:09:01,629
but I think would be really interesting

196
00:08:58,208 --> 00:09:02,829
is to use he's calling a differential

197
00:09:01,629 --> 00:09:05,289
learning rates we've changed the name

198
00:09:02,830 --> 00:09:11,879
now to discriminative learning rates to

199
00:09:05,289 --> 00:09:16,269
use oops yes what fix it just scream

200
00:09:11,879 --> 00:09:17,828
inactive learning race so a combination

201
00:09:16,269 --> 00:09:20,620
of discriminative learning rates and one

202
00:09:17,828 --> 00:09:22,500
cycle no one's tried yet

203
00:09:20,620 --> 00:09:26,019
so that would be really interesting

204
00:09:22,500 --> 00:09:27,759
there's actually a the only paper I've

205
00:09:26,019 --> 00:09:29,709
come across which has discriminative

206
00:09:27,759 --> 00:09:33,789
learning rates is called uses something

207
00:09:29,708 --> 00:09:36,909
called Lars lar s and it was used to

208
00:09:33,789 --> 00:09:40,000
Train imagenet with very very large

209
00:09:36,909 --> 00:09:43,559
batch sizes by basically looking at the

210
00:09:40,000 --> 00:09:49,839
ratio between the gradient and the mean

211
00:09:43,559 --> 00:09:51,039
at H layer and using that to change the

212
00:09:49,839 --> 00:09:52,930
learning rate of each layer

213
00:09:51,039 --> 00:09:55,899
automatically and they found that they

214
00:09:52,929 --> 00:09:57,278
could use much larger batch sizes that's

215
00:09:55,899 --> 00:09:59,320
the only other place I've seen this kind

216
00:09:57,278 --> 00:10:00,899
of approach used but there's lots of

217
00:09:59,320 --> 00:10:03,040
interesting things you could try with

218
00:10:00,899 --> 00:10:06,759
combining discriminative learning rates

219
00:10:03,039 --> 00:10:09,189
and different interesting schedules so

220
00:10:06,759 --> 00:10:11,350
you can now write your own LR finder of

221
00:10:09,190 --> 00:10:13,180
different types specifically because

222
00:10:11,350 --> 00:10:16,060
there's now this stop div parameter

223
00:10:13,179 --> 00:10:18,189
which basically means that it'll you

224
00:10:16,059 --> 00:10:20,229
know use whatever schedule you asked for

225
00:10:18,190 --> 00:10:27,270
but when the loss gets too bad at all

226
00:10:20,230 --> 00:10:29,709
stop training so here's one with no

227
00:10:27,269 --> 00:10:37,659
learning rate versus loss and you can

228
00:10:29,708 --> 00:10:40,328
see it stops itself automatically one

229
00:10:37,659 --> 00:10:44,469
useful thing that's been added is the

230
00:10:40,328 --> 00:10:48,639
linear parameter to the plot function if

231
00:10:44,470 --> 00:10:50,050
you use linear schedule rather than an

232
00:10:48,639 --> 00:10:52,569
exponential schedule and your learning

233
00:10:50,049 --> 00:10:55,149
rate finder which is a good idea if

234
00:10:52,570 --> 00:10:57,040
you've kind of fine-tuned into roughly

235
00:10:55,149 --> 00:10:59,230
the right area then you can use linear

236
00:10:57,039 --> 00:11:00,639
to find exactly the right area and then

237
00:10:59,230 --> 00:11:02,740
you probably want to plot it with a

238
00:11:00,639 --> 00:11:06,500
linear scale so that's why you can also

239
00:11:02,740 --> 00:11:11,750
pass linear to plot now as well

240
00:11:06,500 --> 00:11:14,730
you can change the optimizer HBase and

241
00:11:11,750 --> 00:11:17,190
that's more important than you might

242
00:11:14,730 --> 00:11:20,789
imagine because actually the current

243
00:11:17,190 --> 00:11:22,949
state-of-the-art for training on really

244
00:11:20,789 --> 00:11:25,129
large batch sizes really quickly for

245
00:11:22,948 --> 00:11:27,419
imagenet actually starts with rmsprop

246
00:11:25,129 --> 00:11:32,129
for the first bit and then they switch

247
00:11:27,419 --> 00:11:33,448
to SGD for the second vid and so that

248
00:11:32,129 --> 00:11:36,958
could be something interesting to

249
00:11:33,448 --> 00:11:39,568
experiment more with is like because at

250
00:11:36,958 --> 00:11:42,239
least one paper has now shown that that

251
00:11:39,568 --> 00:11:49,469
can work well and again it's something

252
00:11:42,240 --> 00:11:51,930
that isn't well appreciated as yet and

253
00:11:49,470 --> 00:11:54,360
then the bit I find most interesting is

254
00:11:51,929 --> 00:11:56,309
you can change your data and why would

255
00:11:54,360 --> 00:11:58,139
we want to change our data because you

256
00:11:56,309 --> 00:12:00,419
remember from lessons 1 and 2 you could

257
00:11:58,139 --> 00:12:05,240
use small images at the start and later

258
00:12:00,419 --> 00:12:05,240
bigger images later and the theory is

259
00:12:06,110 --> 00:12:13,289
the theory is that you could use that to

260
00:12:10,759 --> 00:12:15,688
kind of train the first bit more quickly

261
00:12:13,289 --> 00:12:17,099
with smaller images and remember if you

262
00:12:15,688 --> 00:12:19,909
like have half the height and half the

263
00:12:17,100 --> 00:12:22,829
width and you've got a quarter of the

264
00:12:19,909 --> 00:12:25,110
activations basically every layer so it

265
00:12:22,828 --> 00:12:29,489
can be a lot faster and it might even

266
00:12:25,110 --> 00:12:31,740
generalize better so you can now create

267
00:12:29,490 --> 00:12:33,720
a couple of different for example it's

268
00:12:31,740 --> 00:12:35,818
because he's got 28 and then 32 sized

269
00:12:33,720 --> 00:12:38,040
images this is just so far 10 so there's

270
00:12:35,818 --> 00:12:40,979
only so much you can do and then if you

271
00:12:38,039 --> 00:12:42,750
pass in an array of data in this data

272
00:12:40,980 --> 00:12:45,420
list parameter when you call fit pop

273
00:12:42,750 --> 00:12:49,740
shared it'll use a different data set

274
00:12:45,419 --> 00:12:51,990
for each face so that's really cool

275
00:12:49,740 --> 00:12:53,610
because we can use that now like we

276
00:12:51,990 --> 00:12:55,230
could use that in our dorm bench entries

277
00:12:53,610 --> 00:13:00,289
and see what happens when we actually

278
00:12:55,230 --> 00:13:00,289
increase the size with very little code

279
00:13:02,649 --> 00:13:11,240
so what happens when we do that well the

280
00:13:07,490 --> 00:13:14,779
answer is here in Dorn bench training on

281
00:13:11,240 --> 00:13:19,159
imagenet and you can see here that

282
00:13:14,779 --> 00:13:24,949
Google is one this with half an hour on

283
00:13:19,159 --> 00:13:29,350
a cluster of TP use the best non cluster

284
00:13:24,950 --> 00:13:31,629
of TPU result is fast AI plus students

285
00:13:29,350 --> 00:13:37,100
under three hours

286
00:13:31,629 --> 00:13:41,840
beating out Intel on 128 computers where

287
00:13:37,100 --> 00:13:48,080
else we ran on a single computer we also

288
00:13:41,840 --> 00:13:51,590
beat Google running on a TPU so using

289
00:13:48,080 --> 00:13:54,410
this approach we've shown the fastest

290
00:13:51,590 --> 00:13:58,399
GPU result the fastest single machine

291
00:13:54,409 --> 00:14:00,500
result the fastest publicly available

292
00:13:58,399 --> 00:14:04,610
infrastructure result these TPU pods you

293
00:14:00,500 --> 00:14:08,000
can't use unless your Google and the

294
00:14:04,610 --> 00:14:10,159
cost is tiny like this Intel one cost

295
00:14:08,000 --> 00:14:12,200
them $1,200 worth of compute they

296
00:14:10,159 --> 00:14:14,000
haven't even written it here but that's

297
00:14:12,200 --> 00:14:19,070
what you get a few user sorry 128

298
00:14:14,000 --> 00:14:21,529
computers in parallel each one with 36

299
00:14:19,070 --> 00:14:29,390
cause each one with 140 gig compared to

300
00:14:21,529 --> 00:14:33,740
our single AWS instance so this is you

301
00:14:29,389 --> 00:14:35,240
know a kind of a breakthrough in in what

302
00:14:33,740 --> 00:14:37,879
we can do like the idea that we can

303
00:14:35,240 --> 00:14:40,399
train imagenet on a single publicly

304
00:14:37,879 --> 00:14:43,730
available machine and this $72 by the

305
00:14:40,399 --> 00:14:45,949
way it was actually $25 because we used

306
00:14:43,730 --> 00:14:47,870
a spot instance so one of our students

307
00:14:45,950 --> 00:14:49,850
Andrew Shaw built this whole system to

308
00:14:47,870 --> 00:14:51,320
allow us to throw a whole bunch of spod

309
00:14:49,850 --> 00:14:53,750
instance experiments up and run them

310
00:14:51,320 --> 00:14:56,710
simultaneously and pretty much

311
00:14:53,750 --> 00:14:59,629
automatically but dawn binge doesn't

312
00:14:56,710 --> 00:15:04,750
quote the actual number we used so it's

313
00:14:59,629 --> 00:15:11,059
actually 25 bucks not 72 bucks so this

314
00:15:04,750 --> 00:15:17,509
data list idea is super important and

315
00:15:11,059 --> 00:15:22,009
helpful and so our sci-fi 10 results

316
00:15:17,509 --> 00:15:23,509
also now up there officially and you

317
00:15:22,009 --> 00:15:26,480
might remember the previous best was a

318
00:15:23,509 --> 00:15:28,700
bit over an hour and the trick here was

319
00:15:26,480 --> 00:15:30,560
using one cycle basically so all this

320
00:15:28,700 --> 00:15:33,020
stuff that's in silver has training

321
00:15:30,559 --> 00:15:34,819
phase API is really all the stuff that

322
00:15:33,019 --> 00:15:38,240
we used to get these top results and

323
00:15:34,820 --> 00:15:42,350
really cool another fast AI student who

324
00:15:38,240 --> 00:15:47,779
goes by the name here bkj has has taken

325
00:15:42,350 --> 00:15:50,210
that and done his own version he took a

326
00:15:47,779 --> 00:15:51,620
resonant 18 and added the concat polling

327
00:15:50,210 --> 00:15:55,009
that you might remember that we learnt

328
00:15:51,620 --> 00:15:58,789
about on top and used leslie cycles once

329
00:15:55,009 --> 00:16:00,549
leslie smith's one cycle and so he's got

330
00:15:58,789 --> 00:16:04,039
on the leaderboard so all the top three

331
00:16:00,549 --> 00:16:07,459
first day i students which is wonderful

332
00:16:04,039 --> 00:16:12,529
and same for cost the top three

333
00:16:07,460 --> 00:16:15,350
and you can see paper space so brett ran

334
00:16:12,529 --> 00:16:21,289
this on paper space and got the the

335
00:16:15,350 --> 00:16:28,879
cheapest result just ahead of dkj

336
00:16:21,289 --> 00:16:30,319
been his name is i believe okay so so i

337
00:16:28,879 --> 00:16:32,750
think you can see like a lot of the kind

338
00:16:30,320 --> 00:16:34,760
of interesting opportunities at the

339
00:16:32,750 --> 00:16:36,350
moment for the training stuff more

340
00:16:34,759 --> 00:16:38,240
quickly and cheaply you're all about

341
00:16:36,350 --> 00:16:41,149
kind of the learning rate annealing and

342
00:16:38,240 --> 00:16:42,649
size annealing and like training with

343
00:16:41,149 --> 00:16:44,179
different parameters at different times

344
00:16:42,649 --> 00:16:45,590
and I still think we buddies scratching

345
00:16:44,179 --> 00:16:48,679
the surface I think we can go a lot

346
00:16:45,590 --> 00:16:50,420
faster and a lot cheaper and that's

347
00:16:48,679 --> 00:16:52,159
really helpful for people you know in

348
00:16:50,419 --> 00:16:55,329
resource constrained environments which

349
00:16:52,159 --> 00:17:03,079
is basically everybody except Google

350
00:16:55,330 --> 00:17:05,000
maybe Facebook architectures interesting

351
00:17:03,080 --> 00:17:06,380
as well though and one of the things we

352
00:17:05,000 --> 00:17:08,420
looked at last week was just like

353
00:17:06,380 --> 00:17:10,220
creating a simpler architecture which is

354
00:17:08,420 --> 00:17:12,589
basically state of the art you know like

355
00:17:10,220 --> 00:17:16,220
the really basic kind of dark net

356
00:17:12,588 --> 00:17:19,089
architecture but there's a piece of

357
00:17:16,220 --> 00:17:22,039
architecture we we haven't talked about

358
00:17:19,089 --> 00:17:23,389
which is necessary to understand the

359
00:17:22,039 --> 00:17:24,950
inception network

360
00:17:23,390 --> 00:17:27,800
the inception network is actually pretty

361
00:17:24,950 --> 00:17:32,059
interesting because they use some tricks

362
00:17:27,799 --> 00:17:34,039
to to actually make things more

363
00:17:32,059 --> 00:17:35,569
efficient and we're not currently using

364
00:17:34,039 --> 00:17:38,720
these tricks and I kind of feel that

365
00:17:35,569 --> 00:17:41,119
maybe we should try it and so this is

366
00:17:38,720 --> 00:17:42,710
the the most interesting most successful

367
00:17:41,119 --> 00:17:45,500
inception network is their inception

368
00:17:42,710 --> 00:17:47,210
resident to network and most of the

369
00:17:45,500 --> 00:17:49,730
blocks in that looks something like this

370
00:17:47,210 --> 00:17:51,529
and it looks a lot like a standard

371
00:17:49,730 --> 00:17:54,079
ResNet block in that there's an identity

372
00:17:51,529 --> 00:18:25,430
connection here and then there's a conv

373
00:17:54,079 --> 00:18:28,189
confirmation is so a one by one conf is

374
00:18:25,430 --> 00:18:32,210
simply saying for each grid cell in your

375
00:18:28,190 --> 00:18:35,440
input you've got a basically it's a

376
00:18:32,210 --> 00:18:38,180
vector write a 1x1 by number of filters

377
00:18:35,440 --> 00:18:41,360
tensor is basically a vector right so

378
00:18:38,180 --> 00:18:43,789
for each grid cell in your input you're

379
00:18:41,359 --> 00:18:46,159
just doing a dot product with that

380
00:18:43,789 --> 00:18:49,190
tensor right and then of course it's

381
00:18:46,160 --> 00:18:50,360
going to be one of those vectors for

382
00:18:49,190 --> 00:18:52,100
each of the hundred and ninety two

383
00:18:50,359 --> 00:18:55,099
activations we're creating soon

384
00:18:52,099 --> 00:18:58,459
basically do 192 dot products with grid

385
00:18:55,099 --> 00:19:00,949
cell 1 1 and then 192 with good 0 1 2 or

386
00:18:58,460 --> 00:19:02,680
1 3 and so forth and so you'll end up

387
00:19:00,950 --> 00:19:07,009
with something which has got the same

388
00:19:02,680 --> 00:19:10,730
grid size as the input and 192 channels

389
00:19:07,009 --> 00:19:14,029
in the output so that's a really good

390
00:19:10,730 --> 00:19:15,559
way to you know either reduce the

391
00:19:14,029 --> 00:19:18,410
dimensionality or increase the

392
00:19:15,559 --> 00:19:20,690
dimensionality of an input without

393
00:19:18,410 --> 00:19:25,580
changing the grid size that's normally

394
00:19:20,690 --> 00:19:27,380
what we use 1x1 cons for so here we've

395
00:19:25,579 --> 00:19:28,970
got a 1x1 conf and then we've got

396
00:19:27,380 --> 00:19:31,700
another one-by-one conf and then they

397
00:19:28,970 --> 00:19:35,600
add it together and then there's a third

398
00:19:31,700 --> 00:19:37,250
path and this third path is not added

399
00:19:35,599 --> 00:19:38,869
this third path it's not actually

400
00:19:37,250 --> 00:19:41,990
explicitly mentioned but it's

401
00:19:38,869 --> 00:19:45,349
concatenated right and so actually there

402
00:19:41,990 --> 00:19:47,000
is a form of ResNet which is basically

403
00:19:45,349 --> 00:19:50,089
identical to resonate but we don't do

404
00:19:47,000 --> 00:19:52,279
plus we do concat right and that's

405
00:19:50,089 --> 00:19:55,069
called a dense net alright so it's just

406
00:19:52,279 --> 00:19:59,149
a resonate where we do concat instead of

407
00:19:55,069 --> 00:20:02,450
plus and that's an interesting approach

408
00:19:59,150 --> 00:20:05,809
because then the kind of the identity

409
00:20:02,450 --> 00:20:08,390
path is literally being copied right so

410
00:20:05,808 --> 00:20:10,819
you kind of get that that that flow

411
00:20:08,390 --> 00:20:12,259
through all the way through and so as

412
00:20:10,819 --> 00:20:14,990
we'll see next week that tends to be

413
00:20:12,259 --> 00:20:16,548
good for like segmentation and stuff

414
00:20:14,990 --> 00:20:18,380
like that where you really want to kind

415
00:20:16,548 --> 00:20:19,639
of keep the original pixels and the

416
00:20:18,380 --> 00:20:24,940
first layer of pixels and the second

417
00:20:19,640 --> 00:20:28,730
layer of pixels and touched so

418
00:20:24,940 --> 00:20:31,490
concatenate another than adding branches

419
00:20:28,730 --> 00:20:32,990
is is a very useful thing to do and so

420
00:20:31,490 --> 00:20:35,450
here we're concatenate in this branch

421
00:20:32,990 --> 00:20:37,190
and this this branch is doing something

422
00:20:35,450 --> 00:20:40,130
interesting which is it's doing first of

423
00:20:37,190 --> 00:20:45,019
all the 1x1 con and then a 1 by 7 and

424
00:20:40,130 --> 00:20:47,780
then a seven by one so what's going on

425
00:20:45,019 --> 00:20:51,500
there so what's going on there is

426
00:20:47,779 --> 00:20:54,649
basically what we really want to do is

427
00:20:51,500 --> 00:20:56,720
do a seven by seven conch the reason we

428
00:20:54,650 --> 00:20:59,210
want to do a seven by seven con is that

429
00:20:56,720 --> 00:21:03,319
if you've got multiple paths each of

430
00:20:59,210 --> 00:21:04,970
which has different kernel sizes then

431
00:21:03,319 --> 00:21:07,519
it's able to look at you know different

432
00:21:04,970 --> 00:21:09,558
amounts of the image and so like the

433
00:21:07,519 --> 00:21:12,829
original inception network had like a

434
00:21:09,558 --> 00:21:14,119
1x1 or 3x3 a 5x5 seven by seven kind of

435
00:21:12,829 --> 00:21:18,259
getting concatenated in together

436
00:21:14,119 --> 00:21:20,449
something like that and so if we can

437
00:21:18,259 --> 00:21:22,519
have a seven by seven filter then we get

438
00:21:20,450 --> 00:21:23,690
to kind of look at a lot of the image at

439
00:21:22,519 --> 00:21:28,308
once and create a really rich

440
00:21:23,690 --> 00:21:30,830
representation and so actually the stem

441
00:21:28,308 --> 00:21:33,440
of the inception network that is the the

442
00:21:30,829 --> 00:21:36,259
first few layers of the inception

443
00:21:33,440 --> 00:21:39,830
network actually also used you know this

444
00:21:36,259 --> 00:21:42,288
kind of seven by seven cond because you

445
00:21:39,829 --> 00:21:44,899
start out with this 224 by 224 by three

446
00:21:42,288 --> 00:21:48,930
and you want to turn it into something

447
00:21:44,900 --> 00:21:52,200
that's like 112 by 112 by 64

448
00:21:48,930 --> 00:21:54,269
so by using a 7x7 Conniff you can get a

449
00:21:52,200 --> 00:21:58,710
lot of information in each one of those

450
00:21:54,269 --> 00:22:03,960
outputs to get those 64 filters but the

451
00:21:58,710 --> 00:22:09,630
problem is that 7x7 conv is a lot of

452
00:22:03,960 --> 00:22:13,470
work you've got 49 kernel values 2 x 49

453
00:22:09,630 --> 00:22:18,420
inputs for every input pixel across

454
00:22:13,470 --> 00:22:20,730
every channel so the compute is crazy

455
00:22:18,420 --> 00:22:22,920
you know you can kind of get away with

456
00:22:20,730 --> 00:22:25,289
it maybe for the very first layer and in

457
00:22:22,920 --> 00:22:30,320
fact the very first layer the very first

458
00:22:25,289 --> 00:22:33,389
con was reza net is a seven by seven con

459
00:22:30,319 --> 00:22:35,099
but i'm not so for inception for

460
00:22:33,390 --> 00:22:39,930
inception they don't do a seven by seven

461
00:22:35,099 --> 00:22:42,839
comma instead they do a one by seven

462
00:22:39,930 --> 00:22:45,810
followed by a seven by one and so to

463
00:22:42,839 --> 00:22:48,029
explain the basic idea of the inception

464
00:22:45,809 --> 00:22:50,849
networks or all the different versions

465
00:22:48,029 --> 00:22:54,240
of it that you have a number of separate

466
00:22:50,849 --> 00:22:56,399
paths which have different convolution

467
00:22:54,240 --> 00:22:58,589
widths in this case conceptually the

468
00:22:56,400 --> 00:23:00,860
idea is this is a one-by-one convolution

469
00:22:58,589 --> 00:23:03,089
with and this is going to be a seven

470
00:23:00,859 --> 00:23:04,949
convolution with and so they're looking

471
00:23:03,089 --> 00:23:11,220
at different amounts of data and then we

472
00:23:04,950 --> 00:23:13,880
combine them together but we we don't

473
00:23:11,220 --> 00:23:16,079
want to have a seven by seven plunge

474
00:23:13,880 --> 00:23:19,710
throughout the network because it's just

475
00:23:16,079 --> 00:23:22,649
too computationally expensive but if you

476
00:23:19,710 --> 00:23:27,900
think about it if we've got some input

477
00:23:22,650 --> 00:23:30,360
coming in right and we have some big

478
00:23:27,900 --> 00:23:32,670
filter that we want and it's it's too

479
00:23:30,359 --> 00:23:35,009
big to deal with and what could we do

480
00:23:32,670 --> 00:23:36,180
right so let's say let's just to make it

481
00:23:35,009 --> 00:23:41,029
a little bit less drawing that's two

482
00:23:36,180 --> 00:23:41,029
five by five what we can do

483
00:23:44,240 --> 00:23:52,549
is to create two filters one which is 1

484
00:23:47,569 --> 00:23:58,639
by 5 1 which is 5 by 1 or 7 or whatever

485
00:23:52,549 --> 00:24:01,669
on line so we take our activations the

486
00:23:58,640 --> 00:24:04,190
previous layer and we put it through the

487
00:24:01,670 --> 00:24:08,080
1 by 5 we take the activations out of

488
00:24:04,190 --> 00:24:09,980
that and put it through the 5 by 1 and

489
00:24:08,079 --> 00:24:13,009
something comes out the other end now

490
00:24:09,980 --> 00:24:16,370
what comes out the other end well rather

491
00:24:13,009 --> 00:24:18,740
than thinking of it as first of all we

492
00:24:16,369 --> 00:24:20,419
take the activations then we put it

493
00:24:18,740 --> 00:24:21,799
through the 5 by 1 then we put it

494
00:24:20,420 --> 00:24:25,250
through the 5 but then we put it through

495
00:24:21,799 --> 00:24:29,720
the 1 by 5 1 by 5 then the 5 by 1 what

496
00:24:25,250 --> 00:24:33,769
if instead we think of these 2

497
00:24:29,720 --> 00:24:37,490
operations together and say what is a 5

498
00:24:33,769 --> 00:24:40,569
by 1 dot production of one by five dot

499
00:24:37,490 --> 00:24:44,660
product do together right and

500
00:24:40,569 --> 00:24:47,178
effectively right you could take a 1 by

501
00:24:44,660 --> 00:24:55,940
5 and a 5 by 1 and the outer product of

502
00:24:47,179 --> 00:24:58,910
that is going to give you a 5 by 5 right

503
00:24:55,940 --> 00:25:02,420
now that you can't create any possible 5

504
00:24:58,910 --> 00:25:05,540
by 5 matrix by taking that product right

505
00:25:02,420 --> 00:25:08,240
but there's a lot of 5 by 5 matrices

506
00:25:05,539 --> 00:25:10,129
that you can create and so the basic

507
00:25:08,240 --> 00:25:12,140
idea here is you know when you think

508
00:25:10,130 --> 00:25:13,670
about the order of operations and I'm

509
00:25:12,140 --> 00:25:16,309
going to go into the detail of this if

510
00:25:13,670 --> 00:25:17,690
you're interested in more of the theory

511
00:25:16,308 --> 00:25:19,928
here you should check out Rachel's

512
00:25:17,690 --> 00:25:23,090
numerical linear algebra course which is

513
00:25:19,929 --> 00:25:28,269
basically a whole course about this

514
00:25:23,089 --> 00:25:32,119
stuff but conceptually the idea is that

515
00:25:28,269 --> 00:25:35,000
very often the the computation you want

516
00:25:32,119 --> 00:25:40,369
to do is actually more simple than an

517
00:25:35,000 --> 00:25:42,558
entire 5x5 convolution very often that

518
00:25:40,369 --> 00:25:44,619
the term we use in linear algebra is

519
00:25:42,558 --> 00:25:47,240
that there's some lower rank

520
00:25:44,619 --> 00:25:49,399
approximation in other words that the 1

521
00:25:47,240 --> 00:25:53,210
by 5 and the 5 by 1 combined together

522
00:25:49,400 --> 00:25:55,910
that 5 by 5 matrix is nearly as good as

523
00:25:53,210 --> 00:25:57,778
the 5 by 5 matrix you really ideally

524
00:25:55,910 --> 00:26:00,808
would have computed

525
00:25:57,778 --> 00:26:04,648
if you were able to and so this is very

526
00:26:00,808 --> 00:26:06,839
often the case in practice right just

527
00:26:04,648 --> 00:26:09,329
because the nature of kind of the real

528
00:26:06,839 --> 00:26:11,959
world is that the real world tends not

529
00:26:09,329 --> 00:26:15,178
to be is you know it tends to have more

530
00:26:11,960 --> 00:26:18,960
structure you know than kind of

531
00:26:15,179 --> 00:26:24,830
randomness so the cool thing is if we

532
00:26:18,960 --> 00:26:28,619
replace our seven by if we replace our

533
00:26:24,829 --> 00:26:32,579
seven by seven conf where the one by

534
00:26:28,618 --> 00:26:39,648
seven and a seven by one right then this

535
00:26:32,579 --> 00:26:43,019
has basically for each cell it's got 14

536
00:26:39,648 --> 00:26:47,418
by input channel by output Channel dot

537
00:26:43,019 --> 00:26:50,429
products to do whereas this one has 49

538
00:26:47,419 --> 00:26:52,889
to do okay so it's just going to be a

539
00:26:50,429 --> 00:26:55,169
lot faster and we have to hope that it's

540
00:26:52,888 --> 00:26:57,748
going to be nearly as good it's

541
00:26:55,169 --> 00:27:01,259
certainly capturing as much widths of

542
00:26:57,749 --> 00:27:02,249
information by definition so if you're

543
00:27:01,259 --> 00:27:04,108
in student learning more about this

544
00:27:02,249 --> 00:27:07,739
specifically in a deep learning area you

545
00:27:04,108 --> 00:27:10,108
can google for factored convolutions the

546
00:27:07,739 --> 00:27:12,838
idea was come up with three or four

547
00:27:10,108 --> 00:27:14,249
years ago now it's probably been around

548
00:27:12,838 --> 00:27:16,739
for long river that was when I first saw

549
00:27:14,249 --> 00:27:18,858
it and yeah it turned out to work really

550
00:27:16,739 --> 00:27:23,909
well and the inception network uses it

551
00:27:18,858 --> 00:27:27,088
quite widely they actually use it in

552
00:27:23,909 --> 00:27:29,099
their in their stem it's it's

553
00:27:27,088 --> 00:27:33,749
interesting actually we've talked before

554
00:27:29,098 --> 00:27:35,218
about how we tend to kind of add-on we

555
00:27:33,749 --> 00:27:37,558
tend to say like this it's main like

556
00:27:35,219 --> 00:27:39,629
backbone you know like when we have

557
00:27:37,558 --> 00:27:41,700
ResNet 34 for example we kind of say oh

558
00:27:39,628 --> 00:27:43,978
this is main backbone which is all of

559
00:27:41,700 --> 00:27:45,838
the convolutions and then we've talked

560
00:27:43,979 --> 00:27:48,778
about how we can add on to it a custom

561
00:27:45,838 --> 00:27:50,729
head right and that tends to be like a

562
00:27:48,778 --> 00:27:55,528
mac spalling layer and a fully connected

563
00:27:50,729 --> 00:27:57,359
layers and whether the you know it's

564
00:27:55,528 --> 00:28:00,538
actually kind of better to talk about

565
00:27:57,358 --> 00:28:07,710
the the backbone is containing kind of

566
00:28:00,538 --> 00:28:09,929
two pieces one is the stem and then the

567
00:28:07,710 --> 00:28:12,389
other is kind of the main backbone

568
00:28:09,929 --> 00:28:15,720
and the reason is that the thing that's

569
00:28:12,388 --> 00:28:19,678
coming in remember it's only got three

570
00:28:15,720 --> 00:28:21,629
channels and so we want some sequence of

571
00:28:19,679 --> 00:28:23,100
operations it's going to expand that out

572
00:28:21,628 --> 00:28:25,349
into something richer generally

573
00:28:23,099 --> 00:28:28,829
something like 64 channels and so in

574
00:28:25,349 --> 00:28:31,918
ResNet the stem is just super simple

575
00:28:28,829 --> 00:28:36,058
it's a seven by seven cons straight to

576
00:28:31,919 --> 00:28:38,460
one followed by a Strad to Emax port

577
00:28:36,058 --> 00:28:41,308
yeah I think that's it if memory serves

578
00:28:38,460 --> 00:28:44,340
correctly an inception they have a much

579
00:28:41,308 --> 00:28:45,990
more complex stem with multiple paths

580
00:28:44,339 --> 00:28:48,449
getting combined and cabin aided

581
00:28:45,990 --> 00:28:52,409
including factoid comms as one by seven

582
00:28:48,450 --> 00:28:56,940
and seven by one and now I'm kind of

583
00:28:52,409 --> 00:28:59,970
interested in what would happen if you

584
00:28:56,940 --> 00:29:01,740
stopped like a resident standard

585
00:28:59,970 --> 00:29:04,528
resonate on top of an inception instead

586
00:29:01,740 --> 00:29:06,388
for instance like I think that would be

587
00:29:04,528 --> 00:29:09,720
a really interesting thing to try

588
00:29:06,388 --> 00:29:11,428
because like an inception stem is kind

589
00:29:09,720 --> 00:29:13,079
of quite a carefully engineered thing

590
00:29:11,429 --> 00:29:14,788
and this thing of like how do you take

591
00:29:13,079 --> 00:29:16,109
your three channel input and turn it

592
00:29:14,788 --> 00:29:19,499
into something richer seems really

593
00:29:16,109 --> 00:29:22,678
important and all of that work seems to

594
00:29:19,499 --> 00:29:24,629
have got thrown away for ResNet we like

595
00:29:22,679 --> 00:29:26,940
ResNet it works really well but what if

596
00:29:24,628 --> 00:29:28,589
we put you know or a dent in it what if

597
00:29:26,940 --> 00:29:33,119
we put the dense net backbone on top of

598
00:29:28,589 --> 00:29:36,480
an inception stem or what if we replaced

599
00:29:33,118 --> 00:29:38,730
the seven by seven cons with a 1 by 7

600
00:29:36,480 --> 00:29:39,960
and 7 by 1 factored conf you know

601
00:29:38,730 --> 00:29:41,849
standard business I don't know there's

602
00:29:39,960 --> 00:29:44,340
lots of things we could try and I think

603
00:29:41,849 --> 00:29:46,219
it'd be really interesting so there's

604
00:29:44,339 --> 00:29:54,628
some more thoughts about potential

605
00:29:46,220 --> 00:29:56,669
research directions ok so that was kind

606
00:29:54,628 --> 00:30:01,589
of my little bunch of random stuff

607
00:29:56,669 --> 00:30:05,179
section moving a little bit closer to

608
00:30:01,589 --> 00:30:05,178
the actual main topic of this which is

609
00:30:06,378 --> 00:30:10,849
what I used image enhancement

610
00:30:10,960 --> 00:30:16,960
I'm going to talk about a new paper

611
00:30:14,440 --> 00:30:18,309
briefly because it's it really connects

612
00:30:16,960 --> 00:30:21,809
what I just discussed with what we're

613
00:30:18,309 --> 00:30:24,730
going to discuss next and the new paper

614
00:30:21,809 --> 00:30:27,789
well it's not that new is it no it's a

615
00:30:24,730 --> 00:30:33,130
year old it's a paper on progressive

616
00:30:27,789 --> 00:30:37,210
dance which came from Nvidia and the

617
00:30:33,130 --> 00:30:40,180
progressive Ganz paper is really neat it

618
00:30:37,210 --> 00:30:43,420
basically sorry Rachel yes we have a

619
00:30:40,180 --> 00:30:45,370
question one-by-one Kampf is usually

620
00:30:43,420 --> 00:30:47,680
called a network within a network in the

621
00:30:45,369 --> 00:30:50,889
literature what is the intuition of such

622
00:30:47,680 --> 00:30:56,049
a name know networking network is more

623
00:30:50,890 --> 00:30:58,270
than just a one by one time it's part of

624
00:30:56,049 --> 00:30:59,559
it I am and we don't I don't think

625
00:30:58,269 --> 00:31:12,910
there's any particular reason to look at

626
00:30:59,559 --> 00:31:16,690
that said I'm aware of okay so the the

627
00:31:12,910 --> 00:31:19,269
progressive can basically takes this

628
00:31:16,690 --> 00:31:23,610
idea of actually gradually increasing

629
00:31:19,269 --> 00:31:25,779
the image size it's the only other

630
00:31:23,609 --> 00:31:27,759
direction I'm aware of where people have

631
00:31:25,779 --> 00:31:30,069
actually gradually increase the image

632
00:31:27,759 --> 00:31:32,140
size and it kind of surprises me because

633
00:31:30,069 --> 00:31:34,240
this paper is actually very popular and

634
00:31:32,140 --> 00:31:36,340
very well known and very well liked and

635
00:31:34,240 --> 00:31:37,630
yet people haven't taken the basic idea

636
00:31:36,339 --> 00:31:40,569
of gradually increasing the image size

637
00:31:37,630 --> 00:31:42,490
and use it anywhere else which shows you

638
00:31:40,569 --> 00:31:44,349
the general level of creativity you can

639
00:31:42,490 --> 00:31:48,819
expect to find in the deep learning

640
00:31:44,349 --> 00:31:50,980
research community perhaps so they start

641
00:31:48,819 --> 00:31:53,099
with four by four like they really go

642
00:31:50,980 --> 00:31:55,360
back start with a four by four again

643
00:31:53,099 --> 00:31:57,699
like literally they're trying to create

644
00:31:55,359 --> 00:31:59,829
like replicate four by four pixel and

645
00:31:57,700 --> 00:32:02,620
then eight by eight and so here's the 8

646
00:31:59,829 --> 00:32:04,240
by 8 pixels this is the celeb a data set

647
00:32:02,619 --> 00:32:06,849
so we're trying to recreate pictures of

648
00:32:04,240 --> 00:32:10,690
celebrities and then they go 65 16 and

649
00:32:06,849 --> 00:32:13,689
then 32 and then 64 and then 128 and

650
00:32:10,690 --> 00:32:16,330
then 256 and one of the really nifty

651
00:32:13,690 --> 00:32:19,870
things they do is that as they increase

652
00:32:16,329 --> 00:32:22,539
size they also add more layers to the

653
00:32:19,869 --> 00:32:23,109
network right which kind of makes sense

654
00:32:22,539 --> 00:32:24,548
right

655
00:32:23,109 --> 00:32:27,069
because if you're doing a more of a

656
00:32:24,548 --> 00:32:28,750
resin Ettie type thing you know then

657
00:32:27,069 --> 00:32:30,250
you're spitting out something which

658
00:32:28,750 --> 00:32:31,990
hopefully makes sense at each grid cell

659
00:32:30,250 --> 00:32:34,779
size and so you should be able to kind

660
00:32:31,990 --> 00:32:37,569
of layer stuff on top and they do

661
00:32:34,779 --> 00:32:40,240
another nifty thing where they kind of

662
00:32:37,569 --> 00:32:43,240
add a skip connection when they do that

663
00:32:40,240 --> 00:32:44,920
and they gradually change the linear

664
00:32:43,240 --> 00:32:48,548
interpolation parameter that moves it

665
00:32:44,920 --> 00:32:50,860
more and more away from the old 4x4

666
00:32:48,548 --> 00:32:52,750
Network and towards the new 8x8 Network

667
00:32:50,859 --> 00:32:54,849
and then once this totally moved it

668
00:32:52,750 --> 00:32:57,460
across they throw away that extra

669
00:32:54,849 --> 00:32:59,319
connection so it's it the details don't

670
00:32:57,460 --> 00:33:01,329
matter too much but it it uses the basic

671
00:32:59,319 --> 00:33:03,819
ideas we've talked about gradually

672
00:33:01,329 --> 00:33:05,798
increasing the image size it's kind of

673
00:33:03,819 --> 00:33:08,289
skip connections and stuff but it's a

674
00:33:05,798 --> 00:33:10,210
great paper to study because a you know

675
00:33:08,289 --> 00:33:12,700
it's like one of these rare things where

676
00:33:10,210 --> 00:33:14,319
they've like good engineers actually

677
00:33:12,700 --> 00:33:15,789
built something that just works in a

678
00:33:14,319 --> 00:33:16,928
really sensible way now it's not

679
00:33:15,789 --> 00:33:19,058
surprising this actually comes from

680
00:33:16,929 --> 00:33:21,009
Nvidia themselves right so in video

681
00:33:19,058 --> 00:33:22,418
don't do a lot of papers and it's

682
00:33:21,009 --> 00:33:24,669
interesting that when they do they build

683
00:33:22,419 --> 00:33:26,980
something that's so thoroughly practical

684
00:33:24,669 --> 00:33:29,950
and sensible and so I think it's a great

685
00:33:26,980 --> 00:33:32,980
paper to study you know if you want to

686
00:33:29,950 --> 00:33:35,039
kind of like put together lots of the

687
00:33:32,980 --> 00:33:38,650
different things we've learned you know

688
00:33:35,039 --> 00:33:40,690
and there aren't many re-implementation

689
00:33:38,650 --> 00:33:43,720
of this so like it's an interesting

690
00:33:40,690 --> 00:33:44,740
thing you know to project and you maybe

691
00:33:43,720 --> 00:33:47,919
you could build on and find something

692
00:33:44,740 --> 00:33:50,140
else so here's what happens next we

693
00:33:47,919 --> 00:33:52,090
eventually go up to 102 4 by 1 or 2 4

694
00:33:50,140 --> 00:33:53,230
and you'll see that the images are not

695
00:33:52,089 --> 00:33:55,449
only getting higher resolution but

696
00:33:53,230 --> 00:33:58,029
they're getting better and so when I

697
00:33:55,450 --> 00:34:00,548
prove 1 or 2 4 by 184 I'm going to see

698
00:33:58,029 --> 00:34:09,128
if you can guess which one of the next

699
00:34:00,548 --> 00:34:12,789
page is fake they're all fake that's the

700
00:34:09,128 --> 00:34:18,309
next stage right you go up up up up up

701
00:34:12,789 --> 00:34:21,820
up up and then BOOM okay so like dance

702
00:34:18,309 --> 00:34:25,389
and stuff they're getting crazy and some

703
00:34:21,820 --> 00:34:27,570
of you may have seen this during the

704
00:34:25,389 --> 00:34:27,570
week

705
00:34:31,750 --> 00:34:38,980
yeah so this video just came out and

706
00:34:35,530 --> 00:34:44,740
it's a speech by Barack Obama and let's

707
00:34:38,980 --> 00:34:48,699
check it out so my Jordan Peele this is

708
00:34:44,739 --> 00:34:50,739
a dangerous time moving forward we need

709
00:34:48,699 --> 00:34:53,439
to be more vigilant with what we trust

710
00:34:50,739 --> 00:34:58,059
from you nourish it's time we need to

711
00:34:53,440 --> 00:35:03,220
rely on trusted news sources they sound

712
00:34:58,059 --> 00:35:06,809
basic but how we before so as you can

713
00:35:03,219 --> 00:35:13,509
see they've used this kind of technology

714
00:35:06,809 --> 00:35:15,880
to literally move Obama's face in the

715
00:35:13,510 --> 00:35:19,050
way that Jordan peels face was moving

716
00:35:15,880 --> 00:35:26,559
and like you basically have all the

717
00:35:19,050 --> 00:35:29,099
techniques you need now to do that so is

718
00:35:26,559 --> 00:35:29,099
that a good idea

719
00:35:30,780 --> 00:35:36,820
so this is the bit where we talk about

720
00:35:33,280 --> 00:35:41,440
what's most important which is like now

721
00:35:36,820 --> 00:35:45,190
that we can like do all this stuff what

722
00:35:41,440 --> 00:35:52,450
should we be doing and how do we think

723
00:35:45,190 --> 00:35:56,050
about that and the Tod our version is I

724
00:35:52,449 --> 00:36:00,399
actually don't know recently a lot of

725
00:35:56,050 --> 00:36:02,410
you saw the founders of this the spacy

726
00:36:00,400 --> 00:36:04,960
prodigy folks founders of explosion a I

727
00:36:02,409 --> 00:36:07,598
had to to talk and Matthew and Ennis I

728
00:36:04,960 --> 00:36:08,889
went to dinner with them afterwards and

729
00:36:07,599 --> 00:36:14,320
we basically spent the entire evening

730
00:36:08,889 --> 00:36:16,179
talking debating arguing about you know

731
00:36:14,320 --> 00:36:20,820
what does it mean they're companies like

732
00:36:16,179 --> 00:36:22,960
ours of building tools that are

733
00:36:20,820 --> 00:36:27,849
democratizing access to tools that can

734
00:36:22,960 --> 00:36:29,769
be used in harmful ways and you know

735
00:36:27,849 --> 00:36:32,109
they're incredibly thoughtful people and

736
00:36:29,769 --> 00:36:34,599
we I wouldn't say we didn't agree we

737
00:36:32,108 --> 00:36:35,980
just couldn't we just couldn't come to a

738
00:36:34,599 --> 00:36:39,088
conclusion ourselves so I'm just going

739
00:36:35,980 --> 00:36:42,099
to lay out some of the questions and

740
00:36:39,088 --> 00:36:44,519
point to some of the research

741
00:36:42,099 --> 00:36:46,960
and when I say research most of the

742
00:36:44,519 --> 00:36:48,989
actual literature review and putting

743
00:36:46,960 --> 00:36:52,019
this together was done by Rachel so

744
00:36:48,989 --> 00:36:56,859
thanks Rachel

745
00:36:52,019 --> 00:37:01,059
let me start by saying the models we

746
00:36:56,860 --> 00:37:03,579
build are often pretty shitty in ways

747
00:37:01,059 --> 00:37:06,549
which are not immediately apparent and

748
00:37:03,579 --> 00:37:08,500
you won't know how shitty they are

749
00:37:06,550 --> 00:37:11,380
unless the people that are building them

750
00:37:08,500 --> 00:37:12,820
with you a range of people and the

751
00:37:11,380 --> 00:37:16,329
people that are using them with you or a

752
00:37:12,820 --> 00:37:18,789
range of people so for example a couple

753
00:37:16,329 --> 00:37:22,449
of wonderful research is Chemnitz at

754
00:37:18,789 --> 00:37:25,949
Stanford and rest joy is she oh she's at

755
00:37:22,449 --> 00:37:30,159
Microsoft now she wasn't Stanford okay

756
00:37:25,949 --> 00:37:33,699
joy is it from PhD from MIT so joy and

757
00:37:30,159 --> 00:37:35,199
Timna did this really interesting

758
00:37:33,699 --> 00:37:38,409
research where they looked at some

759
00:37:35,199 --> 00:37:40,480
basically off-the-shelf face recognizes

760
00:37:38,409 --> 00:37:42,549
one from face plus plus which is a huge

761
00:37:40,480 --> 00:37:45,460
Chinese company IBM's

762
00:37:42,550 --> 00:37:48,300
and Microsoft's and they looked for a

763
00:37:45,460 --> 00:37:50,139
range of different face types I'm

764
00:37:48,300 --> 00:37:51,550
generally speaking you know the

765
00:37:50,139 --> 00:37:54,190
Microsoft one in particular was

766
00:37:51,550 --> 00:37:56,890
incredibly accurate and last the face

767
00:37:54,190 --> 00:38:00,690
type happened to be dark-skinned when

768
00:37:56,889 --> 00:38:03,789
suddenly it went you know 25 times worse

769
00:38:00,690 --> 00:38:07,929
you know got it wrong nearly half the

770
00:38:03,789 --> 00:38:12,690
time and for somebody to a big company

771
00:38:07,929 --> 00:38:16,419
like this to release a product that for

772
00:38:12,690 --> 00:38:19,720
like a very very large percentage of the

773
00:38:16,420 --> 00:38:22,659
world basically doesn't work is more

774
00:38:19,719 --> 00:38:26,649
than a technical failure right it's a

775
00:38:22,659 --> 00:38:28,779
really deep failure of understanding

776
00:38:26,650 --> 00:38:30,579
what kind of team needs to be used to

777
00:38:28,780 --> 00:38:32,410
create such a technology and to test

778
00:38:30,579 --> 00:38:35,219
such a technology or even an

779
00:38:32,409 --> 00:38:37,779
understanding of who your customers are

780
00:38:35,219 --> 00:38:40,149
yeah some of your customers have dark

781
00:38:37,780 --> 00:38:43,050
skin yes Rachel I was also gonna add

782
00:38:40,150 --> 00:38:48,010
that the classifier is all did worse on

783
00:38:43,050 --> 00:38:51,670
women than on men shocking yeah

784
00:38:48,010 --> 00:38:53,170
yeah as funny like actually Rachel

785
00:38:51,670 --> 00:38:55,440
tweeted about something like this the

786
00:38:53,170 --> 00:38:58,269
other day and some some guy was like

787
00:38:55,440 --> 00:39:00,010
what's this all about you know like what

788
00:38:58,269 --> 00:39:02,108
are you saying that we like you know

789
00:39:00,010 --> 00:39:03,940
don't you know about like people people

790
00:39:02,108 --> 00:39:06,069
made cards for a long time you saying

791
00:39:03,940 --> 00:39:09,400
you need women to make cars - and Rachel

792
00:39:06,070 --> 00:39:12,850
pointed out like well actually yes for

793
00:39:09,400 --> 00:39:16,240
most of the history of car safety women

794
00:39:12,849 --> 00:39:18,608
in cars have been far far more at risk

795
00:39:16,239 --> 00:39:22,179
of death than men in cars because the

796
00:39:18,608 --> 00:39:25,299
men created male looking feeling sized

797
00:39:22,179 --> 00:39:27,549
crash-test dummies and so car safety was

798
00:39:25,300 --> 00:39:30,220
literally not tested on women size

799
00:39:27,550 --> 00:39:31,960
bodies so the fact you know like you

800
00:39:30,219 --> 00:39:33,639
know shitty product management with a

801
00:39:31,960 --> 00:39:36,429
total failure of diversity and

802
00:39:33,639 --> 00:39:39,509
understanding is not new to our field

803
00:39:36,429 --> 00:39:42,608
and I would say that was comparing

804
00:39:39,510 --> 00:39:45,280
impacts of similar strength men and

805
00:39:42,608 --> 00:39:46,420
women mm-hmm yeah I don't know why like

806
00:39:45,280 --> 00:39:48,340
whenever you say something nice on

807
00:39:46,420 --> 00:39:49,389
Twitter like Rachel has to say this

808
00:39:48,340 --> 00:39:50,980
because anytime you say something like

809
00:39:49,389 --> 00:39:52,539
some Twitter there's like 10 people

810
00:39:50,980 --> 00:39:54,429
who'll be like all you have to compare

811
00:39:52,539 --> 00:39:59,559
all these other things is if like we

812
00:39:54,429 --> 00:40:04,210
didn't know that so yeah I mean yeah

813
00:39:59,559 --> 00:40:06,670
other things you know our very best most

814
00:40:04,210 --> 00:40:09,690
famous systems do like Microsoft's face

815
00:40:06,670 --> 00:40:12,820
recognizer or Google's language

816
00:40:09,690 --> 00:40:14,349
translator you turn she is a doctor he

817
00:40:12,820 --> 00:40:16,650
is a nurse into Turkish and quite

818
00:40:14,349 --> 00:40:19,118
correctly both the pronouns become Oh

819
00:40:16,650 --> 00:40:21,519
because there's no gendered pronouns in

820
00:40:19,119 --> 00:40:23,559
Turkish so go the other direction

821
00:40:21,519 --> 00:40:28,480
I'll be a doctor I don't know how to say

822
00:40:23,559 --> 00:40:31,210
that one for Christmas and what does it

823
00:40:28,480 --> 00:40:33,579
get turned into he is a doctor she is a

824
00:40:31,210 --> 00:40:36,429
nurse so like we've got these kind of

825
00:40:33,579 --> 00:40:39,730
like biases built into tools that we're

826
00:40:36,429 --> 00:40:41,289
all using every day and again people

827
00:40:39,730 --> 00:40:43,539
they go it's just showing us what's in

828
00:40:41,289 --> 00:40:45,340
the world and well okay there's lots of

829
00:40:43,539 --> 00:40:48,309
problems with that basic assertion but

830
00:40:45,340 --> 00:40:50,590
as you know machine learning algorithms

831
00:40:48,309 --> 00:40:51,909
love to generalize right and so because

832
00:40:50,590 --> 00:40:53,590
they love to generalize this is one of

833
00:40:51,909 --> 00:40:56,739
the cool things about you guys knowing

834
00:40:53,590 --> 00:40:58,720
the technical details now because they

835
00:40:56,739 --> 00:41:01,399
love to generalize when you see

836
00:40:58,719 --> 00:41:03,349
something like 60% of people cooking our

837
00:41:01,400 --> 00:41:05,300
in the pictures they used to build this

838
00:41:03,349 --> 00:41:07,219
model and then you actually run the

839
00:41:05,300 --> 00:41:10,700
model on a separate set of pictures then

840
00:41:07,219 --> 00:41:14,750
84 percent of the people they choose as

841
00:41:10,699 --> 00:41:17,109
cooking women rather than the correct 67

842
00:41:14,750 --> 00:41:19,730
percent but which is like a really

843
00:41:17,110 --> 00:41:23,599
understandable thing for an algorithm to

844
00:41:19,730 --> 00:41:26,659
do as it took a biased input and created

845
00:41:23,599 --> 00:41:29,360
a more biased output because you know

846
00:41:26,659 --> 00:41:30,469
for this particular loss function you

847
00:41:29,360 --> 00:41:34,030
know that's kind of where it ended up

848
00:41:30,469 --> 00:41:35,959
and this is a really common kind of a

849
00:41:34,030 --> 00:41:43,240
really common kind of model

850
00:41:35,960 --> 00:41:47,690
amplification okay so this stuff matters

851
00:41:43,239 --> 00:41:52,389
right it matters in ways more than just

852
00:41:47,690 --> 00:41:55,519
you know awkward translations or like

853
00:41:52,389 --> 00:41:58,309
you know black people's photos not being

854
00:41:55,519 --> 00:42:00,170
classified correctly or you know maybe

855
00:41:58,309 --> 00:42:01,670
there's some there's some wins too as

856
00:42:00,170 --> 00:42:03,289
well like you know horrifying

857
00:42:01,670 --> 00:42:07,970
surveillance everywhere and maybe won't

858
00:42:03,289 --> 00:42:09,230
work on black people right but yes or

859
00:42:07,969 --> 00:42:10,639
it'll be even worse because it's

860
00:42:09,230 --> 00:42:13,300
horrifying surveillance and it's

861
00:42:10,639 --> 00:42:17,359
flat-out racist and wrong okay that sir

862
00:42:13,300 --> 00:42:21,740
but but let's go deeper right like what

863
00:42:17,360 --> 00:42:25,820
hat like that the four always say about

864
00:42:21,739 --> 00:42:27,439
human failings humans such generally you

865
00:42:25,820 --> 00:42:31,460
know that there's there's a long history

866
00:42:27,440 --> 00:42:34,429
of civilization and societies creating

867
00:42:31,460 --> 00:42:36,800
kind of layers of human judgment which

868
00:42:34,429 --> 00:42:40,309
avoid hopefully the most horrible things

869
00:42:36,800 --> 00:42:43,190
happening and sometimes companies which

870
00:42:40,309 --> 00:42:44,599
love technology think let's throw away

871
00:42:43,190 --> 00:42:47,210
the humans and replace them with

872
00:42:44,599 --> 00:42:49,219
technology like Facebook did right so

873
00:42:47,210 --> 00:42:51,170
let's let two or three years ago a

874
00:42:49,219 --> 00:42:52,969
couple years ago Facebook literally got

875
00:42:51,170 --> 00:42:54,650
rid of their human editors like this is

876
00:42:52,969 --> 00:42:57,409
in the news at the time and they were

877
00:42:54,650 --> 00:42:59,480
replaced with algorithms and so now as

878
00:42:57,409 --> 00:43:01,129
algorithms that put all the stuff on

879
00:42:59,480 --> 00:43:03,969
your on your newsfeed and human editors

880
00:43:01,130 --> 00:43:07,130
right at the loop what happened next

881
00:43:03,969 --> 00:43:12,230
many things happen next one of which was

882
00:43:07,130 --> 00:43:14,510
a massive horrifying genocide Menma

883
00:43:12,230 --> 00:43:14,900
babies getting torn out of their mothers

884
00:43:14,510 --> 00:43:19,430
are

885
00:43:14,900 --> 00:43:22,519
right under fires mass rape murder and

886
00:43:19,429 --> 00:43:27,528
an entire people exiled from their

887
00:43:22,519 --> 00:43:31,880
homeland okay I'm not gonna say that was

888
00:43:27,528 --> 00:43:34,460
because Facebook did this but what I

889
00:43:31,880 --> 00:43:38,028
will say is that when the leaders of

890
00:43:34,460 --> 00:43:41,929
this horrifying project are interviewed

891
00:43:38,028 --> 00:43:45,048
they regularly talk about how everything

892
00:43:41,929 --> 00:43:47,000
they learnt about the disgusting animal

893
00:43:45,048 --> 00:43:48,769
behaviors of Rangers that need to be

894
00:43:47,000 --> 00:43:51,849
thrown off the earth they learnt from

895
00:43:48,769 --> 00:43:54,409
Facebook right because the algorithms

896
00:43:51,849 --> 00:43:56,900
just want to feed you more stuff that

897
00:43:54,409 --> 00:43:59,509
gets you clicking and so if you get told

898
00:43:56,900 --> 00:44:01,338
these people that don't look like you

899
00:43:59,510 --> 00:44:02,539
and you don't know a bad people and

900
00:44:01,338 --> 00:44:03,920
here's what the story's about the bad

901
00:44:02,539 --> 00:44:05,599
people and then you start clicking on

902
00:44:03,920 --> 00:44:07,278
them and then they feed you more of

903
00:44:05,599 --> 00:44:09,950
those things and next thing you know you

904
00:44:07,278 --> 00:44:12,619
have this like extraordinary cycle and

905
00:44:09,949 --> 00:44:15,439
people have been studying this right so

906
00:44:12,619 --> 00:44:17,358
for example some we've been told a few

907
00:44:15,440 --> 00:44:19,309
times people click on our first AI

908
00:44:17,358 --> 00:44:21,440
videos and then the next thing

909
00:44:19,309 --> 00:44:24,260
recommended to them is like conspiracy

910
00:44:21,440 --> 00:44:27,950
theory videos from Alex Jones and then

911
00:44:24,260 --> 00:44:30,710
you know continues there because you

912
00:44:27,949 --> 00:44:33,769
know humans click on things that shocked

913
00:44:30,710 --> 00:44:37,460
us and surprise us and horrify us right

914
00:44:33,769 --> 00:44:41,329
and so at so many levels

915
00:44:37,460 --> 00:44:44,358
you know this decision has had

916
00:44:41,329 --> 00:44:47,240
extraordinary consequences which we're

917
00:44:44,358 --> 00:44:48,769
only beginning to understand and again

918
00:44:47,239 --> 00:44:50,929
this is not to say this particular

919
00:44:48,769 --> 00:44:55,940
consequence is because of this one thing

920
00:44:50,929 --> 00:44:58,250
but to say it's entirely unrelated would

921
00:44:55,940 --> 00:45:03,490
be clearly ignoring all of the evidence

922
00:44:58,250 --> 00:45:07,278
and information that we have right so

923
00:45:03,489 --> 00:45:10,278
this is really kind of the key takeaway

924
00:45:07,278 --> 00:45:16,190
is to think like what are you building

925
00:45:10,278 --> 00:45:19,869
and how could it be used right so lots

926
00:45:16,190 --> 00:45:23,298
and lots of effort now being put into

927
00:45:19,869 --> 00:45:24,798
face detection including in our course

928
00:45:23,298 --> 00:45:27,230
right we've been spending a lot of time

929
00:45:24,798 --> 00:45:28,130
thinking about how to recognize stuff

930
00:45:27,230 --> 00:45:30,769
and where

931
00:45:28,130 --> 00:45:31,670
and there's lots of good reasons to want

932
00:45:30,768 --> 00:45:34,879
to be good at that

933
00:45:31,670 --> 00:45:37,190
you know for improving crop yields and

934
00:45:34,880 --> 00:45:39,709
agriculture for improving diagnostic and

935
00:45:37,190 --> 00:45:43,298
treatment planning and medicine for

936
00:45:39,708 --> 00:45:49,399
improving your logo sorting robot system

937
00:45:43,298 --> 00:45:52,699
whatever right but it's also being

938
00:45:49,400 --> 00:45:57,469
widely used in in surveillance and

939
00:45:52,699 --> 00:46:00,440
propaganda and disinformation and you

940
00:45:57,469 --> 00:46:01,818
know again it's like the question is

941
00:46:00,440 --> 00:46:04,548
like well what do I do about that

942
00:46:01,818 --> 00:46:06,849
I don't exactly know right but it's just

943
00:46:04,548 --> 00:46:11,059
definitely at least important to be

944
00:46:06,849 --> 00:46:13,599
thinking about it talking about it and

945
00:46:11,059 --> 00:46:18,739
sometimes you can do really good things

946
00:46:13,599 --> 00:46:19,849
for example meetup comm did something

947
00:46:18,739 --> 00:46:21,559
which I would put in the category of

948
00:46:19,849 --> 00:46:24,410
really good thing which is they

949
00:46:21,559 --> 00:46:29,390
recognized early a potential problem

950
00:46:24,409 --> 00:46:32,629
which is that more men who are tending

951
00:46:29,389 --> 00:46:36,078
to go to their meet us and that was

952
00:46:32,630 --> 00:46:37,519
causing their collaborative filtering

953
00:46:36,079 --> 00:46:42,019
systems which you're all familiar

954
00:46:37,518 --> 00:46:45,828
building now to recommend more technical

955
00:46:42,018 --> 00:46:47,929
content to men and that was causing more

956
00:46:45,829 --> 00:46:49,369
men to go to more technical content

957
00:46:47,929 --> 00:46:50,838
which was causing the recommendation

958
00:46:49,369 --> 00:46:54,798
systems to suggest more technical

959
00:46:50,838 --> 00:46:56,588
content to men right and this kind of

960
00:46:54,798 --> 00:47:00,619
runaway feedback loop is extremely

961
00:46:56,588 --> 00:47:03,920
common when we interface the algorithm

962
00:47:00,619 --> 00:47:07,670
and the human together so what it made

963
00:47:03,920 --> 00:47:10,670
up do they intentionally made the

964
00:47:07,670 --> 00:47:13,278
decision to recommend more technical

965
00:47:10,670 --> 00:47:18,409
content to women right not because of

966
00:47:13,278 --> 00:47:20,568
some you know highfalutin idea about how

967
00:47:18,409 --> 00:47:23,118
the world should be but just because

968
00:47:20,568 --> 00:47:26,958
that makes sense right that the runaway

969
00:47:23,119 --> 00:47:28,430
feedback loop was a bug right there are

970
00:47:26,958 --> 00:47:29,838
women that want to go to tech meetups

971
00:47:28,429 --> 00:47:32,268
but when you turn up for a tech make up

972
00:47:29,838 --> 00:47:34,578
and it's all men and you don't go and

973
00:47:32,268 --> 00:47:37,159
then it recommends more to men and so on

974
00:47:34,579 --> 00:47:39,619
and so forth right so so I made up made

975
00:47:37,159 --> 00:47:42,089
us a really strong product management

976
00:47:39,619 --> 00:47:45,380
decision here which was too

977
00:47:42,090 --> 00:47:48,030
not do what the algorithm said to do

978
00:47:45,380 --> 00:47:50,640
unfortunately this is rare

979
00:47:48,030 --> 00:47:52,890
most of these runaway feedback loops for

980
00:47:50,639 --> 00:47:55,230
example in predictive policing where

981
00:47:52,889 --> 00:47:57,210
algorithms tell policemen where to go

982
00:47:55,230 --> 00:47:59,039
which very often is more black

983
00:47:57,210 --> 00:48:00,659
neighborhoods which end up crawling with

984
00:47:59,039 --> 00:48:02,759
more policemen which leads to more

985
00:48:00,659 --> 00:48:03,750
arrests which has assistance job more

986
00:48:02,760 --> 00:48:12,390
policemen to go to more black

987
00:48:03,750 --> 00:48:16,800
neighborhoods and so forth so this

988
00:48:12,389 --> 00:48:21,210
problem of algorithmic bias is now very

989
00:48:16,800 --> 00:48:25,200
widespread and as algorithms become more

990
00:48:21,210 --> 00:48:29,519
and more widely used for specific policy

991
00:48:25,199 --> 00:48:32,129
decisions judicial decisions day-to-day

992
00:48:29,519 --> 00:48:36,960
decisions about just who to give what

993
00:48:32,130 --> 00:48:41,340
offer to this just keeps becoming a

994
00:48:36,960 --> 00:48:46,019
bigger problem right and so and some of

995
00:48:41,340 --> 00:48:47,610
them are really things that the people

996
00:48:46,019 --> 00:48:49,710
involved in the product management

997
00:48:47,610 --> 00:48:52,829
decision should have seen at the very

998
00:48:49,710 --> 00:48:54,659
start didn't make sense and were

999
00:48:52,829 --> 00:48:57,809
unreasonable under any definition of the

1000
00:48:54,659 --> 00:49:00,960
term for example this stuff that I'd

1001
00:48:57,809 --> 00:49:05,009
gone pointed out these were questions

1002
00:49:00,960 --> 00:49:09,119
that were used to decide which was the

1003
00:49:05,010 --> 00:49:12,180
sentencing guidelines this software is

1004
00:49:09,119 --> 00:49:13,949
used for both pretrial so who it was

1005
00:49:12,179 --> 00:49:15,089
required to post bail so these are

1006
00:49:13,949 --> 00:49:18,089
people that haven't even been convicted

1007
00:49:15,090 --> 00:49:21,240
as well as for sentencing and for who

1008
00:49:18,090 --> 00:49:22,920
gets parole and this was upheld by the

1009
00:49:21,239 --> 00:49:26,909
Wisconsin Supreme Court last year

1010
00:49:22,920 --> 00:49:29,280
despite all the flaws okay so whether

1011
00:49:26,909 --> 00:49:31,589
you have to stay in jail because you

1012
00:49:29,280 --> 00:49:33,269
can't pay the bail and how long your

1013
00:49:31,590 --> 00:49:37,130
sentences for and how long you stay in

1014
00:49:33,269 --> 00:49:40,259
jail for depends on what your father did

1015
00:49:37,130 --> 00:49:42,619
whether your parents stayed married who

1016
00:49:40,260 --> 00:49:45,630
your friends are and where you live

1017
00:49:42,619 --> 00:49:49,259
right now

1018
00:49:45,630 --> 00:49:51,269
turns out these algorithms are actually

1019
00:49:49,260 --> 00:49:52,980
terribly terribly bad so some recent

1020
00:49:51,269 --> 00:49:54,849
analysis showed that they're basically

1021
00:49:52,980 --> 00:49:56,559
worse than chance but even the

1022
00:49:54,849 --> 00:49:58,179
the company's building them were

1023
00:49:56,559 --> 00:50:01,409
confident on these were statistically

1024
00:49:58,179 --> 00:50:03,819
accurate correlations

1025
00:50:01,409 --> 00:50:07,449
does anybody imagine there's a world

1026
00:50:03,820 --> 00:50:11,410
where it makes sense to decide like what

1027
00:50:07,449 --> 00:50:17,379
happens to you based on what your dad

1028
00:50:11,409 --> 00:50:21,579
did you know so a lot of this stuff you

1029
00:50:17,380 --> 00:50:24,910
know at the basic level is obviously

1030
00:50:21,579 --> 00:50:26,349
unreasonable and a lot of it just fails

1031
00:50:24,909 --> 00:50:28,029
in these ways that you can see

1032
00:50:26,349 --> 00:50:29,799
empirically that these kind of runaway

1033
00:50:28,030 --> 00:50:31,060
feedback loops must have happened and

1034
00:50:29,800 --> 00:50:33,100
these over generalizations must have

1035
00:50:31,059 --> 00:50:35,199
happened you know for example these are

1036
00:50:33,099 --> 00:50:38,380
the kind of cross tabs that anybody

1037
00:50:35,199 --> 00:50:39,730
working in these fields in any field is

1038
00:50:38,380 --> 00:50:46,030
using algorithm should be preparing

1039
00:50:39,730 --> 00:50:49,110
right so prediction of likelihood of

1040
00:50:46,030 --> 00:50:52,600
reoffending for black versus white

1041
00:50:49,110 --> 00:50:55,360
defendants like we can just calculate

1042
00:50:52,599 --> 00:51:00,329
this very simply of the people that were

1043
00:50:55,360 --> 00:51:03,160
labeled high-risk but didn't reopen

1044
00:51:00,329 --> 00:51:06,509
there were twenty three point five

1045
00:51:03,159 --> 00:51:09,639
percent white but about twice that

1046
00:51:06,510 --> 00:51:12,220
african-american where else those that

1047
00:51:09,639 --> 00:51:17,049
were labeled law risk but did riaf end

1048
00:51:12,219 --> 00:51:18,309
was like half the white people and only

1049
00:51:17,050 --> 00:51:20,890
twenty percent of the african-american

1050
00:51:18,309 --> 00:51:24,279
right so like this is the kind of stuff

1051
00:51:20,889 --> 00:51:25,659
we're least you know if you're taking

1052
00:51:24,280 --> 00:51:27,370
the technologies we've been talking

1053
00:51:25,659 --> 00:51:30,179
about and putting the production in some

1054
00:51:27,369 --> 00:51:33,849
kind of in any way right or building a

1055
00:51:30,179 --> 00:51:36,669
an API for other people or providing

1056
00:51:33,849 --> 00:51:41,559
training for people or or whatever right

1057
00:51:36,670 --> 00:51:44,110
then at least make sure that the that

1058
00:51:41,559 --> 00:51:46,059
what you're doing can be tracked in a

1059
00:51:44,110 --> 00:51:48,039
way that people know if some things you

1060
00:51:46,059 --> 00:51:50,679
know people know what's going on that's

1061
00:51:48,039 --> 00:51:53,320
at least they're informed okay I think

1062
00:51:50,679 --> 00:51:58,000
it's a mistake in my opinion to assume

1063
00:51:53,320 --> 00:52:01,059
that people are our evil you know and

1064
00:51:58,000 --> 00:52:03,909
and trying to break society right like I

1065
00:52:01,059 --> 00:52:05,769
think I would I prefer to start with an

1066
00:52:03,909 --> 00:52:08,710
assumption of like okay if people are

1067
00:52:05,769 --> 00:52:10,690
doing dumb stuff it's because they don't

1068
00:52:08,710 --> 00:52:12,369
all right so you know at least make sure

1069
00:52:10,690 --> 00:52:17,380
that they have this information and I

1070
00:52:12,369 --> 00:52:19,000
find very few ml practitioners thinking

1071
00:52:17,380 --> 00:52:20,500
about what is the information they

1072
00:52:19,000 --> 00:52:22,539
should be presenting in their interface

1073
00:52:20,500 --> 00:52:24,070
you know and then often I'll talk to

1074
00:52:22,539 --> 00:52:25,358
data scientists who will kind of say

1075
00:52:24,070 --> 00:52:28,019
like oh the stuff I'm working one

1076
00:52:25,358 --> 00:52:31,630
doesn't have a societal impact it's like

1077
00:52:28,019 --> 00:52:32,889
really like like a number of people who

1078
00:52:31,630 --> 00:52:35,980
think that what they're doing is

1079
00:52:32,889 --> 00:52:37,719
entirely pointless come on you know

1080
00:52:35,980 --> 00:52:39,490
otherwise you think people are paying

1081
00:52:37,719 --> 00:52:41,828
you to do it for a reason that's going

1082
00:52:39,489 --> 00:52:46,719
to impact people in some way okay so

1083
00:52:41,829 --> 00:52:48,220
think about what that is the other thing

1084
00:52:46,719 --> 00:52:51,009
I know is a lot of people involved here

1085
00:52:48,219 --> 00:52:53,439
are hiring people and so if you're

1086
00:52:51,010 --> 00:52:54,700
hiring people you know I guess you're

1087
00:52:53,440 --> 00:52:56,559
all very familiar with the first day I

1088
00:52:54,699 --> 00:52:58,299
philosophy now which is the basic

1089
00:52:56,559 --> 00:53:01,328
premise that and I think it comes back

1090
00:52:58,300 --> 00:53:03,160
to this idea that I don't think about

1091
00:53:01,329 --> 00:53:06,060
people on the whole were evil I think

1092
00:53:03,159 --> 00:53:09,190
they need to be informed and have tools

1093
00:53:06,059 --> 00:53:11,108
right so we're trying to have us give as

1094
00:53:09,190 --> 00:53:13,450
many people the tools as possible that

1095
00:53:11,108 --> 00:53:15,219
they need and particularly we're trying

1096
00:53:13,449 --> 00:53:17,679
to put those tools in the hand of a more

1097
00:53:15,219 --> 00:53:19,449
the hands of a more diverse range of

1098
00:53:17,679 --> 00:53:22,598
people so if you're involved in hiring

1099
00:53:19,449 --> 00:53:24,818
decisions perhaps you can keep this kind

1100
00:53:22,599 --> 00:53:27,700
of philosophy in mind as well that if

1101
00:53:24,818 --> 00:53:32,469
you're if you're not just hiring a wider

1102
00:53:27,699 --> 00:53:35,409
range of people but also promoting a

1103
00:53:32,469 --> 00:53:37,389
wider range of people and providing like

1104
00:53:35,409 --> 00:53:39,759
really appropriate Career Management for

1105
00:53:37,389 --> 00:53:43,210
a wider range of people well apart from

1106
00:53:39,760 --> 00:53:46,089
anything else your company will do

1107
00:53:43,210 --> 00:53:48,429
better it actually turns out that more

1108
00:53:46,088 --> 00:53:51,130
diverse teams are more creative and tend

1109
00:53:48,429 --> 00:53:53,679
to solve problems more quickly and

1110
00:53:51,130 --> 00:53:56,970
better than most diverse teams but also

1111
00:53:53,679 --> 00:54:00,578
you know you might avoid these kind of

1112
00:53:56,969 --> 00:54:03,159
awful screw-ups which you know that one

1113
00:54:00,579 --> 00:54:04,839
level are bad for the world and another

1114
00:54:03,159 --> 00:54:10,539
level if you ever get found out they can

1115
00:54:04,838 --> 00:54:15,219
also destroy your company also they can

1116
00:54:10,539 --> 00:54:16,809
destroy you or at least make you look

1117
00:54:15,219 --> 00:54:20,949
pretty bad in history a couple of

1118
00:54:16,809 --> 00:54:21,590
examples one is you know going right

1119
00:54:20,949 --> 00:54:25,609
back to

1120
00:54:21,590 --> 00:54:26,900
the Second World War IBM basically

1121
00:54:25,610 --> 00:54:32,960
provided all of the infrastructure

1122
00:54:26,900 --> 00:54:35,150
necessary to track the Holocaust so they

1123
00:54:32,960 --> 00:54:38,869
had a these are the forms that they used

1124
00:54:35,150 --> 00:54:40,809
and they say had different code for you

1125
00:54:38,869 --> 00:54:43,670
know Jews were Asian gypsies for 12

1126
00:54:40,809 --> 00:54:44,960
death and the gas chambers were six and

1127
00:54:43,670 --> 00:54:47,000
they all went on these punch cards you

1128
00:54:44,960 --> 00:54:49,880
can go and look at these punch cards and

1129
00:54:47,000 --> 00:54:53,719
museums now and this has actually been

1130
00:54:49,880 --> 00:54:56,630
reviewed by a Swiss judge who said that

1131
00:54:53,719 --> 00:54:58,189
IBM's technical assistance facilitated

1132
00:54:56,630 --> 00:55:03,320
the task of the Nazis and the commission

1133
00:54:58,190 --> 00:55:05,210
of the crimes against humanity and you

1134
00:55:03,320 --> 00:55:09,590
know it's interesting to read back the

1135
00:55:05,210 --> 00:55:11,119
history you know from these times to see

1136
00:55:09,590 --> 00:55:13,579
like what was going through the minds of

1137
00:55:11,119 --> 00:55:15,019
people at IBM at that time and you know

1138
00:55:13,579 --> 00:55:17,269
what what was clearly going through the

1139
00:55:15,019 --> 00:55:19,309
minds was like the opportunity to show

1140
00:55:17,269 --> 00:55:21,110
technical superiority the opportunity

1141
00:55:19,309 --> 00:55:25,009
that I test out their you know their new

1142
00:55:21,110 --> 00:55:26,090
systems it's it's it's you know and the

1143
00:55:25,010 --> 00:55:29,630
course the extraordinary amount of money

1144
00:55:26,090 --> 00:55:34,970
that they were making um you know and

1145
00:55:29,630 --> 00:55:36,980
when when you do something which at some

1146
00:55:34,969 --> 00:55:40,599
point down the line turns out to be a

1147
00:55:36,980 --> 00:55:42,800
problem even if you were told to do it

1148
00:55:40,599 --> 00:55:45,079
that can turn out to be a problem for

1149
00:55:42,800 --> 00:55:47,240
you personally for example you will

1150
00:55:45,079 --> 00:55:50,299
remember the diesel emissions scandal in

1151
00:55:47,239 --> 00:55:54,259
VW know who is the one guy that went to

1152
00:55:50,300 --> 00:55:54,970
jail it was the engineer right just

1153
00:55:54,260 --> 00:55:58,550
doing his job

1154
00:55:54,969 --> 00:56:01,069
okay so if all of this stuff about

1155
00:55:58,550 --> 00:56:03,769
actually you know not sucking up the

1156
00:56:01,070 --> 00:56:06,110
world isn't enough to convince you they

1157
00:56:03,769 --> 00:56:08,780
can up your life too right so if

1158
00:56:06,110 --> 00:56:11,300
you if you do something that turns out

1159
00:56:08,780 --> 00:56:14,060
to cause problems even though somebody

1160
00:56:11,300 --> 00:56:17,840
told you to do it you can absolutely be

1161
00:56:14,059 --> 00:56:20,210
held criminally responsible and you're

1162
00:56:17,840 --> 00:56:20,930
certainly like look at the but there's

1163
00:56:20,210 --> 00:56:22,550
no Cogan

1164
00:56:20,929 --> 00:56:24,349
you know I think a lot of people now

1165
00:56:22,550 --> 00:56:26,810
know the name Aleksandr Cogan he was the

1166
00:56:24,349 --> 00:56:28,670
guy that handed over the Cambridge

1167
00:56:26,809 --> 00:56:32,179
analytic er data

1168
00:56:28,670 --> 00:56:34,889
he's a Cambridge academic now a very

1169
00:56:32,179 --> 00:56:37,889
famous Cambridge academic the world over

1170
00:56:34,889 --> 00:56:41,639
for doing his part to destroy the

1171
00:56:37,889 --> 00:56:43,078
foundations of democracy right so you

1172
00:56:41,639 --> 00:56:47,338
know this is probably not how we want to

1173
00:56:43,079 --> 00:56:50,390
go down in history all right so let's

1174
00:56:47,338 --> 00:56:54,599
have a break before we do read short

1175
00:56:50,389 --> 00:56:56,368
question on a different topic yes in one

1176
00:56:54,599 --> 00:56:58,470
of your tweets you said drop out is

1177
00:56:56,369 --> 00:57:01,680
patented I think this is about wavenet

1178
00:56:58,469 --> 00:57:03,088
patent from Google what does it mean can

1179
00:57:01,679 --> 00:57:04,710
you please share more insight on this

1180
00:57:03,088 --> 00:57:07,380
subject does it mean that will help to

1181
00:57:04,710 --> 00:57:09,298
pay to use drop out in the future yeah

1182
00:57:07,380 --> 00:57:12,088
okay good question let's talk about that

1183
00:57:09,298 --> 00:57:17,068
after the break and so let's come back

1184
00:57:12,088 --> 00:57:24,679
at 7:40 the question before the break

1185
00:57:17,068 --> 00:57:28,018
was about patents what does it mean so

1186
00:57:24,679 --> 00:57:32,639
so I guess the reasons coming up was

1187
00:57:28,018 --> 00:57:34,649
because I wrote a tweet this week which

1188
00:57:32,639 --> 00:57:38,670
I think was like three words and said

1189
00:57:34,650 --> 00:57:44,849
drop out is patented - the patent

1190
00:57:38,670 --> 00:57:46,858
holders is Geoffrey Hinton so what isn't

1191
00:57:44,849 --> 00:57:50,640
that great inventions all of our patents

1192
00:57:46,858 --> 00:57:54,380
right and so you know my answer is no

1193
00:57:50,639 --> 00:57:58,259
you know patents have gone wildly crazy

1194
00:57:54,380 --> 00:57:59,849
the amount of things that are patentable

1195
00:57:58,259 --> 00:58:02,730
that we talk about every week would be

1196
00:57:59,849 --> 00:58:07,920
dozens like it's so easy to come up with

1197
00:58:02,730 --> 00:58:09,329
a little tweak and then you know if you

1198
00:58:07,920 --> 00:58:10,889
turn that into a patent to stop

1199
00:58:09,329 --> 00:58:12,420
everybody from using that little tweak

1200
00:58:10,889 --> 00:58:14,420
for the next 14 years and you end up

1201
00:58:12,420 --> 00:58:17,460
with a situation we have now where

1202
00:58:14,420 --> 00:58:20,099
everything is patented in 50 different

1203
00:58:17,460 --> 00:58:22,170
ways and so then you get these patent

1204
00:58:20,099 --> 00:58:24,539
trolls who have made a very very good

1205
00:58:22,170 --> 00:58:27,088
business out of looking better basically

1206
00:58:24,539 --> 00:58:29,640
buying lots of shitty little patents and

1207
00:58:27,088 --> 00:58:33,619
then suing anybody who accidentally

1208
00:58:29,639 --> 00:58:36,480
turned out did that thing you know like

1209
00:58:33,619 --> 00:58:40,528
putting rounded corners on buttons you

1210
00:58:36,480 --> 00:58:42,150
know so who was it oh this there's Apple

1211
00:58:40,528 --> 00:58:48,298
suits Samsung or something I don't

1212
00:58:42,150 --> 00:58:50,759
remember so yeah so what does it mean

1213
00:58:48,298 --> 00:58:53,730
for us that a lot of stuff is patented

1214
00:58:50,759 --> 00:58:58,048
in deep learning I don't know

1215
00:58:53,730 --> 00:59:00,088
it's like one theory like a lot of the

1216
00:58:58,048 --> 00:59:04,108
one of the main people doing this is

1217
00:59:00,088 --> 00:59:06,358
Google and people from Google who

1218
00:59:04,108 --> 00:59:09,480
replied to this patent tend to assume

1219
00:59:06,358 --> 00:59:11,098
that on Google's doing it because they

1220
00:59:09,480 --> 00:59:12,690
wanted to have it defensively so if

1221
00:59:11,099 --> 00:59:14,548
somebody Sue's them they'll be like

1222
00:59:12,690 --> 00:59:16,588
don't sue us we'll see you back because

1223
00:59:14,548 --> 00:59:20,130
we have all these patents

1224
00:59:16,588 --> 00:59:21,449
the problem is that as far as I know

1225
00:59:20,130 --> 00:59:23,730
they haven't signed what's called a

1226
00:59:21,449 --> 00:59:26,338
defensive patent pledge so basically you

1227
00:59:23,730 --> 00:59:28,528
can sign a legally binding document that

1228
00:59:26,338 --> 00:59:31,949
says our patent portfolio will only be

1229
00:59:28,528 --> 00:59:33,119
used in defense and not offense and even

1230
00:59:31,949 --> 00:59:35,759
if you believe all the management of

1231
00:59:33,119 --> 00:59:36,059
Google would never turn into a patent

1232
00:59:35,759 --> 00:59:38,329
troll

1233
00:59:36,059 --> 00:59:41,309
you've got to remember that you know

1234
00:59:38,329 --> 00:59:44,339
management changes right and like to

1235
00:59:41,309 --> 00:59:47,548
give a specific example I know the you

1236
00:59:44,338 --> 00:59:49,619
know the somewhat recent CFO of Google

1237
00:59:47,548 --> 00:59:52,288
you know has a much more you know kind

1238
00:59:49,619 --> 00:59:55,048
of aggressive stance towards the PNL and

1239
00:59:52,289 --> 00:59:56,880
I don't know maybe maybe she might

1240
00:59:55,048 --> 01:00:00,329
decide that they should start monetizing

1241
00:59:56,880 --> 01:00:02,160
their patents or maybe the you know the

1242
01:00:00,329 --> 01:00:03,599
group that made that patent might get

1243
01:00:02,159 --> 01:00:05,098
spun off and then sold to another

1244
01:00:03,599 --> 01:00:07,048
company that might end up in private

1245
01:00:05,099 --> 01:00:10,109
equity hands and decide to monetize the

1246
01:00:07,048 --> 01:00:13,949
patents or whatever like so I think it's

1247
01:00:10,108 --> 01:00:17,909
a problem there has been a big shift

1248
01:00:13,949 --> 01:00:20,460
legally recently away from software

1249
01:00:17,909 --> 01:00:23,038
patents actually having any legal

1250
01:00:20,460 --> 01:00:24,509
standing so it's possible that these

1251
01:00:23,039 --> 01:00:27,480
will all end up thrown out of court but

1252
01:00:24,509 --> 01:00:29,400
you know the reality is that anything

1253
01:00:27,480 --> 01:00:32,219
but a big company is unlikely to have

1254
01:00:29,400 --> 01:00:34,490
the financial ability to defend

1255
01:00:32,219 --> 01:00:36,828
themselves against one of these huge

1256
01:00:34,489 --> 01:00:40,199
patent trolls

1257
01:00:36,829 --> 01:00:45,359
so I think it's a problem I don't know

1258
01:00:40,199 --> 01:00:47,639
like it you you can't you can't avoid

1259
01:00:45,358 --> 01:00:49,619
using patented stuff if you write code

1260
01:00:47,639 --> 01:00:51,900
like most I wouldn't be surprised if

1261
01:00:49,619 --> 01:00:54,059
most lines of code you write have

1262
01:00:51,900 --> 01:00:55,889
patents on them

1263
01:00:54,059 --> 01:00:56,100
so actually funnily enough the best

1264
01:00:55,889 --> 01:00:59,239
thing

1265
01:00:56,099 --> 01:01:03,119
to do is not to study the patents

1266
01:00:59,239 --> 01:01:06,089
because if you do and you infringe

1267
01:01:03,119 --> 01:01:10,230
knowingly then it's the penalties are

1268
01:01:06,090 --> 01:01:11,850
worse so the best thing to do is to like

1269
01:01:10,230 --> 01:01:17,699
put your hands in your ears sing a song

1270
01:01:11,849 --> 01:01:19,409
you know and get back to work so that

1271
01:01:17,699 --> 01:01:20,939
thing about it said about dropouts

1272
01:01:19,409 --> 01:01:25,190
patented forget I said that you don't

1273
01:01:20,940 --> 01:01:25,190
you don't know that he's given that bit

1274
01:01:26,840 --> 01:01:35,370
okay this is super fun artistic style

1275
01:01:32,809 --> 01:01:36,750
we're gonna kind of go a bit retro here

1276
01:01:35,369 --> 01:01:40,159
because this is actually the kind of

1277
01:01:36,750 --> 01:01:43,739
original artistic style paper and

1278
01:01:40,159 --> 01:01:45,869
there's been a lot of updates to it a

1279
01:01:43,739 --> 01:01:48,449
lot of different approaches and I

1280
01:01:45,869 --> 01:01:50,849
actually think kind of in many ways the

1281
01:01:48,449 --> 01:01:52,349
original is the best we're going to look

1282
01:01:50,849 --> 01:01:56,460
at some of the newer approaches as well

1283
01:01:52,349 --> 01:01:59,400
that I actually think the original is a

1284
01:01:56,460 --> 01:02:06,630
terrific way to do it even with

1285
01:01:59,400 --> 01:02:08,730
everything that's gone since let's just

1286
01:02:06,630 --> 01:02:15,500
jump to the code so this is the style

1287
01:02:08,730 --> 01:02:20,429
transfer no four so the idea here is

1288
01:02:15,500 --> 01:02:23,010
that we want to take a photo we've got

1289
01:02:20,429 --> 01:02:26,129
to take a photo of this bird and we want

1290
01:02:23,010 --> 01:02:28,820
to create a painting that looks like van

1291
01:02:26,130 --> 01:02:38,340
Gogh painted the picture of the bird

1292
01:02:28,820 --> 01:02:40,170
thank off then go quite a bit of the

1293
01:02:38,340 --> 01:02:42,120
stuff that I'm doing by the way uses an

1294
01:02:40,170 --> 01:02:43,530
image net you don't have to download the

1295
01:02:42,119 --> 01:02:46,109
whole of image net for any of the things

1296
01:02:43,530 --> 01:02:49,050
I'm doing there's an image net sample on

1297
01:02:46,110 --> 01:02:51,240
file start fast today I slash data which

1298
01:02:49,050 --> 01:02:53,130
has like I don't know a couple of gig

1299
01:02:51,239 --> 01:02:55,049
and it should be plenty good enough for

1300
01:02:53,130 --> 01:02:56,340
everything we're doing if you want to

1301
01:02:55,050 --> 01:02:58,500
get really great results you can grab

1302
01:02:56,340 --> 01:03:02,960
image net you can download it from cab

1303
01:02:58,500 --> 01:03:05,340
all the I'm Carol it's the localization

1304
01:03:02,960 --> 01:03:09,199
competition actually contains all of the

1305
01:03:05,340 --> 01:03:09,200
classification data as well

1306
01:03:09,469 --> 01:03:13,829
all right so and you know if you've got

1307
01:03:12,179 --> 01:03:16,710
room it's good to have a copy of

1308
01:03:13,829 --> 01:03:20,400
imagenet because it comes in handy all

1309
01:03:16,710 --> 01:03:22,409
the time so I just grab the bird out of

1310
01:03:20,400 --> 01:03:29,460
my imagenet folder and there is my

1311
01:03:22,409 --> 01:03:33,619
Buddha and so what I'm going to do is

1312
01:03:29,460 --> 01:03:37,679
I'm going to start with this picture and

1313
01:03:33,619 --> 01:03:42,960
I'm going to try and make it more and

1314
01:03:37,679 --> 01:03:46,199
more like a picture of this bird painted

1315
01:03:42,960 --> 01:03:50,490
by Van Gogh and the way I do that is

1316
01:03:46,199 --> 01:03:59,029
actually very simple you're all familiar

1317
01:03:50,489 --> 01:04:03,599
with it we will create a loss function

1318
01:03:59,030 --> 01:04:08,000
which we'll call f yeah and the loss

1319
01:04:03,599 --> 01:04:08,000
function is going to take as input a

1320
01:04:08,119 --> 01:04:18,809
picture and spit out as output a value

1321
01:04:13,440 --> 01:04:25,789
and the value will be lower if the image

1322
01:04:18,809 --> 01:04:31,079
looks more like a the bird photo painted

1323
01:04:25,789 --> 01:04:34,880
by Van Gogh having written that loss

1324
01:04:31,079 --> 01:04:44,039
function we will then use the PI torch

1325
01:04:34,880 --> 01:04:47,070
gradient and optimizers gradient times

1326
01:04:44,039 --> 01:04:50,989
the learning rate and we're not going to

1327
01:04:47,070 --> 01:04:55,890
update any weights we're going to update

1328
01:04:50,989 --> 01:04:59,099
the pixels of the input image to make it

1329
01:04:55,889 --> 01:05:01,799
a little bit more like a picture which

1330
01:04:59,099 --> 01:05:02,849
would be a bird painted by Van Gogh and

1331
01:05:01,800 --> 01:05:06,930
we'll stick it through the loss function

1332
01:05:02,849 --> 01:05:10,130
again to get more gradients and do it

1333
01:05:06,929 --> 01:05:13,710
again and again and that's it so it's

1334
01:05:10,130 --> 01:05:15,599
like identical to how we solve every

1335
01:05:13,710 --> 01:05:19,139
problem like you know I'm a one-trick

1336
01:05:15,599 --> 01:05:21,420
pony right this is my only trick ok tap

1337
01:05:19,139 --> 01:05:23,250
create a loss function use it to get

1338
01:05:21,420 --> 01:05:26,280
some gradients x learning rates

1339
01:05:23,250 --> 01:05:29,730
to update something always before we've

1340
01:05:26,280 --> 01:05:31,320
updated weights in a model but today

1341
01:05:29,730 --> 01:05:35,699
we're not going to do that they're going

1342
01:05:31,320 --> 01:05:37,740
to update that pixels in the input but

1343
01:05:35,699 --> 01:05:39,989
it's no different at all

1344
01:05:37,739 --> 01:05:42,000
all right we're just taking the gradient

1345
01:05:39,989 --> 01:05:47,369
with respect to the input rather than

1346
01:05:42,000 --> 01:05:50,190
respect to the weights okay that's it so

1347
01:05:47,369 --> 01:05:53,009
we're nearly done let's do a couple more

1348
01:05:50,190 --> 01:05:54,750
things let's mention here that there's

1349
01:05:53,010 --> 01:06:00,440
going to be two more inputs to our loss

1350
01:05:54,750 --> 01:06:08,039
function one is the picture of the bird

1351
01:06:00,440 --> 01:06:14,039
birds look like this okay and the second

1352
01:06:08,039 --> 01:06:26,489
is an artwork by Van Gogh they look like

1353
01:06:14,039 --> 01:06:28,259
this oh and of course go okay so and by

1354
01:06:26,489 --> 01:06:30,509
having those as inputs as well that

1355
01:06:28,260 --> 01:06:32,940
means we all be able to rerun the

1356
01:06:30,510 --> 01:06:39,360
function later to make it look like you

1357
01:06:32,940 --> 01:06:41,340
know a bird painted by money or a jumbo

1358
01:06:39,360 --> 01:06:43,230
jet painted by van Gogh or whatever

1359
01:06:41,340 --> 01:06:46,740
right so those are going to be the three

1360
01:06:43,230 --> 01:06:50,010
three inputs and so initially as we

1361
01:06:46,739 --> 01:06:51,179
discussed input here this is going to be

1362
01:06:50,010 --> 01:06:55,820
the first time I've ever found the

1363
01:06:51,179 --> 01:06:59,399
rainbow pen useful there's going to be

1364
01:06:55,820 --> 01:07:02,070
that there's also okay

1365
01:06:59,400 --> 01:07:03,750
some random noise okay so we start with

1366
01:07:02,070 --> 01:07:05,820
some random noise use the loss function

1367
01:07:03,750 --> 01:07:07,380
get the gradients make it a little bit

1368
01:07:05,820 --> 01:07:10,680
more like a bird painted by Van Gogh and

1369
01:07:07,380 --> 01:07:14,340
so forth okay so the only outstanding

1370
01:07:10,679 --> 01:07:17,539
question which you know I guess we can

1371
01:07:14,340 --> 01:07:20,880
talk about briefly is how we calculate

1372
01:07:17,539 --> 01:07:25,529
how much our image looks like a bird

1373
01:07:20,880 --> 01:07:29,130
this bird painted by Van Gogh okay so

1374
01:07:25,530 --> 01:07:34,720
let's split it into two parts let's put

1375
01:07:29,130 --> 01:07:38,318
it into a part called the content loss

1376
01:07:34,719 --> 01:07:44,549
and that's going to return a function a

1377
01:07:38,318 --> 01:07:48,699
value that's lower if it looks more like

1378
01:07:44,550 --> 01:07:55,568
the bird not just any bird the specific

1379
01:07:48,699 --> 01:07:58,598
bird that we have coming in okay and

1380
01:07:55,568 --> 01:08:02,199
then let's also create something called

1381
01:07:58,599 --> 01:08:07,588
the style loss and that's going to be a

1382
01:08:02,199 --> 01:08:22,809
lower number if the the image is more

1383
01:08:07,588 --> 01:08:25,238
like van goths style okay so there's one

1384
01:08:22,810 --> 01:08:28,989
way to do the content loss which is very

1385
01:08:25,238 --> 01:08:31,809
simple we could look at the pixels of

1386
01:08:28,988 --> 01:08:33,608
the output compare them to the pixels of

1387
01:08:31,810 --> 01:08:36,029
the bird and to a mean square error

1388
01:08:33,609 --> 01:08:40,350
addemup

1389
01:08:36,029 --> 01:08:44,020
so if we did that I ran this for a while

1390
01:08:40,350 --> 01:08:46,660
eventually our image would turn into an

1391
01:08:44,020 --> 01:08:49,319
image of the bird you should try it

1392
01:08:46,659 --> 01:08:53,048
right you should try this as an exercise

1393
01:08:49,319 --> 01:08:55,239
try to use the optimizer implied torch

1394
01:08:53,048 --> 01:08:57,698
to start with a random image and turn it

1395
01:08:55,238 --> 01:09:00,759
into another image by using mean squared

1396
01:08:57,698 --> 01:09:06,250
error pixel loss okay not terribly

1397
01:09:00,759 --> 01:09:08,469
exciting but that would be step one the

1398
01:09:06,250 --> 01:09:11,609
problem is even if we already had our

1399
01:09:08,469 --> 01:09:14,469
style loss function working beautifully

1400
01:09:11,609 --> 01:09:17,380
and then presumably what we're going to

1401
01:09:14,469 --> 01:09:21,460
do is we're going to add these two

1402
01:09:17,380 --> 01:09:26,289
together right and then one of them will

1403
01:09:21,460 --> 01:09:28,630
multiplied by some lambda so like adjust

1404
01:09:26,289 --> 01:09:31,448
some number we'll pick to adjust how

1405
01:09:28,630 --> 01:09:33,369
much style versus how much content right

1406
01:09:31,448 --> 01:09:35,559
so assuming we had a style loss or we

1407
01:09:33,369 --> 01:09:38,048
picked some sensible lambda if we use

1408
01:09:35,560 --> 01:09:40,150
two pixel wise content loss then

1409
01:09:38,048 --> 01:09:44,079
anything that makes it look more like

1410
01:09:40,149 --> 01:09:46,778
Van Gogh and less like the exact photo

1411
01:09:44,079 --> 01:09:47,869
the exact background the exact contrast

1412
01:09:46,779 --> 01:09:51,530
lighting everything

1413
01:09:47,869 --> 01:09:53,659
will decrease the content was which is

1414
01:09:51,529 --> 01:09:59,019
not what we want right we wanted to look

1415
01:09:53,659 --> 01:10:01,970
like the bird but not in the same way

1416
01:09:59,020 --> 01:10:03,680
right it's still gonna have the same two

1417
01:10:01,970 --> 01:10:06,770
eyes in the same place and be the same

1418
01:10:03,680 --> 01:10:10,159
kind of shape and so forth but not the

1419
01:10:06,770 --> 01:10:13,340
same representation so what we're going

1420
01:10:10,159 --> 01:10:16,309
to do is this is going to shop here

1421
01:10:13,340 --> 01:10:17,750
we're going to use a neural network all

1422
01:10:16,310 --> 01:10:21,230
right they're going to use a neural

1423
01:10:17,750 --> 01:10:23,539
network I totally meant that to be black

1424
01:10:21,229 --> 01:10:29,059
and a came out green it's always a black

1425
01:10:23,539 --> 01:10:32,510
box ever mind and we're going to use the

1426
01:10:29,060 --> 01:10:34,220
vgg neural network because that's what I

1427
01:10:32,510 --> 01:10:36,079
used last year and I didn't have time to

1428
01:10:34,220 --> 01:10:40,449
see if other things worked so you can

1429
01:10:36,079 --> 01:10:44,269
try that yourself during the week and

1430
01:10:40,449 --> 01:10:48,979
the vgg network is something which takes

1431
01:10:44,270 --> 01:10:53,330
in an input and sticks it through a

1432
01:10:48,979 --> 01:10:54,979
number of layers and I'm just going to

1433
01:10:53,329 --> 01:10:57,680
treat these as just the convolutional

1434
01:10:54,979 --> 01:11:00,379
layers there's obviously value there and

1435
01:10:57,680 --> 01:11:03,829
if it's a bgg with batch norm which most

1436
01:11:00,380 --> 01:11:06,770
are today then it's it's also got better

1437
01:11:03,829 --> 01:11:09,920
on men there's some X pulling and so

1438
01:11:06,770 --> 01:11:14,710
forth but that's fine what we could do

1439
01:11:09,920 --> 01:11:14,710
is we could take one of these

1440
01:11:15,640 --> 01:11:25,039
convolutional activations and then

1441
01:11:19,970 --> 01:11:29,390
rather than comparing the pixels of this

1442
01:11:25,039 --> 01:11:34,310
bird we could instead compare the vgg

1443
01:11:29,390 --> 01:11:36,289
layer five activations of this to the

1444
01:11:34,310 --> 01:11:38,810
vgg layer five activations of our

1445
01:11:36,289 --> 01:11:42,289
original birth or layer six or layer

1446
01:11:38,810 --> 01:11:45,920
seven or whatever so why might that be

1447
01:11:42,289 --> 01:11:47,840
more interesting well for one thing it

1448
01:11:45,920 --> 01:11:49,640
wouldn't be the same bird right it

1449
01:11:47,840 --> 01:11:51,560
wouldn't be exactly the same because

1450
01:11:49,640 --> 01:11:52,970
we're not checking the pixels we're

1451
01:11:51,560 --> 01:11:54,740
checking some later set of activations

1452
01:11:52,970 --> 01:11:57,490
and so what are those latest sets of

1453
01:11:54,739 --> 01:11:59,869
activations contained right well

1454
01:11:57,489 --> 01:12:01,719
assuming that's after some max pooling

1455
01:11:59,869 --> 01:12:04,189
they contain a small agree

1456
01:12:01,719 --> 01:12:06,578
right so it's less specific about where

1457
01:12:04,189 --> 01:12:09,078
things are and rather than containing

1458
01:12:06,578 --> 01:12:11,599
pixel color values they're more like

1459
01:12:09,078 --> 01:12:14,149
semantic things like is this kind of

1460
01:12:11,599 --> 01:12:16,250
like an eyeball or is this kind of furry

1461
01:12:14,149 --> 01:12:17,929
or is this kind of bright or is this

1462
01:12:16,250 --> 01:12:22,639
kind of reflective or is this laying

1463
01:12:17,929 --> 01:12:26,989
flat whatever right so we would hope

1464
01:12:22,639 --> 01:12:29,750
that there's some level kind of semantic

1465
01:12:26,988 --> 01:12:31,848
features through those layers where if

1466
01:12:29,750 --> 01:12:35,420
we get something a picture that that

1467
01:12:31,849 --> 01:12:37,300
matches those activations then any

1468
01:12:35,420 --> 01:12:42,500
picture that matches those activations

1469
01:12:37,300 --> 01:12:43,940
looks like the bird but it's not the

1470
01:12:42,500 --> 01:12:45,948
same representation of the bird

1471
01:12:43,939 --> 01:12:48,399
so that's what we're going to do that's

1472
01:12:45,948 --> 01:12:51,589
what our content loss is going to be and

1473
01:12:48,399 --> 01:12:54,649
people generally call this a perceptual

1474
01:12:51,590 --> 01:12:56,210
loss right which because like it's

1475
01:12:54,649 --> 01:12:58,670
really important in deep learning that

1476
01:12:56,210 --> 01:13:00,618
you always create a new name for every

1477
01:12:58,670 --> 01:13:03,469
obvious thing you do right so if you

1478
01:13:00,618 --> 01:13:08,960
compare two activations together you're

1479
01:13:03,469 --> 01:13:10,340
doing a perceptual was okay so so that's

1480
01:13:08,960 --> 01:13:12,230
it a Content loss is going to be a

1481
01:13:10,340 --> 01:13:14,328
perceptual loss and then we'll do the

1482
01:13:12,229 --> 01:13:19,428
style loss later so let's start by

1483
01:13:14,328 --> 01:13:22,578
trying to create a bird that initially

1484
01:13:19,429 --> 01:13:24,770
is random noise and we're going to use

1485
01:13:22,578 --> 01:13:29,649
perceptual loss to create something that

1486
01:13:24,770 --> 01:13:34,909
is bird-like but it's not this better

1487
01:13:29,649 --> 01:13:37,039
okay so let's start by saying they don't

1488
01:13:34,908 --> 01:13:39,888
do 28 by 288 like we've because pretty

1489
01:13:37,039 --> 01:13:42,529
good to do one bird there's going to be

1490
01:13:39,889 --> 01:13:43,849
no GPU memory problems right so I was

1491
01:13:42,529 --> 01:13:45,469
actually disappointed that I realized

1492
01:13:43,849 --> 01:13:47,690
that I picked a rather small important

1493
01:13:45,469 --> 01:13:49,309
image it'd be fun to try this with

1494
01:13:47,689 --> 01:13:52,819
something much bigger to create a really

1495
01:13:49,309 --> 01:13:54,079
grand scale piece the other thing to

1496
01:13:52,819 --> 01:13:55,578
remember is if you are like production

1497
01:13:54,078 --> 01:14:00,139
izing this you could like do a whole

1498
01:13:55,578 --> 01:14:01,729
batch at a time so people sometimes

1499
01:14:00,139 --> 01:14:03,889
complain about this this approach

1500
01:14:01,729 --> 01:14:06,169
gaddy's is the lead author the gaddy's

1501
01:14:03,889 --> 01:14:08,118
style transfer approaches being slow and

1502
01:14:06,170 --> 01:14:09,679
I don't agree it's low it takes a few

1503
01:14:08,118 --> 01:14:12,789
seconds and you can do a whole batch in

1504
01:14:09,679 --> 01:14:14,840
a few seconds anyway

1505
01:14:12,789 --> 01:14:15,229
so we're going to stick it through some

1506
01:14:14,840 --> 01:14:18,079
trance

1507
01:14:15,229 --> 01:14:23,149
as per usual transforms for vgg 16 model

1508
01:14:18,079 --> 01:14:27,109
and so remember the transform class has

1509
01:14:23,149 --> 01:14:29,899
a dunder call method so we can treat it

1510
01:14:27,109 --> 01:14:33,019
as if it's a function right so if you

1511
01:14:29,899 --> 01:14:35,629
pass an image into that then we get the

1512
01:14:33,020 --> 01:14:38,300
transformed image right so like try not

1513
01:14:35,630 --> 01:14:40,940
to treat the fast AI and ply torch

1514
01:14:38,300 --> 01:14:43,100
infrastructure as a black box because

1515
01:14:40,939 --> 01:14:45,679
like it's all designed to be like really

1516
01:14:43,100 --> 01:14:48,820
easy to use in a decoupled way all right

1517
01:14:45,680 --> 01:14:51,710
so this idea of that transforms are just

1518
01:14:48,819 --> 01:14:53,299
callable x' ie things that you can do

1519
01:14:51,710 --> 01:14:56,359
with parentheses comes from pipe torch

1520
01:14:53,300 --> 01:14:58,760
and we totally plagiarized the idea so

1521
01:14:56,359 --> 01:15:01,849
with with torch vision or with fast AI

1522
01:14:58,760 --> 01:15:03,890
you basically you're transforms are just

1523
01:15:01,850 --> 01:15:06,470
color balls and the whole pipeline of

1524
01:15:03,890 --> 01:15:09,770
transforms is just a callable so now we

1525
01:15:06,470 --> 01:15:11,390
have something of 3 by 2 88 by 2 88

1526
01:15:09,770 --> 01:15:13,250
because PI torch likes the channel to be

1527
01:15:11,390 --> 01:15:15,560
first and as you can see it's been

1528
01:15:13,250 --> 01:15:17,930
turned into a square for us it's being

1529
01:15:15,560 --> 01:15:23,920
normalized to 0 1 or that normal stuff

1530
01:15:17,930 --> 01:15:28,489
ok now we're creating a random image ok

1531
01:15:23,920 --> 01:15:31,159
and here's something I discovered trying

1532
01:15:28,488 --> 01:15:33,619
to turn this into a picture of anything

1533
01:15:31,159 --> 01:15:36,079
it's actually really hard I found it

1534
01:15:33,619 --> 01:15:38,269
very difficult to actually get an

1535
01:15:36,079 --> 01:15:42,109
optimizer to get reasonable gradients

1536
01:15:38,270 --> 01:15:43,310
that went anywhere and just as I thought

1537
01:15:42,109 --> 01:15:45,019
I was going to run out of time for this

1538
01:15:43,310 --> 01:15:49,850
class and really embarrassed myself I

1539
01:15:45,020 --> 01:15:52,880
realized the key issue is that pictures

1540
01:15:49,850 --> 01:15:57,289
don't look like this they have more

1541
01:15:52,880 --> 01:15:59,630
smoothness so I turned this into this by

1542
01:15:57,289 --> 01:16:01,789
just kind of blurring it a little bit I

1543
01:15:59,630 --> 01:16:06,590
used a median filter that basically it's

1544
01:16:01,789 --> 01:16:09,319
like a like a median pooling effectively

1545
01:16:06,590 --> 01:16:10,880
right and as soon as I change it from

1546
01:16:09,319 --> 01:16:13,359
this to this it immediately started

1547
01:16:10,880 --> 01:16:15,619
training really well ok so it's like a

1548
01:16:13,359 --> 01:16:17,119
number of little tweaks you have to do

1549
01:16:15,619 --> 01:16:19,970
to get these things to work is kind of

1550
01:16:17,119 --> 01:16:24,199
insane but there's that here is a little

1551
01:16:19,970 --> 01:16:28,480
booty alright so we start with a random

1552
01:16:24,199 --> 01:16:28,479
image which is at least somewhat smooth

1553
01:16:29,479 --> 01:16:37,429
okay and I found that my bird image had

1554
01:16:35,359 --> 01:16:38,929
a standard deviation of pixels that was

1555
01:16:37,430 --> 01:16:41,270
about half of this

1556
01:16:38,930 --> 01:16:42,890
so I mean about half of this mean so I

1557
01:16:41,270 --> 01:16:44,570
divided it by two just trying to make it

1558
01:16:42,890 --> 01:16:47,150
a little bit easier for it to match I

1559
01:16:44,569 --> 01:16:49,670
don't know if it matters turn that into

1560
01:16:47,149 --> 01:16:52,460
a variable because this image remember

1561
01:16:49,670 --> 01:16:55,250
we're going to be modifying those pixels

1562
01:16:52,460 --> 01:16:57,109
with an optimization algorithm so

1563
01:16:55,250 --> 01:16:59,119
anything that involved in the loss

1564
01:16:57,109 --> 01:17:00,889
function needs to be a variable and

1565
01:16:59,119 --> 01:17:02,750
specifically it requires a gradient

1566
01:17:00,890 --> 01:17:08,210
because we're actually updating the

1567
01:17:02,750 --> 01:17:10,939
image okay all right so we now have a

1568
01:17:08,210 --> 01:17:17,960
mini batch of one three channels 288 by

1569
01:17:10,939 --> 01:17:20,539
288 random noise we're going to use for

1570
01:17:17,960 --> 01:17:24,050
no particular reason the thirty-seventh

1571
01:17:20,539 --> 01:17:25,310
layer of vgg if you print out the vgg

1572
01:17:24,050 --> 01:17:26,750
Network you can just type in their

1573
01:17:25,310 --> 01:17:29,120
member score vgg and prints it out

1574
01:17:26,750 --> 01:17:33,739
you'll see that this is a you know kind

1575
01:17:29,119 --> 01:17:37,760
of mid to late stage layer so we can

1576
01:17:33,739 --> 01:17:39,380
just grab the first 37 layers and turn

1577
01:17:37,760 --> 01:17:41,600
it into a sequential model and so now

1578
01:17:39,380 --> 01:17:45,470
we've got a subset of heg that will spit

1579
01:17:41,600 --> 01:17:47,570
out some mid layer activations and so

1580
01:17:45,470 --> 01:17:52,430
that's that's what the models going to

1581
01:17:47,569 --> 01:17:55,219
be so we can take our actual bird image

1582
01:17:52,430 --> 01:17:59,630
right and we want to create a mini batch

1583
01:17:55,220 --> 01:18:04,730
of one so remember if you slice in numpy

1584
01:17:59,630 --> 01:18:09,500
with none also known as NP you axis it

1585
01:18:04,729 --> 01:18:12,439
introduces a new unit axis in that point

1586
01:18:09,500 --> 01:18:14,569
so in here I want to create an axis of

1587
01:18:12,439 --> 01:18:16,819
size one to say this is a mini batch of

1588
01:18:14,569 --> 01:18:18,949
size one alright so slicing with none

1589
01:18:16,819 --> 01:18:22,399
just like I did here has sliced with

1590
01:18:18,949 --> 01:18:25,159
none to get this one's one unit axis at

1591
01:18:22,399 --> 01:18:28,969
the front okay sis so then we turn that

1592
01:18:25,159 --> 01:18:30,800
into a variable and this one doesn't

1593
01:18:28,970 --> 01:18:33,289
need to write big be updated so it's we

1594
01:18:30,800 --> 01:18:38,210
use DV to say you don't need gradients

1595
01:18:33,289 --> 01:18:41,750
for this guy and so that's going to give

1596
01:18:38,210 --> 01:18:44,149
us our our target activations

1597
01:18:41,750 --> 01:18:48,050
okay so we've basically taken our bird

1598
01:18:44,149 --> 01:18:50,750
image turn it into a variable stuck it

1599
01:18:48,050 --> 01:18:53,180
through our model to grab the thirty

1600
01:18:50,750 --> 01:18:55,880
seventh layer activations and that's our

1601
01:18:53,180 --> 01:19:00,400
target right is that we want our content

1602
01:18:55,880 --> 01:19:00,400
loss to be this set of activations here

1603
01:19:00,550 --> 01:19:04,430
so then we're going to create an

1604
01:19:02,270 --> 01:19:05,630
optimizer we'll go back to the details

1605
01:19:04,430 --> 01:19:08,890
of this in a moment but we're going to

1606
01:19:05,630 --> 01:19:12,590
create an optimizer and we're going to

1607
01:19:08,890 --> 01:19:16,250
step a bunch of times going 0 the

1608
01:19:12,590 --> 01:19:18,100
gradients call some loss function loss

1609
01:19:16,250 --> 01:19:26,960
top backward

1610
01:19:18,100 --> 01:19:28,070
no so that's the high-level version and

1611
01:19:26,960 --> 01:19:30,529
I'm going to come back to the details in

1612
01:19:28,069 --> 01:19:33,069
a moment but the key thing is that the

1613
01:19:30,529 --> 01:19:35,630
loss function we're passing in that

1614
01:19:33,069 --> 01:19:37,670
randomly generated image the

1615
01:19:35,630 --> 01:19:40,069
optimization image or actually the

1616
01:19:37,670 --> 01:19:44,300
variable of it right so we passed that

1617
01:19:40,069 --> 01:19:46,399
to our loss function and so it's going

1618
01:19:44,300 --> 01:19:49,010
to update this using the loss function

1619
01:19:46,399 --> 01:19:52,969
and the loss function is the mean

1620
01:19:49,010 --> 01:19:55,159
squared error loss comparing our current

1621
01:19:52,970 --> 01:19:57,619
optimization image passed through our

1622
01:19:55,159 --> 01:19:59,449
vgg to get the intermediate activations

1623
01:19:57,619 --> 01:20:02,859
and comparing it to our target

1624
01:19:59,449 --> 01:20:05,329
activations okay just like we discussed

1625
01:20:02,859 --> 01:20:10,549
okay and we'll run that a bunch of times

1626
01:20:05,329 --> 01:20:13,100
and we'll print it out and we have our

1627
01:20:10,550 --> 01:20:19,520
bird but not the representation of the

1628
01:20:13,100 --> 01:20:25,300
boat okay so there it is so a couple of

1629
01:20:19,520 --> 01:20:31,700
new details here one is we had optimizer

1630
01:20:25,300 --> 01:20:33,230
lb-ft yes anybody who's done I don't

1631
01:20:31,699 --> 01:20:34,849
know exactly what courses they're in but

1632
01:20:33,229 --> 01:20:39,159
certain parts of math and computer

1633
01:20:34,850 --> 01:20:41,300
science courses comes into deep learning

1634
01:20:39,159 --> 01:20:46,130
discovers we use all this stuff like

1635
01:20:41,300 --> 01:20:47,960
Adam and the SGD and always assume that

1636
01:20:46,130 --> 01:20:49,310
nobody in the field knows the first

1637
01:20:47,960 --> 01:20:51,319
thing about computer science and

1638
01:20:49,310 --> 01:20:55,100
immediately says oh of any of you guys

1639
01:20:51,319 --> 01:20:57,469
tried using the FDS

1640
01:20:55,100 --> 01:20:59,930
there's basically a long history of a

1641
01:20:57,470 --> 01:21:02,240
totally different kind of algorithm for

1642
01:20:59,930 --> 01:21:04,190
optimization that we don't use to train

1643
01:21:02,239 --> 01:21:05,719
neural networks and of course the answer

1644
01:21:04,189 --> 01:21:07,819
is actually the people who have spent

1645
01:21:05,720 --> 01:21:09,140
decades studying neural networks do know

1646
01:21:07,819 --> 01:21:11,119
a thing or two about computer science

1647
01:21:09,140 --> 01:21:13,490
and it turns out these techniques on the

1648
01:21:11,119 --> 01:21:15,019
whole don't work very well but it's

1649
01:21:13,489 --> 01:21:16,880
actually going to work well for this and

1650
01:21:15,020 --> 01:21:18,890
it's a good opportunity to talk about an

1651
01:21:16,880 --> 01:21:22,100
interesting algorithm for those of you

1652
01:21:18,890 --> 01:21:27,650
that haven't studied this type of

1653
01:21:22,100 --> 01:21:33,530
optimization algorithm at school so BFGS

1654
01:21:27,649 --> 01:21:35,659
is one of the names Broyden favor I

1655
01:21:33,529 --> 01:21:36,199
can't remember anyway initials are for

1656
01:21:35,659 --> 01:21:39,079
different people

1657
01:21:36,199 --> 01:21:40,869
at the L stands for limited memory so

1658
01:21:39,079 --> 01:21:44,090
it's really just quote VFDs

1659
01:21:40,869 --> 01:21:46,939
limited memory BFGS and it's an

1660
01:21:44,090 --> 01:21:49,100
optimizer so as an optimizer that means

1661
01:21:46,939 --> 01:21:51,649
that there's some loss function and it's

1662
01:21:49,100 --> 01:21:53,270
going to use some gradients to I mean

1663
01:21:51,649 --> 01:21:54,259
not all optimizes use gradients but all

1664
01:21:53,270 --> 01:21:56,030
the ones we use do

1665
01:21:54,260 --> 01:21:59,210
here's gradients to find a direction to

1666
01:21:56,029 --> 01:22:01,460
go and try to make the loss function go

1667
01:21:59,210 --> 01:22:04,840
lower and lower by adjusting some

1668
01:22:01,460 --> 01:22:07,159
parameters yeah this just an optimizer

1669
01:22:04,840 --> 01:22:09,020
but it's an interesting kind of

1670
01:22:07,159 --> 01:22:11,569
optimizer because it does a bit more

1671
01:22:09,020 --> 01:22:15,880
work than the ones we're used to on each

1672
01:22:11,569 --> 01:22:15,880
step and so specifically

1673
01:22:21,760 --> 01:22:40,090
okay Facebook okay so the way it works

1674
01:22:38,350 --> 01:22:41,380
is it starts the same way that we used

1675
01:22:40,090 --> 01:22:44,529
to which is we just kind of pick

1676
01:22:41,380 --> 01:22:46,690
somewhere to get started and in this

1677
01:22:44,529 --> 01:22:51,849
case we've picked like a random image as

1678
01:22:46,689 --> 01:23:00,849
we saw and as per usual we we calculate

1679
01:22:51,850 --> 01:23:04,210
the gradient but we then don't just take

1680
01:23:00,850 --> 01:23:06,610
a step but what we actually do is as

1681
01:23:04,210 --> 01:23:08,800
well as finding the gradient we also try

1682
01:23:06,609 --> 01:23:10,988
to find the second derivative so the

1683
01:23:08,800 --> 01:23:13,300
direct second derivative says how fast

1684
01:23:10,988 --> 01:23:15,009
is the gradient change so the gradient

1685
01:23:13,300 --> 01:23:16,239
is how fast of the function change the

1686
01:23:15,010 --> 01:23:17,980
second derivative is how fast as a

1687
01:23:16,238 --> 01:23:21,419
gradient change in other words how curvy

1688
01:23:17,979 --> 01:23:25,929
is it right and the basic idea is that

1689
01:23:21,420 --> 01:23:30,720
if you know that it's like not very

1690
01:23:25,930 --> 01:23:33,820
curvy then you can probably jump further

1691
01:23:30,720 --> 01:23:37,180
but if it's very curvy then you probably

1692
01:23:33,819 --> 01:23:38,889
don't want to jump as far and so in in

1693
01:23:37,180 --> 01:23:40,869
higher dimensions the gradients called

1694
01:23:38,890 --> 01:23:42,489
the Jacobian and the second derivative

1695
01:23:40,869 --> 01:23:44,500
is called the Hessian you'll see those

1696
01:23:42,488 --> 01:23:47,019
words all the time that that's what they

1697
01:23:44,500 --> 01:23:48,729
mean okay again mathematicians have to

1698
01:23:47,020 --> 01:23:49,840
invent your words for everything as well

1699
01:23:48,729 --> 01:23:52,959
they're just like deep learning

1700
01:23:49,840 --> 01:24:00,489
researchers so it may be a bit more

1701
01:23:52,960 --> 01:24:03,310
snooty so with BFGS we're going to try

1702
01:24:00,488 --> 01:24:05,319
and calculate the second derivative and

1703
01:24:03,310 --> 01:24:09,489
then we're going to use that to figure

1704
01:24:05,319 --> 01:24:11,710
out kind of what direction to go and and

1705
01:24:09,488 --> 01:24:15,209
how far to go all right so it's less of

1706
01:24:11,710 --> 01:24:15,210
a kind of a wild jump into the unknown

1707
01:24:15,329 --> 01:24:19,809
now the problem is that actually

1708
01:24:17,350 --> 01:24:22,840
calculating the hessian the second

1709
01:24:19,810 --> 01:24:25,570
derivative is almost certainly not a

1710
01:24:22,840 --> 01:24:28,239
good idea because in each possible

1711
01:24:25,569 --> 01:24:29,500
direction that you can add for each

1712
01:24:28,238 --> 01:24:32,289
direction that you're measuring the

1713
01:24:29,500 --> 01:24:34,170
gradient in you also have to calculate

1714
01:24:32,289 --> 01:24:38,670
the hessian in every

1715
01:24:34,170 --> 01:24:41,760
direction it gets ridiculously big so

1716
01:24:38,670 --> 01:24:44,730
rather than actually calculating it we

1717
01:24:41,760 --> 01:24:47,850
take a few steps and we basically look

1718
01:24:44,729 --> 01:24:50,309
at how much the gradients changing as we

1719
01:24:47,850 --> 01:24:53,910
do each step and we approximate the

1720
01:24:50,310 --> 01:24:58,920
Hessian using that little function right

1721
01:24:53,909 --> 01:25:00,539
and again this seems like a really

1722
01:24:58,920 --> 01:25:02,550
obvious thing to do but nobody thought

1723
01:25:00,539 --> 01:25:05,729
of it until someone well surprisingly a

1724
01:25:02,550 --> 01:25:08,100
long time later keeping track of every

1725
01:25:05,729 --> 01:25:12,569
single step you take takes a lot of

1726
01:25:08,100 --> 01:25:14,489
memory so duh don't keep track of every

1727
01:25:12,569 --> 01:25:17,488
step you take just keep the last ten or

1728
01:25:14,488 --> 01:25:20,909
twenty and the second bit there that's

1729
01:25:17,488 --> 01:25:24,319
the L to the l-bfgs so a limited memory

1730
01:25:20,909 --> 01:25:28,109
BFGS means keep the last ten or 20

1731
01:25:24,319 --> 01:25:30,119
gradients use that to approximate the

1732
01:25:28,109 --> 01:25:32,399
amount of curvature and then use the

1733
01:25:30,119 --> 01:25:35,869
curvature in gradient to estimate what

1734
01:25:32,399 --> 01:25:35,869
direction to travel and how far

1735
01:25:36,590 --> 01:25:41,900
and so that's normally not a good idea

1736
01:25:40,020 --> 01:25:44,340
in deep learning for a number of reasons

1737
01:25:41,899 --> 01:25:48,109
you know it's obviously more work to do

1738
01:25:44,340 --> 01:25:51,510
than a kind of an atom or an SGD update

1739
01:25:48,109 --> 01:25:54,329
number Z more memory memory is much more

1740
01:25:51,510 --> 01:25:55,619
of a big issue when you've got a GPU to

1741
01:25:54,329 --> 01:25:58,469
store it on an hundreds of millions of

1742
01:25:55,619 --> 01:26:01,439
weights but more importantly the

1743
01:25:58,469 --> 01:26:03,630
mini-batches super bumpy so figuring out

1744
01:26:01,439 --> 01:26:07,169
like curvature decide exactly how far to

1745
01:26:03,630 --> 01:26:08,850
travel is kind of polishing turds as we

1746
01:26:07,170 --> 01:26:11,850
say is that an American expression or

1747
01:26:08,850 --> 01:26:14,100
just an Australian Australian thing a

1748
01:26:11,850 --> 01:26:15,000
bit English there to do in a certain

1749
01:26:14,100 --> 01:26:17,429
sense yeah obviously

1750
01:26:15,000 --> 01:26:21,380
yeah oh yeah yeah polishing turns you

1751
01:26:17,429 --> 01:26:23,760
get the idea and also interestingly

1752
01:26:21,380 --> 01:26:26,670
actually take using the second

1753
01:26:23,760 --> 01:26:29,190
derivative information it turns out is

1754
01:26:26,670 --> 01:26:30,329
like a magnet for saddle points so

1755
01:26:29,189 --> 01:26:32,750
there's some interesting theoretical

1756
01:26:30,329 --> 01:26:36,238
results that basically say it's actually

1757
01:26:32,750 --> 01:26:38,219
sends you towards nasty flat areas of

1758
01:26:36,238 --> 01:26:39,869
the function if you use second

1759
01:26:38,219 --> 01:26:41,760
derivative information so normally not a

1760
01:26:39,869 --> 01:26:43,590
good idea but in this case we're not

1761
01:26:41,760 --> 01:26:46,310
optimising weights we're optimizing

1762
01:26:43,590 --> 01:26:47,828
pixels so all the rules change and

1763
01:26:46,310 --> 01:26:51,880
actually turns

1764
01:26:47,828 --> 01:26:53,769
our BFGS does make sense and because it

1765
01:26:51,880 --> 01:26:55,059
does more work each time you know it's a

1766
01:26:53,770 --> 01:26:57,010
kind of a different kind of optimizer

1767
01:26:55,059 --> 01:26:59,500
the API is a little bit different in

1768
01:26:57,010 --> 01:27:02,199
plight watch as you can see here when

1769
01:26:59,500 --> 01:27:06,219
you say optimizer dot step you actually

1770
01:27:02,198 --> 01:27:10,808
pass in the loss function okay

1771
01:27:06,219 --> 01:27:14,050
and so my log so my loss function is to

1772
01:27:10,809 --> 01:27:15,880
call step with a particular loss

1773
01:27:14,050 --> 01:27:18,219
function which is my activation loss

1774
01:27:15,880 --> 01:27:19,929
right and as you can see you don't so

1775
01:27:18,219 --> 01:27:22,448
you don't inside the loop you don't say

1776
01:27:19,929 --> 01:27:24,420
step step-step right but rather it looks

1777
01:27:22,448 --> 01:27:27,729
like this so it's a little bit different

1778
01:27:24,420 --> 01:27:30,520
and you're welcome to try and rewrite

1779
01:27:27,729 --> 01:27:32,408
this to use SGD it'll still work it'll

1780
01:27:30,520 --> 01:27:33,969
just take a bit longer I haven't tried

1781
01:27:32,408 --> 01:27:39,789
it with SGD I'd be interested to know

1782
01:27:33,969 --> 01:27:41,889
how much longer it takes okay so you can

1783
01:27:39,789 --> 01:27:45,639
see the loss function going down the

1784
01:27:41,889 --> 01:27:50,380
mean squared error between the you know

1785
01:27:45,639 --> 01:27:54,099
activations at layer 37 of our vgg model

1786
01:27:50,380 --> 01:27:56,078
for our optimized image versus the

1787
01:27:54,099 --> 01:27:59,349
target activations and remember the

1788
01:27:56,078 --> 01:28:02,590
target activations were the vgg applied

1789
01:27:59,349 --> 01:28:12,250
to our Albert so make sense right so

1790
01:28:02,590 --> 01:28:14,770
we've okay so we've now got a Content

1791
01:28:12,250 --> 01:28:18,219
loss now one thing I'll say about this

1792
01:28:14,770 --> 01:28:21,730
content loss is we don't know which

1793
01:28:18,219 --> 01:28:23,800
layer it's going to work best so it'd be

1794
01:28:21,729 --> 01:28:25,209
nice if we were able to experiment a

1795
01:28:23,800 --> 01:28:27,579
little bit more and the way it is here

1796
01:28:25,210 --> 01:28:32,309
is annoying maybe we even want to use

1797
01:28:27,578 --> 01:28:35,380
multiple layers okay so rather than like

1798
01:28:32,309 --> 01:28:37,840
lopping off all of the layers are for

1799
01:28:35,380 --> 01:28:40,239
the one we want wouldn't it be nice if

1800
01:28:37,840 --> 01:28:43,270
we could somehow like grab the

1801
01:28:40,238 --> 01:28:46,388
activations of a few layers as it

1802
01:28:43,270 --> 01:28:50,710
calculates now we already know one way

1803
01:28:46,389 --> 01:28:54,250
to do that back when we did SSD we

1804
01:28:50,710 --> 01:28:56,529
actually wrote our own network which had

1805
01:28:54,250 --> 01:28:58,270
a number of outputs remember like the

1806
01:28:56,529 --> 01:29:00,149
different convolutional layers we spat

1807
01:28:58,270 --> 01:29:03,540
out a different like icon

1808
01:29:00,149 --> 01:29:07,079
thing but I don't really want to go and

1809
01:29:03,539 --> 01:29:09,300
like add that to the torch vision ResNet

1810
01:29:07,079 --> 01:29:10,979
model especially not if like later on I

1811
01:29:09,300 --> 01:29:12,929
want to try you know then I want to try

1812
01:29:10,979 --> 01:29:14,849
the torch vision vgg model and then I

1813
01:29:12,929 --> 01:29:16,829
want to try an S and at a model I don't

1814
01:29:14,850 --> 01:29:19,679
to go into all of them and like change

1815
01:29:16,829 --> 01:29:21,269
their outputs right besides which I'd

1816
01:29:19,679 --> 01:29:24,960
like to easily be able to turn certain

1817
01:29:21,270 --> 01:29:27,989
activations on and off with demand so we

1818
01:29:24,960 --> 01:29:29,609
briefly touched before this idea that PI

1819
01:29:27,988 --> 01:29:32,789
torch has these fantastic things called

1820
01:29:29,609 --> 01:29:35,069
hooks you can have forward Hawks that

1821
01:29:32,789 --> 01:29:38,550
let you plug anything you like into the

1822
01:29:35,069 --> 01:29:40,259
forward path of a calculation or a

1823
01:29:38,550 --> 01:29:42,140
backward walk so that's you plug

1824
01:29:40,260 --> 01:29:45,360
anything you like into the backward pass

1825
01:29:42,140 --> 01:29:48,150
so we're going to create the world's

1826
01:29:45,359 --> 01:29:50,279
simplest forward hook and this is one of

1827
01:29:48,149 --> 01:29:52,500
these things that like almost nobody

1828
01:29:50,279 --> 01:29:56,359
knows about so like almost any code you

1829
01:29:52,500 --> 01:30:00,600
find on the internet that implements

1830
01:29:56,359 --> 01:30:02,698
style transfer will have all kinds of

1831
01:30:00,600 --> 01:30:04,079
horrible hacks rather than using forward

1832
01:30:02,698 --> 01:30:06,960
walks but with four books it's really

1833
01:30:04,079 --> 01:30:09,800
easy so to create a forward hook you

1834
01:30:06,960 --> 01:30:12,719
just create a class right and the class

1835
01:30:09,800 --> 01:30:16,469
has to have something called hook

1836
01:30:12,719 --> 01:30:19,408
function okay and your hook function is

1837
01:30:16,469 --> 01:30:22,050
going to receive the module that you've

1838
01:30:19,408 --> 01:30:24,029
hooked it's going to receive the input

1839
01:30:22,050 --> 01:30:26,039
for the forward pass and it's going to

1840
01:30:24,029 --> 01:30:28,380
receive the target and then you do

1841
01:30:26,039 --> 01:30:30,529
whatever the hell you like so what I'm

1842
01:30:28,380 --> 01:30:36,810
going to do is I'm just going to store

1843
01:30:30,529 --> 01:30:43,019
the output of this module in some

1844
01:30:36,810 --> 01:30:44,400
attribute that's it all right so this

1845
01:30:43,020 --> 01:30:45,719
can actually be called anything you like

1846
01:30:44,399 --> 01:30:47,250
but hook function seems to be the

1847
01:30:45,719 --> 01:30:49,739
standard because you can see what

1848
01:30:47,250 --> 01:30:52,260
happens here in the constructor is I

1849
01:30:49,738 --> 01:30:54,448
store inside some attribute the result

1850
01:30:52,260 --> 01:30:57,719
of this is going to be the layer that

1851
01:30:54,448 --> 01:31:01,349
I'm gonna hook you go module register

1852
01:30:57,719 --> 01:31:04,079
forward hook and pass in the function

1853
01:31:01,350 --> 01:31:06,870
that you want to be called when this

1854
01:31:04,079 --> 01:31:08,760
module when it's when it's forward

1855
01:31:06,869 --> 01:31:11,429
method is called so when it's forward

1856
01:31:08,760 --> 01:31:12,389
method is called it will call self dot

1857
01:31:11,429 --> 01:31:16,050
hook function

1858
01:31:12,389 --> 01:31:23,760
which will store the output in an

1859
01:31:16,050 --> 01:31:27,300
attribute cord features okay so now what

1860
01:31:23,760 --> 01:31:31,170
we can do is we can create a vgg as

1861
01:31:27,300 --> 01:31:33,630
before right and let's set it to not

1862
01:31:31,170 --> 01:31:35,880
trainable so we don't waste time and

1863
01:31:33,630 --> 01:31:39,179
memory calculating gradients for it and

1864
01:31:35,880 --> 01:31:41,880
let's go through and find out let's find

1865
01:31:39,179 --> 01:31:43,319
all of the max pool layers alright so

1866
01:31:41,880 --> 01:31:47,090
let's go through all of the children of

1867
01:31:43,319 --> 01:31:51,329
this module and if it's a max pool layer

1868
01:31:47,090 --> 01:31:53,159
let's spit out index minus one so that's

1869
01:31:51,329 --> 01:31:55,109
going to give me the layer before the

1870
01:31:53,158 --> 01:31:57,238
map sport and so in general the layer

1871
01:31:55,109 --> 01:31:59,549
before and that's pool or the layer

1872
01:31:57,238 --> 01:32:02,250
before us dry to cons is a very

1873
01:31:59,550 --> 01:32:06,329
interesting layer but because it's like

1874
01:32:02,250 --> 01:32:09,029
it's the most you know complete

1875
01:32:06,329 --> 01:32:11,550
representation we have at that grid cell

1876
01:32:09,029 --> 01:32:14,969
size back because the very next layer is

1877
01:32:11,550 --> 01:32:18,539
changing the grid okay so that seems to

1878
01:32:14,969 --> 01:32:21,118
me like a good place to grab the for

1879
01:32:18,539 --> 01:32:23,519
content loss from is you know the best

1880
01:32:21,118 --> 01:32:26,429
most semantic most interesting content

1881
01:32:23,520 --> 01:32:29,719
we have at that grid size so that's why

1882
01:32:26,429 --> 01:32:33,090
I'm going to pick those indexes so Helia

1883
01:32:29,719 --> 01:32:38,819
those are the indexes of the last layer

1884
01:32:33,090 --> 01:32:41,969
before each max poor in vgg so I'm going

1885
01:32:38,819 --> 01:32:43,349
to grab this one here 22 just no

1886
01:32:41,969 --> 01:32:46,739
particular reason just to try something

1887
01:32:43,350 --> 01:32:48,840
else so I'm going to say sorry this one

1888
01:32:46,738 --> 01:32:53,939
here 32 so I'm going to say block ends 3

1889
01:32:48,840 --> 01:32:57,719
that's maybe 32 so children vgg indexed

1890
01:32:53,939 --> 01:33:01,049
to block ends 3 will give me the 30

1891
01:32:57,719 --> 01:33:04,139
second layer of vgg as a as a module

1892
01:33:01,050 --> 01:33:06,840
right and then if I call the save

1893
01:33:04,139 --> 01:33:10,170
features constructor it's going to go

1894
01:33:06,840 --> 01:33:13,260
self cork equals 30 second layer of the

1895
01:33:10,170 --> 01:33:16,319
GG register forward hook hook function

1896
01:33:13,260 --> 01:33:18,810
ok so now every time I do a forward pass

1897
01:33:16,319 --> 01:33:24,808
on this bjg model it's going to store

1898
01:33:18,810 --> 01:33:34,469
the 30 second layers output inside

1899
01:33:24,809 --> 01:33:36,809
sf dot features so we can now say see

1900
01:33:34,469 --> 01:33:38,730
here I'm calling my vgg Network but I'm

1901
01:33:36,809 --> 01:33:42,270
not strong it anywhere I'm not saying

1902
01:33:38,729 --> 01:33:46,109
you know activations equals vgg of my

1903
01:33:42,270 --> 01:33:50,309
image I'm calling it throwing away the

1904
01:33:46,109 --> 01:33:54,808
answer and then grabbing the features

1905
01:33:50,309 --> 01:33:57,779
that we stored in our SF in our safe

1906
01:33:54,809 --> 01:34:00,150
features object right so that way this

1907
01:33:57,779 --> 01:34:02,219
is now going to contain one so like I've

1908
01:34:00,149 --> 01:34:03,929
done if this is a forward plus now

1909
01:34:02,219 --> 01:34:06,149
that's how you do a forward pass and ply

1910
01:34:03,929 --> 01:34:08,038
torch you don't say dot forward you just

1911
01:34:06,149 --> 01:34:10,019
use it as a callable and using as a

1912
01:34:08,038 --> 01:34:12,630
callable on an NN dot module

1913
01:34:10,020 --> 01:34:16,469
automatically calls forward that's how

1914
01:34:12,630 --> 01:34:18,779
plat watch modules what okay so we call

1915
01:34:16,469 --> 01:34:20,578
it as a koala ball that ends up calling

1916
01:34:18,779 --> 01:34:23,340
our forward hook that forward hook

1917
01:34:20,578 --> 01:34:27,000
stores the activations in SF dot

1918
01:34:23,340 --> 01:34:29,610
features and so now we have our target

1919
01:34:27,000 --> 01:34:35,520
variable just like before but in a much

1920
01:34:29,609 --> 01:34:37,170
more flexible way these are the same

1921
01:34:35,520 --> 01:34:39,179
four lines of code we had earlier I've

1922
01:34:37,170 --> 01:34:41,489
just stuck them into a function okay and

1923
01:34:39,179 --> 01:34:44,340
so it's just giving me my popped up my

1924
01:34:41,488 --> 01:34:46,859
random image to optimize and an

1925
01:34:44,340 --> 01:34:48,809
optimizer to optimize that image this is

1926
01:34:46,859 --> 01:34:51,269
exactly the same code as before so that

1927
01:34:48,809 --> 01:34:54,599
gives me these and so now I can go ahead

1928
01:34:51,270 --> 01:34:55,650
and do exactly the same thing right but

1929
01:34:54,599 --> 01:34:58,849
now I'm going to use a different loss

1930
01:34:55,649 --> 01:35:03,118
function activation lost number two

1931
01:34:58,849 --> 01:35:04,920
which doesn't say out equals mV GG again

1932
01:35:03,118 --> 01:35:09,210
the calls MV chuchita to a forward pass

1933
01:35:04,920 --> 01:35:13,618
throws away the results and grabs SF top

1934
01:35:09,210 --> 01:35:15,840
features okay and so that's now my 30

1935
01:35:13,618 --> 01:35:19,738
second layer activations which I can

1936
01:35:15,840 --> 01:35:21,480
then do my MSA loss on you might have

1937
01:35:19,738 --> 01:35:23,669
noticed the last time the last loss

1938
01:35:21,479 --> 01:35:25,649
function in this one both multiplied by

1939
01:35:23,670 --> 01:35:28,020
a thousand why are they multiplied by a

1940
01:35:25,649 --> 01:35:29,038
thousand again this was like all the

1941
01:35:28,020 --> 01:35:32,070
things that were trying to get this

1942
01:35:29,038 --> 01:35:33,359
lesson to not work correctly I didn't

1943
01:35:32,069 --> 01:35:36,448
used to have the a thousand yeah it

1944
01:35:33,359 --> 01:35:38,170
wasn't training by lunchtime today

1945
01:35:36,448 --> 01:35:40,269
nothing was working

1946
01:35:38,170 --> 01:35:45,250
after days of trying to get this thing

1947
01:35:40,270 --> 01:35:48,130
to work and finally kind of just

1948
01:35:45,250 --> 01:35:50,199
randomly noticed like gosh the last

1949
01:35:48,130 --> 01:35:54,100
functions like the numbers are really

1950
01:35:50,199 --> 01:35:54,880
low you know like 10 e neg 7 and I just

1951
01:35:54,100 --> 01:35:57,039
kind of thought well what if they

1952
01:35:54,880 --> 01:35:59,800
weren't so low so I multiplied them by a

1953
01:35:57,039 --> 01:36:01,899
thousand and instead of working so why

1954
01:35:59,800 --> 01:36:03,970
did it not work because we're doing

1955
01:36:01,899 --> 01:36:05,139
single precision floating point right

1956
01:36:03,970 --> 01:36:08,079
and single precision floating point

1957
01:36:05,140 --> 01:36:09,340
ain't that precise and particularly once

1958
01:36:08,079 --> 01:36:10,479
you're kind of getting gradients that

1959
01:36:09,340 --> 01:36:11,980
are kind of small and then you're

1960
01:36:10,479 --> 01:36:13,569
multiplying around the learning rate can

1961
01:36:11,979 --> 01:36:16,389
be kind of small and you end up with a

1962
01:36:13,569 --> 01:36:18,130
small number and if it's so small they

1963
01:36:16,390 --> 01:36:20,079
could get rounded to zero and that's

1964
01:36:18,130 --> 01:36:23,590
what was happening and my model wasn't

1965
01:36:20,079 --> 01:36:25,409
ready okay so I'm sure there are better

1966
01:36:23,590 --> 01:36:28,300
ways I'm multiplying by a thousand

1967
01:36:25,409 --> 01:36:29,829
whatever it works fine like it doesn't

1968
01:36:28,300 --> 01:36:31,869
matter what you multiply a loss function

1969
01:36:29,829 --> 01:36:36,059
by because all you care about is its is

1970
01:36:31,869 --> 01:36:36,059
its direction it's relative size right

1971
01:36:36,600 --> 01:36:40,870
and interestingly like this is actually

1972
01:36:38,949 --> 01:36:42,639
something similar we do for when we were

1973
01:36:40,869 --> 01:36:44,859
training imagenet we were using half

1974
01:36:42,640 --> 01:36:47,350
precision floating point because the

1975
01:36:44,859 --> 01:36:50,559
Volta tents of course require that and

1976
01:36:47,350 --> 01:36:53,530
it's actually a standard practice if you

1977
01:36:50,560 --> 01:36:55,150
want to get the half precision floating

1978
01:36:53,529 --> 01:36:57,639
point to Train you actually have to

1979
01:36:55,149 --> 01:37:00,279
multiply the loss function by a scaling

1980
01:36:57,640 --> 01:37:03,420
factor and we were using a thousand and

1981
01:37:00,279 --> 01:37:06,729
twenty four or five twelve and I think

1982
01:37:03,420 --> 01:37:08,949
fast AI is now the first library that

1983
01:37:06,729 --> 01:37:10,149
has all of the tricks necessary to train

1984
01:37:08,949 --> 01:37:12,489
in half precision floating point

1985
01:37:10,149 --> 01:37:15,489
built-in so if you now if you have a

1986
01:37:12,489 --> 01:37:18,099
lucky enough to have a Volta or you can

1987
01:37:15,489 --> 01:37:20,309
pay for a p3 if you've got a learner

1988
01:37:18,100 --> 01:37:24,600
object you can just say learned half and

1989
01:37:20,310 --> 01:37:27,910
it'll now just magically train correctly

1990
01:37:24,600 --> 01:37:29,740
position floating point that built into

1991
01:37:27,909 --> 01:37:32,139
the model data objects as well it's all

1992
01:37:29,739 --> 01:37:36,029
automatic and pretty sure no other

1993
01:37:32,140 --> 01:37:38,380
library does that okay

1994
01:37:36,029 --> 01:37:41,139
so this is just doing the same thing on

1995
01:37:38,380 --> 01:37:43,720
a slightly earlier layer and you can see

1996
01:37:41,140 --> 01:37:46,450
that the bird looks you know the later

1997
01:37:43,720 --> 01:37:47,890
layer you know doesn't look very

1998
01:37:46,449 --> 01:37:49,659
bird-like at all but you can kind of

1999
01:37:47,890 --> 01:37:51,579
tell it's bird slightly earlier layer

2000
01:37:49,659 --> 01:37:53,859
more bird-like right

2001
01:37:51,579 --> 01:37:57,189
and hopefully that makes sense to you

2002
01:37:53,859 --> 01:37:59,289
that earlier layers are getting closer

2003
01:37:57,189 --> 01:38:03,939
to the they're getting closer to the

2004
01:37:59,289 --> 01:38:05,890
pixels you know it's a it's a smaller

2005
01:38:03,939 --> 01:38:09,759
grid size well there's this little more

2006
01:38:05,890 --> 01:38:12,820
grid cells each cell is smaller smaller

2007
01:38:09,760 --> 01:38:16,630
receptive field less complex semantic

2008
01:38:12,819 --> 01:38:18,969
features so the earlier we get the more

2009
01:38:16,630 --> 01:38:23,140
it's going to look like a bit and in

2010
01:38:18,970 --> 01:38:25,420
fact the paper has a nice picture of

2011
01:38:23,140 --> 01:38:27,490
that showing various different layers

2012
01:38:25,420 --> 01:38:28,840
and kind of zooming into this house

2013
01:38:27,489 --> 01:38:31,000
they're trying to make this house look

2014
01:38:28,840 --> 01:38:34,210
like this picture and you can see that

2015
01:38:31,000 --> 01:38:37,119
later on it's pretty messy and earlier

2016
01:38:34,210 --> 01:38:39,609
on it looks like this okay

2017
01:38:37,119 --> 01:38:41,529
so this is just doing what we just did

2018
01:38:39,609 --> 01:38:43,710
and I will say like one of the things

2019
01:38:41,529 --> 01:38:46,449
I've noticed in our study group is

2020
01:38:43,710 --> 01:38:50,170
anytime I say to somebody to answer a

2021
01:38:46,449 --> 01:38:51,429
question yes if we're anytime I say read

2022
01:38:50,170 --> 01:38:52,539
the paper there's a thing in the paper

2023
01:38:51,430 --> 01:38:54,280
that tells you the answer to that

2024
01:38:52,539 --> 01:39:00,069
question there's always this shock look

2025
01:38:54,279 --> 01:39:02,889
okay read the paper me the paper but

2026
01:39:00,069 --> 01:39:04,899
seriously the papers have like they've

2027
01:39:02,890 --> 01:39:07,090
done these experiments and drawn the

2028
01:39:04,899 --> 01:39:09,460
pictures like there's all this stuff in

2029
01:39:07,090 --> 01:39:11,710
the papers like it doesn't mean you have

2030
01:39:09,460 --> 01:39:14,199
to read every part of the paper right

2031
01:39:11,710 --> 01:39:16,689
but at least look at the pictures right

2032
01:39:14,199 --> 01:39:20,949
so check out the gaddy's paper it's got

2033
01:39:16,689 --> 01:39:22,869
nice pictures okay so they've done the

2034
01:39:20,949 --> 01:39:25,510
experiment for us they basically did

2035
01:39:22,869 --> 01:39:26,769
this experiment okay but it looks like

2036
01:39:25,510 --> 01:39:30,730
they didn't go as deep they just got

2037
01:39:26,770 --> 01:39:33,640
some earlier ones okay the next thing we

2038
01:39:30,729 --> 01:39:34,959
need to do is to create style loss all

2039
01:39:33,640 --> 01:39:38,579
right so we've already got the loss

2040
01:39:34,960 --> 01:39:42,970
which is how much like the bird is it

2041
01:39:38,579 --> 01:39:46,239
now we need how like this painting style

2042
01:39:42,970 --> 01:39:48,640
is it and we're going to do nearly the

2043
01:39:46,239 --> 01:39:51,550
same thing okay we're going to grab the

2044
01:39:48,640 --> 01:39:55,260
activations of somewhere now the problem

2045
01:39:51,550 --> 01:39:55,260
is that the activations of some layer

2046
01:39:57,429 --> 01:40:04,340
let's say it was a five by five layer

2047
01:40:01,988 --> 01:40:07,029
way of course there are no five by five

2048
01:40:04,340 --> 01:40:14,949
layers up to 24 by 24 bit corporate head

2049
01:40:07,029 --> 01:40:19,569
five by five I whatever nine to say

2050
01:40:14,948 --> 01:40:19,569
totally unrealistic sizes but never mind

2051
01:40:19,988 --> 01:40:25,368
so there here's some activations and we

2052
01:40:23,510 --> 01:40:28,309
could get these activations both per

2053
01:40:25,368 --> 01:40:31,698
hour the image we're optimizing and for

2054
01:40:28,309 --> 01:40:36,579
our van Gogh thank you and let's look at

2055
01:40:31,698 --> 01:40:42,049
our van Gogh painting there it is night

2056
01:40:36,578 --> 01:40:43,458
I downloaded this from Wikipedia and I

2057
01:40:42,050 --> 01:40:46,279
was wondering what is taking so long to

2058
01:40:43,458 --> 01:40:48,408
load it turns out that the the Wikipedia

2059
01:40:46,279 --> 01:40:50,719
version I downloaded was thirty thousand

2060
01:40:48,408 --> 01:40:52,509
by thirty thousand pixels okay that's

2061
01:40:50,719 --> 01:40:55,550
pretty cool they've got this like

2062
01:40:52,510 --> 01:40:58,670
serious gallery quality archive stuff

2063
01:40:55,550 --> 01:41:01,969
there I didn't know it existed so don't

2064
01:40:58,670 --> 01:41:08,059
try and run a neuron in on that totally

2065
01:41:01,969 --> 01:41:10,069
killed my Jupiter notebook okay so yeah

2066
01:41:08,059 --> 01:41:11,420
so we can do that for our van Gogh image

2067
01:41:10,069 --> 01:41:15,828
and we can do that for our optimizer

2068
01:41:11,420 --> 01:41:17,538
image and then we can compare the two

2069
01:41:15,828 --> 01:41:20,929
and we would end up creating an image

2070
01:41:17,538 --> 01:41:22,189
that looks you know content like the

2071
01:41:20,929 --> 01:41:23,538
painting but it's not the painting

2072
01:41:22,189 --> 01:41:25,158
that's not what we want we want

2073
01:41:23,538 --> 01:41:26,420
something with the same style but it's

2074
01:41:25,158 --> 01:41:28,518
not the painting it doesn't have the

2075
01:41:26,420 --> 01:41:32,050
contrary so we actually want to throw

2076
01:41:28,519 --> 01:41:33,979
away all of the spatial information

2077
01:41:32,050 --> 01:41:37,788
right we're not trying to create

2078
01:41:33,979 --> 01:41:40,550
something that looks that has a moon

2079
01:41:37,788 --> 01:41:43,429
here and stars here and because it's a

2080
01:41:40,550 --> 01:41:45,979
church here and whatever right we don't

2081
01:41:43,429 --> 01:41:49,069
want any of that so how do we throw away

2082
01:41:45,979 --> 01:41:51,860
all the spatial information what we do

2083
01:41:49,069 --> 01:41:56,538
is let's grab so there are like in this

2084
01:41:51,859 --> 01:41:59,948
case they're like nineteen faces on this

2085
01:41:56,538 --> 01:42:04,050
right like nineteen slices so let's grab

2086
01:41:59,948 --> 01:42:07,269
this top slice

2087
01:42:04,050 --> 01:42:13,570
okay let's grab that top slice so that's

2088
01:42:07,270 --> 01:42:21,700
going to be a five by five matrix okay

2089
01:42:13,569 --> 01:42:28,449
and now let's flatten it so now we've

2090
01:42:21,699 --> 01:42:32,500
got a twenty five long vector now in one

2091
01:42:28,449 --> 01:42:34,359
stroke we've thrown away the you know

2092
01:42:32,500 --> 01:42:38,819
the bulk of the spatial information by

2093
01:42:34,359 --> 01:42:44,289
flattening it all right now let's grab a

2094
01:42:38,819 --> 01:42:50,489
second slice alright so another another

2095
01:42:44,289 --> 01:42:50,489
Channel and do the same thing

2096
01:42:54,630 --> 01:43:02,199
okay so here's channel one flattened

2097
01:42:58,000 --> 01:43:05,829
here's channel two flattened and they've

2098
01:43:02,199 --> 01:43:09,309
both got $25 and now let's take the dot

2099
01:43:05,829 --> 01:43:13,029
product which we can do with at in dump

2100
01:43:09,310 --> 01:43:18,690
I and so the nine the dot products going

2101
01:43:13,029 --> 01:43:23,800
to give us one number what's that number

2102
01:43:18,689 --> 01:43:26,819
what is it telling us well assuming this

2103
01:43:23,800 --> 01:43:28,779
is kind of somewhere around the middle

2104
01:43:26,819 --> 01:43:29,889
activation you know the activations are

2105
01:43:28,779 --> 01:43:32,199
somewhere around the middle layer of the

2106
01:43:29,890 --> 01:43:34,690
vgg network we might expect some of

2107
01:43:32,199 --> 01:43:37,000
these activations to be like how

2108
01:43:34,689 --> 01:43:38,829
textured is the brushstroke and some of

2109
01:43:37,000 --> 01:43:41,920
them to be like how bright is this area

2110
01:43:38,829 --> 01:43:46,269
and some of them to be like is this part

2111
01:43:41,920 --> 01:43:49,720
of a house or a part of a circular thing

2112
01:43:46,270 --> 01:43:52,900
or other parts to be you know how dark

2113
01:43:49,720 --> 01:43:54,579
is this part of the painting and so this

2114
01:43:52,899 --> 01:43:56,979
a dot product

2115
01:43:54,579 --> 01:44:00,880
remember it's basically a correlation

2116
01:43:56,979 --> 01:44:04,869
right if if if this element and this

2117
01:44:00,880 --> 01:44:07,449
element are both highly positive or both

2118
01:44:04,869 --> 01:44:08,140
highly negative it gives us a big result

2119
01:44:07,449 --> 01:44:09,729
right

2120
01:44:08,140 --> 01:44:12,039
we're also if they're the opposite gives

2121
01:44:09,729 --> 01:44:13,809
a small result if they're both close to

2122
01:44:12,039 --> 01:44:15,369
zero it gives no result so it's

2123
01:44:13,810 --> 01:44:17,800
basically a dot product as a measure of

2124
01:44:15,369 --> 01:44:21,039
how similar these two things are

2125
01:44:17,800 --> 01:44:23,520
right and so if the activations of

2126
01:44:21,039 --> 01:44:27,189
channel 1 and channel 2

2127
01:44:23,520 --> 01:44:29,800
you know how similar that it basically

2128
01:44:27,189 --> 01:44:33,639
says let's give an example let's say

2129
01:44:29,800 --> 01:44:36,279
this first one was like how textured are

2130
01:44:33,640 --> 01:44:39,430
the brushstrokes and this one here that

2131
01:44:36,279 --> 01:44:42,519
say was like how kind of diagonally

2132
01:44:39,430 --> 01:44:44,560
oriented are the brushstrokes right and

2133
01:44:42,520 --> 01:44:46,390
if and if both of these were high

2134
01:44:44,560 --> 01:44:48,760
together and both of these were high

2135
01:44:46,390 --> 01:44:50,200
together then it's basically saying oh

2136
01:44:48,760 --> 01:44:52,470
anywhere that there's more textured

2137
01:44:50,199 --> 01:44:57,099
brush strokes they tend to be diagonal

2138
01:44:52,470 --> 01:45:02,490
right or another interesting one is what

2139
01:44:57,100 --> 01:45:05,890
would be the dot product of c1 with c1

2140
01:45:02,489 --> 01:45:08,880
so that would be basically the the two

2141
01:45:05,890 --> 01:45:12,610
normal that the sum of the squares of

2142
01:45:08,880 --> 01:45:19,239
that channel which in other words is

2143
01:45:12,609 --> 01:45:22,170
basically just on average how so let's

2144
01:45:19,239 --> 01:45:22,170
go back I screwed this up

2145
01:45:23,310 --> 01:45:32,590
channel 1 might be texture and channel

2146
01:45:28,420 --> 01:45:36,369
two might be diagonal and this one here

2147
01:45:32,590 --> 01:45:39,460
would be cell 1 comma 1 and this cell

2148
01:45:36,369 --> 01:45:42,519
here would be like cell say 4 comma 2

2149
01:45:39,460 --> 01:45:45,189
and so sorry what I was should have been

2150
01:45:42,520 --> 01:45:47,140
saying is if these are both high at the

2151
01:45:45,189 --> 01:45:49,989
same time and these are both high at the

2152
01:45:47,140 --> 01:45:53,520
same time then it's saying grid cells

2153
01:45:49,989 --> 01:45:56,949
would have texture tend to also have

2154
01:45:53,520 --> 01:45:58,870
diagonal so sorry I drew that all wrong

2155
01:45:56,949 --> 01:46:02,380
the idea was right it has drew it all

2156
01:45:58,869 --> 01:46:05,439
wrong so yeah so this number is going to

2157
01:46:02,380 --> 01:46:08,710
be high when grid cells that have

2158
01:46:05,439 --> 01:46:15,009
texture also have diagonal and when they

2159
01:46:08,710 --> 01:46:21,100
don't they don't so that's C 1 dot

2160
01:46:15,010 --> 01:46:24,699
product C 2 where else C 1 dot product C

2161
01:46:21,100 --> 01:46:27,850
1 right is basically as we said like the

2162
01:46:24,699 --> 01:46:30,380
two norm effectively squared or the sum

2163
01:46:27,850 --> 01:46:39,199
of the squares of C 1

2164
01:46:30,380 --> 01:46:44,539
sum over I of c1 squared and this is

2165
01:46:39,198 --> 01:46:49,059
basically saying how in how many grid

2166
01:46:44,539 --> 01:46:53,210
cells is the textured channel active and

2167
01:46:49,060 --> 01:46:56,989
how active is it so in other words see

2168
01:46:53,210 --> 01:46:59,000
one dot product see one tells us how

2169
01:46:56,988 --> 01:47:03,859
much textured painting is going on and

2170
01:46:59,000 --> 01:47:05,869
see two dot product see two tells us how

2171
01:47:03,859 --> 01:47:09,229
much diagonal paint strokes is going on

2172
01:47:05,869 --> 01:47:11,658
and you know maybe see three is you know

2173
01:47:09,229 --> 01:47:14,119
is it bright colors so see three dot

2174
01:47:11,658 --> 01:47:18,019
product see three would be you know how

2175
01:47:14,119 --> 01:47:20,090
often do we have bright colored cells so

2176
01:47:18,020 --> 01:47:27,500
what we could do then is we could create

2177
01:47:20,090 --> 01:47:31,219
a 25 by 25 matrix containing every one

2178
01:47:27,500 --> 01:47:34,069
channel 1 channel 2 channel 3 channel 1

2179
01:47:31,219 --> 01:47:43,850
channel 2 channel 3 so you're not

2180
01:47:34,069 --> 01:47:48,408
channel man it's been a long day 19

2181
01:47:43,850 --> 01:47:52,539
there are 19 channels 19 by 19 okay

2182
01:47:48,408 --> 01:47:56,329
channel 1 channel 2 channel 3 channel 19

2183
01:47:52,539 --> 01:48:00,229
channel 1 channel 2 channel 3 did it do

2184
01:47:56,329 --> 01:48:02,389
it channel 19 okay and so this would be

2185
01:48:00,229 --> 01:48:04,519
the dot product of channel 1 or channel

2186
01:48:02,389 --> 01:48:06,829
1 this would be the drug product of

2187
01:48:04,520 --> 01:48:12,260
channel 2 with channel 2 and so forth

2188
01:48:06,829 --> 01:48:15,469
after flattening yeah and like we

2189
01:48:12,260 --> 01:48:17,750
discussed mathematicians have to give

2190
01:48:15,469 --> 01:48:21,079
everything a name so this particular

2191
01:48:17,750 --> 01:48:22,908
matrix where you flatten something L out

2192
01:48:21,079 --> 01:48:28,809
and then do the doctrine all the dot

2193
01:48:22,908 --> 01:48:28,809
products is called a gram matrix

2194
01:48:28,960 --> 01:48:36,220
and I'll tell you a secret like most

2195
01:48:32,260 --> 01:48:37,810
deep learning practitioners either don't

2196
01:48:36,220 --> 01:48:40,840
know or don't remember all these things

2197
01:48:37,810 --> 01:48:42,220
like what is a grand matrix if they ever

2198
01:48:40,840 --> 01:48:43,690
did study at university they probably

2199
01:48:42,220 --> 01:48:45,730
forgot it because they had a big night

2200
01:48:43,689 --> 01:48:48,279
afterwards and the way it works in

2201
01:48:45,729 --> 01:48:51,209
practice is like you realize oh I could

2202
01:48:48,279 --> 01:48:54,399
create a kind of non spatial

2203
01:48:51,210 --> 01:48:56,739
representation of how the channels

2204
01:48:54,399 --> 01:48:58,689
correlate with each other and then when

2205
01:48:56,739 --> 01:49:00,699
I write up the paper I have to go and

2206
01:48:58,689 --> 01:49:03,369
ask around and say like does this thing

2207
01:49:00,699 --> 01:49:04,929
have a name and somebody be right isn't

2208
01:49:03,369 --> 01:49:06,729
it the gram matrix and you go and look

2209
01:49:04,930 --> 01:49:08,020
it up that it is right so don't think

2210
01:49:06,729 --> 01:49:11,199
like you have to go and study all of

2211
01:49:08,020 --> 01:49:13,390
math first you use your intuition and

2212
01:49:11,199 --> 01:49:16,769
common sense and then you worry about

2213
01:49:13,390 --> 01:49:19,570
what the math is called later normally

2214
01:49:16,770 --> 01:49:23,470
sometimes it works the other way not

2215
01:49:19,569 --> 01:49:25,090
with me because I can do a mess okay so

2216
01:49:23,470 --> 01:49:26,500
this is called the gram matrix and of

2217
01:49:25,090 --> 01:49:28,989
course if you're a real mathematician is

2218
01:49:26,500 --> 01:49:31,239
very important that you you say this as

2219
01:49:28,989 --> 01:49:33,099
if you already always knew it was a gram

2220
01:49:31,239 --> 01:49:35,469
matrix and you kind of just go oh yes we

2221
01:49:33,100 --> 01:49:40,420
just calculate the gram matrix that's

2222
01:49:35,470 --> 01:49:46,659
really important so the grand matrix

2223
01:49:40,420 --> 01:49:51,609
then is this kind of map of the diagonal

2224
01:49:46,659 --> 01:49:54,460
is perhaps the most interesting right

2225
01:49:51,609 --> 01:49:57,309
the diagonal is like which channels are

2226
01:49:54,460 --> 01:49:59,380
the most active and then the off

2227
01:49:57,310 --> 01:50:03,280
diagonal is like which channels tend to

2228
01:49:59,380 --> 01:50:07,720
appear together and overall if two

2229
01:50:03,279 --> 01:50:09,969
pictures have the same style right then

2230
01:50:07,720 --> 01:50:12,820
we're expecting that some layer of

2231
01:50:09,970 --> 01:50:15,640
activations they will have similar Gramm

2232
01:50:12,819 --> 01:50:17,679
matrices because if we found the level

2233
01:50:15,640 --> 01:50:19,840
of activations that capture a lot of

2234
01:50:17,680 --> 01:50:23,159
stuff about like paint strokes and

2235
01:50:19,840 --> 01:50:26,440
colors and stuff then the diagonal alone

2236
01:50:23,159 --> 01:50:28,899
might even be enough and like that's

2237
01:50:26,439 --> 01:50:30,969
another interesting homework assignment

2238
01:50:28,899 --> 01:50:33,670
if somebody wants to take it is try

2239
01:50:30,970 --> 01:50:35,680
doing gaddy's style transfer not using

2240
01:50:33,670 --> 01:50:37,619
the ground matrix but just using the

2241
01:50:35,680 --> 01:50:39,760
diagonal of the gray matrix and that

2242
01:50:37,619 --> 01:50:42,609
would be like a single line of code to

2243
01:50:39,760 --> 01:50:44,500
change that I haven't seen it tried and

2244
01:50:42,609 --> 01:50:51,058
I don't know if it would work at all but

2245
01:50:44,500 --> 01:50:54,578
it might work fine Christine Christine

2246
01:50:51,059 --> 01:50:56,710
okay yes Christine you've tried it and

2247
01:50:54,578 --> 01:50:58,118
it works most of the time except when

2248
01:50:56,710 --> 01:51:01,029
you have funny pictures where you need

2249
01:50:58,118 --> 01:51:02,948
two styles to appear in the same spot so

2250
01:51:01,029 --> 01:51:04,630
it sounds like grass in one half and

2251
01:51:02,948 --> 01:51:07,000
like a crowd in one half and you need

2252
01:51:04,630 --> 01:51:08,230
the two styles ah cool

2253
01:51:07,000 --> 01:51:11,529
you're still gonna take your homework is

2254
01:51:08,229 --> 01:51:14,069
that okay Christine says she'll do it

2255
01:51:11,529 --> 01:51:14,069
for you okay

2256
01:51:17,520 --> 01:51:25,260
so let's do that so here's our painting

2257
01:51:26,368 --> 01:51:33,460
I've tried to resize the painting so

2258
01:51:30,520 --> 01:51:38,619
it's the same size as my bird picture so

2259
01:51:33,460 --> 01:51:42,279
that's all this is just doing so I make

2260
01:51:38,618 --> 01:51:45,399
the yeah so there it is it doesn't

2261
01:51:42,279 --> 01:51:48,029
matter too much which bit I use as long

2262
01:51:45,399 --> 01:51:51,729
as it's got lots of a nice style in it I

2263
01:51:48,029 --> 01:51:55,269
grab my optimizer and my random image

2264
01:51:51,729 --> 01:51:58,569
just like before and this time I call

2265
01:51:55,270 --> 01:52:00,219
save features for all of my block ends

2266
01:51:58,569 --> 01:52:03,939
and that's going to give me an array of

2267
01:52:00,219 --> 01:52:06,368
save features objects one for each

2268
01:52:03,939 --> 01:52:09,698
module that appears the layer before

2269
01:52:06,368 --> 01:52:13,259
IMAX Paul so now because because this

2270
01:52:09,698 --> 01:52:16,839
time I want to play around with

2271
01:52:13,260 --> 01:52:19,239
different activation layer styles or

2272
01:52:16,840 --> 01:52:21,909
more specifically I want to let you play

2273
01:52:19,238 --> 01:52:26,618
around with it okay so now I've got a

2274
01:52:21,908 --> 01:52:36,488
whole array of them so now I call my vgg

2275
01:52:26,618 --> 01:52:38,469
module on my my image again yeah I'm not

2276
01:52:36,488 --> 01:52:42,939
going to use that yeah okay ignore that

2277
01:52:38,469 --> 01:52:45,219
line.i style image sorry style images my

2278
01:52:42,939 --> 01:52:46,988
van Gogh painting so I take my style

2279
01:52:45,219 --> 01:52:48,908
image put it through my transformations

2280
01:52:46,988 --> 01:52:52,388
to create my transform style image I

2281
01:52:48,908 --> 01:52:54,578
turn that into a variable put it through

2282
01:52:52,389 --> 01:52:56,288
the forward pass of my vgg module and

2283
01:52:54,578 --> 01:52:59,349
now I can go

2284
01:52:56,288 --> 01:53:02,349
through all of my save features objects

2285
01:52:59,349 --> 01:53:04,510
and grab each set of features and notice

2286
01:53:02,349 --> 01:53:07,149
I call clone right because I don't I've

2287
01:53:04,510 --> 01:53:09,248
caused like later on if I call my vgg

2288
01:53:07,149 --> 01:53:12,099
object again it's going to replace those

2289
01:53:09,248 --> 01:53:13,719
contents I haven't quite thought about

2290
01:53:12,099 --> 01:53:15,399
whether this is necessary if you take it

2291
01:53:13,719 --> 01:53:17,010
away and it's not that's fine but us as

2292
01:53:15,399 --> 01:53:21,179
being careful

2293
01:53:17,010 --> 01:53:28,239
so here's now an array of the

2294
01:53:21,179 --> 01:53:30,429
activations at every block and player so

2295
01:53:28,238 --> 01:53:32,768
here you can see all of those shapes and

2296
01:53:30,429 --> 01:53:34,838
you can see like being able to like whip

2297
01:53:32,769 --> 01:53:36,699
up a list comprehension really quickly

2298
01:53:34,838 --> 01:53:38,019
it's really important in your Jupiter

2299
01:53:36,698 --> 01:53:41,018
fiddling around because you really want

2300
01:53:38,019 --> 01:53:42,458
to be able to like immediately see you

2301
01:53:41,019 --> 01:53:44,109
know here's my channel sixty four one

2302
01:53:42,458 --> 01:53:46,809
four six five twelve and you can see

2303
01:53:44,109 --> 01:53:48,760
here the grid size having as we would

2304
01:53:46,809 --> 01:53:57,010
expect because all of these appear just

2305
01:53:48,760 --> 01:53:59,859
before M export so so do a Graham MSC

2306
01:53:57,010 --> 01:54:01,989
loss it's going to be the MSE loss on

2307
01:53:59,859 --> 01:54:05,229
the ground matrix of the input versus

2308
01:54:01,988 --> 01:54:07,509
the gram matrix of the target and the

2309
01:54:05,229 --> 01:54:13,689
ground matrix is just the matrix

2310
01:54:07,510 --> 01:54:17,739
multiply of X with X transpose where X

2311
01:54:13,689 --> 01:54:22,479
is simply equal to my input where I've

2312
01:54:17,738 --> 01:54:24,398
flattened the batch and channel axes all

2313
01:54:22,479 --> 01:54:26,289
down together and I already got one

2314
01:54:24,399 --> 01:54:28,419
image so you can kind of ignore the

2315
01:54:26,288 --> 01:54:30,938
batch part right it's basically channel

2316
01:54:28,418 --> 01:54:33,010
and then everything else which in this

2317
01:54:30,939 --> 01:54:34,899
case is the height and width is the

2318
01:54:33,010 --> 01:54:38,798
other dimension because there's now

2319
01:54:34,899 --> 01:54:40,569
it'll be channel by width and then as we

2320
01:54:38,798 --> 01:54:43,689
discussed we can then just do the matrix

2321
01:54:40,569 --> 01:54:46,869
multiply of that by its transpose and

2322
01:54:43,689 --> 01:54:49,838
just to normalize it we'll divide that

2323
01:54:46,868 --> 01:54:55,408
by the number of elements it would

2324
01:54:49,838 --> 01:55:00,729
actually be more elegant if I had said /

2325
01:54:55,408 --> 01:55:03,868
import dot Nam elements that were in the

2326
01:55:00,729 --> 01:55:03,869
same thing okay

2327
01:55:03,908 --> 01:55:08,058
and then again this kind of keep me tiny

2328
01:55:06,260 --> 01:55:12,378
numbers so I multiply it by a big number

2329
01:55:08,059 --> 01:55:14,239
to make it something more sensible okay

2330
01:55:12,378 --> 01:55:16,908
so that's basically my loss right so now

2331
01:55:14,238 --> 01:55:19,728
my style loss is to take my image to

2332
01:55:16,908 --> 01:55:22,998
optimize throw it through vgg forward

2333
01:55:19,729 --> 01:55:25,249
pass grab an array of the features in

2334
01:55:22,998 --> 01:55:32,298
all of the safe features objects and

2335
01:55:25,248 --> 01:55:34,878
then call my Graham MSC loss on every

2336
01:55:32,298 --> 01:55:36,588
one of those layers okay and that's

2337
01:55:34,878 --> 01:55:40,368
going to give me an array and then I

2338
01:55:36,588 --> 01:55:42,439
just add them up now you could add them

2339
01:55:40,368 --> 01:55:46,938
up with different weightings you could

2340
01:55:42,439 --> 01:55:51,918
add up subsets whatever right in this

2341
01:55:46,939 --> 01:55:54,789
case I'm just grabbing all of them pass

2342
01:55:51,918 --> 01:55:59,029
that into my optimizer as before and

2343
01:55:54,788 --> 01:56:01,338
here we have a random image in the style

2344
01:55:59,029 --> 01:56:05,868
of Van Gogh which i think is kind of

2345
01:56:01,338 --> 01:56:11,059
cool and again gaddy's has done it for

2346
01:56:05,868 --> 01:56:13,578
us here is different layers of random

2347
01:56:11,059 --> 01:56:15,319
image in the style of Van Gogh and so

2348
01:56:13,578 --> 01:56:18,679
that the first one as you can see the

2349
01:56:15,319 --> 01:56:21,349
activations are simple geometric things

2350
01:56:18,679 --> 01:56:22,908
not very interesting at all the later

2351
01:56:21,349 --> 01:56:26,088
eight layers are much more interesting

2352
01:56:22,908 --> 01:56:28,998
so we kind of have a suspicion that we

2353
01:56:26,088 --> 01:56:31,849
probably want to use later layers

2354
01:56:28,998 --> 01:56:38,748
largely for our style laughs if we

2355
01:56:31,849 --> 01:56:45,260
wanted to look good all right I added

2356
01:56:38,748 --> 01:56:48,588
this what was it this save features dot

2357
01:56:45,260 --> 01:56:52,189
close which just calls remember I stored

2358
01:56:48,588 --> 01:56:54,649
the hook here and so Hawk don't remove

2359
01:56:52,189 --> 01:56:57,109
gets rid of it and it's a good idea to

2360
01:56:54,649 --> 01:56:59,260
get rid of it because otherwise you know

2361
01:56:57,109 --> 01:57:03,109
you can potentially just keep using

2362
01:56:59,260 --> 01:57:04,729
memory all right so at the end I go

2363
01:57:03,109 --> 01:57:11,979
through each of my so features objection

2364
01:57:04,729 --> 01:57:11,979
was it so style transfer is

2365
01:57:13,729 --> 01:57:20,759
adding the two together with some weight

2366
01:57:18,739 --> 01:57:23,099
so there's not much to show

2367
01:57:20,760 --> 01:57:27,630
grab my optimizer grab my image and now

2368
01:57:23,100 --> 01:57:30,570
my combined loss is the MSE loss at one

2369
01:57:27,630 --> 01:57:33,930
particular layer my style loss set all

2370
01:57:30,569 --> 01:57:35,670
of my layers sum up the stay losses add

2371
01:57:33,930 --> 01:57:39,360
them to the content loss the content

2372
01:57:35,670 --> 01:57:42,869
lost so I'm scaling actually the style

2373
01:57:39,359 --> 01:57:46,679
loss a scaled already by 1e6

2374
01:57:42,869 --> 01:57:48,359
and this one is one two three four five

2375
01:57:46,680 --> 01:57:51,420
six okay so actually they're they're

2376
01:57:48,359 --> 01:57:53,279
both the scaled exactly the same add

2377
01:57:51,420 --> 01:57:55,380
them together and again you could try

2378
01:57:53,279 --> 01:57:56,789
weighting the different style losses or

2379
01:57:55,380 --> 01:57:59,159
you could maybe remove some of them

2380
01:57:56,789 --> 01:58:05,010
whatever so this is the simplest

2381
01:57:59,159 --> 01:58:10,519
possible version train that and like

2382
01:58:05,010 --> 01:58:14,760
holy it actually looks good so I

2383
01:58:10,520 --> 01:58:20,280
think that's yeah I think that's pretty

2384
01:58:14,760 --> 01:58:24,060
awesome you know again you know the main

2385
01:58:20,279 --> 01:58:31,199
takeaway here is if you want to solve

2386
01:58:24,060 --> 01:58:35,150
something with a neural network all you

2387
01:58:31,199 --> 01:58:39,059
got to do is set up a loss function and

2388
01:58:35,149 --> 01:58:40,949
then optimize something all right and

2389
01:58:39,060 --> 01:58:43,230
the loss function is something which a

2390
01:58:40,949 --> 01:58:45,359
lower number is something that you're

2391
01:58:43,229 --> 01:58:46,529
happier with because then when you

2392
01:58:45,359 --> 01:58:48,529
optimize it it's going to make that

2393
01:58:46,529 --> 01:58:55,259
number as low as you can and it'll do

2394
01:58:48,529 --> 01:58:56,550
what's your what did its do okay so here

2395
01:58:55,260 --> 01:58:59,010
we can't what we didn't come up with

2396
01:58:56,550 --> 01:59:01,650
Gettys came up with a loss function that

2397
01:58:59,010 --> 01:59:03,989
does a good job of being a smaller

2398
01:59:01,649 --> 01:59:05,219
number when it looks like the thing we

2399
01:59:03,989 --> 01:59:06,659
want it to look like and it looks like

2400
01:59:05,220 --> 01:59:08,640
the style of the thing we want to be in

2401
01:59:06,659 --> 01:59:11,579
the style of that's all we had to do

2402
01:59:08,640 --> 01:59:15,150
right we like what it actually comes to

2403
01:59:11,579 --> 01:59:17,159
it you know apart from implementing gram

2404
01:59:15,149 --> 01:59:19,649
MSE loss which was like six lines of

2405
01:59:17,159 --> 01:59:24,960
code if that that's our loss function

2406
01:59:19,649 --> 01:59:26,139
pass it to our optimizer wait about five

2407
01:59:24,960 --> 01:59:27,970
seconds

2408
01:59:26,140 --> 01:59:29,740
and we're done and remember we could do

2409
01:59:27,970 --> 01:59:31,390
a batch of these at a time so we could

2410
01:59:29,739 --> 01:59:36,639
wait five seconds and sixty-four of

2411
01:59:31,390 --> 01:59:38,950
these will be done yeah so I think

2412
01:59:36,640 --> 01:59:43,539
that's really interesting and and since

2413
01:59:38,949 --> 01:59:47,679
this paper came out you know it's really

2414
01:59:43,539 --> 01:59:49,420
inspired a lot of interesting work to me

2415
01:59:47,680 --> 01:59:51,220
though most of the interesting work

2416
01:59:49,420 --> 01:59:54,100
hasn't happened yet because to me the

2417
01:59:51,220 --> 01:59:57,940
interesting work is the work where you

2418
01:59:54,100 --> 01:59:59,829
combine human creativity with these

2419
01:59:57,939 --> 02:00:02,199
kinds of tools you know and you know I

2420
01:59:59,829 --> 02:00:06,309
haven't seen much in the way of tools

2421
02:00:02,199 --> 02:00:08,710
that you can download or use where you

2422
02:00:06,310 --> 02:00:12,160
know that the artist is in control and

2423
02:00:08,710 --> 02:00:13,750
can kind of do things interactively it's

2424
02:00:12,159 --> 02:00:16,449
interesting talking to the guys at the

2425
02:00:13,750 --> 02:00:19,180
Google Magento project which is kind of

2426
02:00:16,449 --> 02:00:20,979
their creative value project all of the

2427
02:00:19,180 --> 02:00:23,320
stuff they're doing with music is

2428
02:00:20,979 --> 02:00:25,989
specifically about this it's building

2429
02:00:23,319 --> 02:00:28,149
tools that musicians can use to perform

2430
02:00:25,989 --> 02:00:30,369
in real time and so you'll see much more

2431
02:00:28,149 --> 02:00:31,539
of that on the music space thanks to

2432
02:00:30,369 --> 02:00:32,949
magenta if you go to their website

2433
02:00:31,539 --> 02:00:34,930
there's all kinds of things where you

2434
02:00:32,949 --> 02:00:36,579
can like press the buttons to like

2435
02:00:34,930 --> 02:00:40,270
actually change the drum beats or

2436
02:00:36,579 --> 02:00:42,430
melodies or keys or whatever and you can

2437
02:00:40,270 --> 02:00:45,010
definitely see like Adobe an Nvidia it's

2438
02:00:42,430 --> 02:00:46,990
kind of starting to release you know

2439
02:00:45,010 --> 02:00:49,420
little prototypes and started you

2440
02:00:46,989 --> 02:00:53,979
through this spit you know this kind of

2441
02:00:49,420 --> 02:00:56,289
like creative AI explosion hasn't

2442
02:00:53,979 --> 02:00:58,599
happened yet I think we have pretty much

2443
02:00:56,289 --> 02:01:00,460
all the technology we need but no one's

2444
02:00:58,600 --> 02:01:03,160
like put it together into a thing and

2445
02:01:00,460 --> 02:01:04,930
said like look at the thing I built and

2446
02:01:03,159 --> 02:01:09,099
look at the stuff that people built with

2447
02:01:04,930 --> 02:01:18,060
my thing you know so that's just a huge

2448
02:01:09,100 --> 02:01:20,620
area of opportunity so the paper that I

2449
02:01:18,060 --> 02:01:23,620
mentioned at the start of class in

2450
02:01:20,619 --> 02:01:27,539
passing the one where we can add Captain

2451
02:01:23,619 --> 02:01:31,689
America's shield to arbitrary paintings

2452
02:01:27,539 --> 02:01:34,920
basically used this technique right that

2453
02:01:31,689 --> 02:01:38,739
the trick was though some minor tweaks

2454
02:01:34,920 --> 02:01:40,170
to make the kind of the pasted Captain

2455
02:01:38,739 --> 02:01:42,750
America shield

2456
02:01:40,170 --> 02:01:44,760
blending nicely right but like that

2457
02:01:42,750 --> 02:01:46,170
would that papers only a couple of days

2458
02:01:44,760 --> 02:01:48,420
old so like that would be a really

2459
02:01:46,170 --> 02:01:51,180
interesting project to try because you

2460
02:01:48,420 --> 02:01:54,359
you can use all this code you know it

2461
02:01:51,180 --> 02:01:59,579
really does leverage this approach and

2462
02:01:54,359 --> 02:02:02,969
then you could start by you know making

2463
02:01:59,579 --> 02:02:05,760
the content image be like the painting

2464
02:02:02,970 --> 02:02:07,550
with the shield and then the style image

2465
02:02:05,760 --> 02:02:09,900
could be the painting without the shield

2466
02:02:07,550 --> 02:02:11,670
and like that would be a good start and

2467
02:02:09,899 --> 02:02:13,079
then you could kind of see what specific

2468
02:02:11,670 --> 02:02:15,890
problems they try to solve and there's

2469
02:02:13,079 --> 02:02:17,909
painting in this paper to make it better

2470
02:02:15,890 --> 02:02:20,539
but you know you could you could have a

2471
02:02:17,909 --> 02:02:20,539
start on it right now

2472
02:02:21,949 --> 02:02:35,369
okay so let's make a quick start on the

2473
02:02:27,270 --> 02:02:37,950
next bit which is yes Rachel say two

2474
02:02:35,369 --> 02:02:39,630
questions earlier there are a number of

2475
02:02:37,949 --> 02:02:42,090
people that expressed interest in your

2476
02:02:39,630 --> 02:02:50,190
thoughts on pyro and probabilistic

2477
02:02:42,090 --> 02:02:52,440
programming yeah so you know tensor

2478
02:02:50,189 --> 02:02:55,679
flows now but this particular tends to

2479
02:02:52,439 --> 02:02:56,969
flow probability or something there's

2480
02:02:55,680 --> 02:03:01,100
yeah there's a bunch of probabilistic

2481
02:02:56,970 --> 02:03:06,590
programming frameworks out there I I

2482
02:03:01,100 --> 02:03:11,840
think they're intriguing you know but as

2483
02:03:06,590 --> 02:03:16,500
yet unproven in the sense that like I

2484
02:03:11,840 --> 02:03:19,500
haven't seen anything done with any

2485
02:03:16,500 --> 02:03:22,770
probabilistic programming system which

2486
02:03:19,500 --> 02:03:26,340
hasn't been done better without them the

2487
02:03:22,770 --> 02:03:31,980
basic premise is that it allows you to

2488
02:03:26,340 --> 02:03:34,050
create more of a moral of how you think

2489
02:03:31,979 --> 02:03:35,399
the world works and then like plug in

2490
02:03:34,050 --> 02:03:37,199
the parameters so back when I used to

2491
02:03:35,399 --> 02:03:39,179
work in management consulting 20 years

2492
02:03:37,199 --> 02:03:42,210
ago we used to do a lot of stuff where

2493
02:03:39,180 --> 02:03:44,460
we would use a spreadsheet and then we

2494
02:03:42,210 --> 02:03:47,670
would have these Monte Carlo simulation

2495
02:03:44,460 --> 02:03:48,779
and plugins at risk and one crystal ball

2496
02:03:47,670 --> 02:03:50,640
I don't know if there still exists

2497
02:03:48,779 --> 02:03:53,759
decades later but basically they would

2498
02:03:50,640 --> 02:03:56,579
let you like change a spreadsheet cell

2499
02:03:53,760 --> 02:03:58,289
to say this is not a specific value but

2500
02:03:56,578 --> 02:03:59,518
it actually represents a distribution of

2501
02:03:58,288 --> 02:04:01,920
values with this mean and the standard

2502
02:03:59,519 --> 02:04:04,380
deviation or it's got this distribution

2503
02:04:01,920 --> 02:04:06,328
and then you would like hit a button and

2504
02:04:04,380 --> 02:04:08,250
the spreadsheet would recalculate a

2505
02:04:06,328 --> 02:04:09,630
thousand times pulling random numbers

2506
02:04:08,250 --> 02:04:11,309
from those distributions and show you

2507
02:04:09,630 --> 02:04:14,010
like the distribution of your outcome

2508
02:04:11,309 --> 02:04:16,619
that might be some you know profit or

2509
02:04:14,010 --> 02:04:21,269
market share or whatever and we used

2510
02:04:16,618 --> 02:04:24,000
them all the time back there apparently

2511
02:04:21,269 --> 02:04:25,800
think that feel that a spreadsheets a

2512
02:04:24,000 --> 02:04:27,719
more obvious place to do that kind of

2513
02:04:25,800 --> 02:04:33,619
work because you can kind of see it all

2514
02:04:27,719 --> 02:04:38,219
much more naturally but I don't know

2515
02:04:33,618 --> 02:04:40,049
we'll see at this stage I I hope it

2516
02:04:38,219 --> 02:04:42,260
turns out to be useful because I find it

2517
02:04:40,050 --> 02:04:44,639
very appealing and it kind of appeals to

2518
02:04:42,260 --> 02:04:47,460
as I say the kind of work I used to do a

2519
02:04:44,639 --> 02:04:48,719
lot of there's actually whole practices

2520
02:04:47,460 --> 02:04:51,989
around this stuff they used to call

2521
02:04:48,719 --> 02:04:54,868
systems dynamics which really was built

2522
02:04:51,988 --> 02:04:58,468
on top of this kind of stuff but no it's

2523
02:04:54,868 --> 02:05:02,308
it's not quite gone anywhere hey then

2524
02:04:58,469 --> 02:05:09,899
there is a question about pre training

2525
02:05:02,309 --> 02:05:11,400
for generic style transfer yes I don't

2526
02:05:09,899 --> 02:05:16,439
think you can pre train for a generic

2527
02:05:11,399 --> 02:05:21,448
style but you can pre train for a

2528
02:05:16,439 --> 02:05:23,598
generic photo for a particular style

2529
02:05:21,448 --> 02:05:27,928
which is where we're going to get to

2530
02:05:23,599 --> 02:05:29,880
although it may end up being a homework

2531
02:05:27,929 --> 02:05:33,389
I haven't decided but I'm going to do

2532
02:05:29,880 --> 02:05:37,099
all the pieces and one more question is

2533
02:05:33,389 --> 02:05:42,630
please ask him to talk about multi-gpu

2534
02:05:37,099 --> 02:05:43,710
oh yeah I haven't had a slide about that

2535
02:05:42,630 --> 02:05:45,328
it's events actually we're about to

2536
02:05:43,710 --> 02:05:51,239
about to get it

2537
02:05:45,328 --> 02:05:52,920
so yes okay so before we do just another

2538
02:05:51,238 --> 02:05:55,468
interesting picture from the Geddes

2539
02:05:52,920 --> 02:05:56,880
paper they've got a few more just didn't

2540
02:05:55,469 --> 02:05:59,099
fit in mice in my slide here but

2541
02:05:56,880 --> 02:06:03,690
different convolutional layers for the

2542
02:05:59,099 --> 02:06:05,519
style different style to content ratios

2543
02:06:03,689 --> 02:06:06,909
and here's the different images

2544
02:06:05,519 --> 02:06:08,110
obviously this isn't

2545
02:06:06,909 --> 02:06:11,199
then go anymore there's a different

2546
02:06:08,109 --> 02:06:13,000
combination so you can see like if you

2547
02:06:11,199 --> 02:06:16,470
just do like wall style you don't see

2548
02:06:13,000 --> 02:06:19,630
any image if you do all you know lots of

2549
02:06:16,470 --> 02:06:21,340
content that you use low enough

2550
02:06:19,630 --> 02:06:24,069
convolutional layer it looks okay but

2551
02:06:21,340 --> 02:06:25,750
the backgrounds kind of dumb so you kind

2552
02:06:24,069 --> 02:06:28,329
of want somewhere around here or here

2553
02:06:25,750 --> 02:06:30,069
I guess anyway so you can play around

2554
02:06:28,329 --> 02:06:34,449
with it and experiment but also use the

2555
02:06:30,069 --> 02:06:36,969
paper to help guide you actually I think

2556
02:06:34,449 --> 02:06:42,099
I might work on the math now and we'll

2557
02:06:36,970 --> 02:06:44,199
talk about multi GPU and and super

2558
02:06:42,100 --> 02:06:47,289
resolution next week because I think

2559
02:06:44,199 --> 02:06:48,399
that this is from the the paper and like

2560
02:06:47,289 --> 02:06:50,470
one of the things I really do want you

2561
02:06:48,399 --> 02:06:53,829
to do after we talk about a paper is to

2562
02:06:50,470 --> 02:06:56,289
read the paper and then ask questions on

2563
02:06:53,829 --> 02:06:57,729
the forum anything that's not clear but

2564
02:06:56,289 --> 02:07:00,659
there's kind of like a key part of this

2565
02:06:57,729 --> 02:07:04,719
paper which I wanted to talk about and

2566
02:07:00,659 --> 02:07:06,189
discuss how to interpret it so we're

2567
02:07:04,720 --> 02:07:10,659
going to be the paper says we're going

2568
02:07:06,189 --> 02:07:14,559
to be given an input image X and this

2569
02:07:10,659 --> 02:07:16,119
little thing means it's whatnot it means

2570
02:07:14,560 --> 02:07:24,610
it's a vector Rachel but this one's a

2571
02:07:16,119 --> 02:07:28,809
matrix I guess it could mean either yeah

2572
02:07:24,609 --> 02:07:32,199
I don't know maybe it's anyway so

2573
02:07:28,810 --> 02:07:35,200
normally small letter bulk means vector

2574
02:07:32,199 --> 02:07:37,630
or a small letter with Dubey on top

2575
02:07:35,199 --> 02:07:40,510
means vector they can both mean vector

2576
02:07:37,630 --> 02:07:42,159
and normally big letter means matrix or

2577
02:07:40,510 --> 02:07:46,060
small letter with two doobies on top

2578
02:07:42,159 --> 02:07:47,710
means matrix in this case our image is a

2579
02:07:46,060 --> 02:07:49,090
matrix we are going to basically treat

2580
02:07:47,710 --> 02:07:52,270
it as a vector so maybe we're just

2581
02:07:49,090 --> 02:07:56,020
getting ahead of ourselves so we've got

2582
02:07:52,270 --> 02:07:58,510
an input image X and it can be encoded

2583
02:07:56,020 --> 02:08:01,270
in a particular layer of the CNN by the

2584
02:07:58,510 --> 02:08:03,760
filter responses so the activations your

2585
02:08:01,270 --> 02:08:05,650
responses are activations right so

2586
02:08:03,760 --> 02:08:07,449
hopefully that's something you all

2587
02:08:05,649 --> 02:08:09,219
understand that's basically what a CNN

2588
02:08:07,449 --> 02:08:13,109
does is it produces layers of

2589
02:08:09,220 --> 02:08:15,640
activations Alea has a bunch of filters

2590
02:08:13,109 --> 02:08:18,219
right which produce a number of channels

2591
02:08:15,640 --> 02:08:20,260
right and so this year says that layer

2592
02:08:18,220 --> 02:08:25,329
number L has capital

2593
02:08:20,260 --> 02:08:27,610
our filters and again this capital does

2594
02:08:25,328 --> 02:08:31,090
not mean matrix so I don't know math

2595
02:08:27,609 --> 02:08:36,009
notation is so inconsistent so capital

2596
02:08:31,090 --> 02:08:38,529
NL distinct filters that layer L which

2597
02:08:36,010 --> 02:08:40,389
means it has that also that many feature

2598
02:08:38,529 --> 02:08:42,009
Mouse right so make sure you can see

2599
02:08:40,389 --> 02:08:43,659
that this letter is the same as list

2600
02:08:42,010 --> 02:08:45,309
letter that's you've got to be very

2601
02:08:43,658 --> 02:08:47,500
careful to read the letters and

2602
02:08:45,309 --> 02:08:49,630
recognize it's like snap you know that's

2603
02:08:47,500 --> 02:08:52,118
the same letter as that okay so

2604
02:08:49,630 --> 02:08:54,880
obviously NL feature maps are in our

2605
02:08:52,118 --> 02:09:00,009
filters filters create and our feature

2606
02:08:54,880 --> 02:09:02,260
maps or channels h1 is of size M okay so

2607
02:09:00,010 --> 02:09:03,730
I can see this is where the this is

2608
02:09:02,260 --> 02:09:07,119
where the unrolling is happening each

2609
02:09:03,729 --> 02:09:10,118
map is of size M little L right so this

2610
02:09:07,118 --> 02:09:14,018
is like you know m square bracket L in

2611
02:09:10,118 --> 02:09:17,799
numpy notation it's the elf layer so m

2612
02:09:14,019 --> 02:09:21,190
for the elf layer and the the size is

2613
02:09:17,800 --> 02:09:25,050
height times width okay so we flattened

2614
02:09:21,189 --> 02:09:29,589
it out so the responses at that layer L

2615
02:09:25,050 --> 02:09:31,719
can be stored in a matrix F and now the

2616
02:09:29,590 --> 02:09:34,139
old grows at the top for some reason so

2617
02:09:31,719 --> 02:09:37,050
this it's not f ^ else it's just another

2618
02:09:34,139 --> 02:09:40,000
indexing we're just moving around fun

2619
02:09:37,050 --> 02:09:42,519
and this thing here where we say it's an

2620
02:09:40,000 --> 02:09:44,559
element of R this is a special I mean in

2621
02:09:42,519 --> 02:09:47,619
the real numbers n times M this is

2622
02:09:44,559 --> 02:09:50,110
saying that the dimensions of this is n

2623
02:09:47,618 --> 02:09:51,698
by M right so this is really important

2624
02:09:50,109 --> 02:09:53,618
like you don't move on it's just like

2625
02:09:51,698 --> 02:09:55,479
with PI torch making sure that you

2626
02:09:53,618 --> 02:09:58,210
understand the rank and size of your

2627
02:09:55,479 --> 02:09:59,408
dimensions first same with math right

2628
02:09:58,210 --> 02:10:02,769
you did these are the bits where you

2629
02:09:59,408 --> 02:10:06,250
stop and think why is it n by M right

2630
02:10:02,769 --> 02:10:08,619
okay so n is a number of filters M is

2631
02:10:06,250 --> 02:10:12,519
height by width right so do you remember

2632
02:10:08,618 --> 02:10:15,630
that thing where we did viewer batch x

2633
02:10:12,519 --> 02:10:19,059
channel comma minus 1 right here that is

2634
02:10:15,630 --> 02:10:22,170
okay so try to map the code to the math

2635
02:10:19,059 --> 02:10:22,170
so f is

2636
02:10:23,219 --> 02:10:35,288
f is X if I was nicer to you I would

2637
02:10:33,248 --> 02:10:37,029
have used the same letters as the paper

2638
02:10:35,288 --> 02:10:39,969
but I was too busy getting this damn

2639
02:10:37,029 --> 02:10:41,768
thing working to do that carefully so

2640
02:10:39,969 --> 02:10:45,309
you can go back and rename it as capital

2641
02:10:41,769 --> 02:10:46,479
F okay and this is why we moved the L to

2642
02:10:45,309 --> 02:10:48,849
the top is because we're now going to

2643
02:10:46,479 --> 02:10:51,429
have some more indexing right so like

2644
02:10:48,849 --> 02:10:53,110
where else your numpy or apply torch we

2645
02:10:51,429 --> 02:10:55,179
index things by square brackets and then

2646
02:10:53,109 --> 02:10:57,398
lots of things with commas between the

2647
02:10:55,179 --> 02:11:00,130
approach in math is to like surround

2648
02:10:57,399 --> 02:11:02,949
your letter by little letters all around

2649
02:11:00,130 --> 02:11:05,229
it okay and just throw them up there

2650
02:11:02,948 --> 02:11:08,978
everywhere so here F L is the elf layer

2651
02:11:05,229 --> 02:11:13,989
of F and then I J is the activation of

2652
02:11:08,979 --> 02:11:18,399
the I filter at position J of layer yeah

2653
02:11:13,988 --> 02:11:20,708
right so position J is cut up to size M

2654
02:11:18,399 --> 02:11:21,820
which is up to size height by width this

2655
02:11:20,708 --> 02:11:24,069
is the kind of thing that be easy to get

2656
02:11:21,819 --> 02:11:26,438
confused like often you'd see an IJ and

2657
02:11:24,069 --> 02:11:28,148
assume that's like indexing into a

2658
02:11:26,439 --> 02:11:30,909
position of an image like height by

2659
02:11:28,149 --> 02:11:36,429
width but it's totally not is it okay

2660
02:11:30,908 --> 02:11:39,158
it's indexing into channel by flattened

2661
02:11:36,429 --> 02:11:42,489
image right and it even tells you it's

2662
02:11:39,158 --> 02:11:45,368
the I filter the earth channel in the

2663
02:11:42,488 --> 02:11:49,058
J's position in the flattened out image

2664
02:11:45,368 --> 02:11:51,328
in layer L right so you you're not gonna

2665
02:11:49,059 --> 02:11:54,159
be able to get any further in the paper

2666
02:11:51,328 --> 02:11:58,418
unless you know unless you understand

2667
02:11:54,158 --> 02:12:00,938
what F is okay so that's why like these

2668
02:11:58,418 --> 02:12:06,359
are the bits where you stop and make

2669
02:12:00,939 --> 02:12:06,360
sure you're comfortable all right so now

2670
02:12:06,748 --> 02:12:10,779
the content lost so I'm not going to

2671
02:12:08,918 --> 02:12:13,179
spend much time on but basically we're

2672
02:12:10,779 --> 02:12:19,259
going to just check out the values of

2673
02:12:13,179 --> 02:12:22,179
the activations versus the predictions

2674
02:12:19,260 --> 02:12:25,300
squared right so there's our content

2675
02:12:22,179 --> 02:12:26,889
loss okay and the style loss will be

2676
02:12:25,300 --> 02:12:29,918
much the same thing but using the grande

2677
02:12:26,889 --> 02:12:31,208
matrix G okay and I really wanted to

2678
02:12:29,918 --> 02:12:33,760
show you this ones I think it's super

2679
02:12:31,208 --> 02:12:34,920
this is sometimes I really like things

2680
02:12:33,760 --> 02:12:36,449
you can do in math note

2681
02:12:34,920 --> 02:12:39,840
and they're things that you can also

2682
02:12:36,449 --> 02:12:42,149
generally do in J and APL which is this

2683
02:12:39,840 --> 02:12:44,940
kind of this implicit loop going on here

2684
02:12:42,149 --> 02:12:47,309
right what this is saying is there's a

2685
02:12:44,939 --> 02:12:49,409
whole bunch of values of I and a whole

2686
02:12:47,310 --> 02:12:52,530
bunch of values of J and I'm going to

2687
02:12:49,409 --> 02:12:54,090
define G for all of them and there's a

2688
02:12:52,529 --> 02:12:55,559
whole bunch of values of L as well I'm

2689
02:12:54,090 --> 02:12:58,829
going to define G for all of those as

2690
02:12:55,560 --> 02:13:01,080
well right and so for all of my G at

2691
02:12:58,829 --> 02:13:03,600
every L of every I at every J it's going

2692
02:13:01,079 --> 02:13:08,130
to be equal to something and you can see

2693
02:13:03,600 --> 02:13:09,329
that something has an i and a J and an L

2694
02:13:08,130 --> 02:13:11,579
right

2695
02:13:09,329 --> 02:13:13,920
so matching these and it also has a K

2696
02:13:11,579 --> 02:13:17,579
and that's part of the sum

2697
02:13:13,920 --> 02:13:22,920
so what's going on here well it's saying

2698
02:13:17,579 --> 02:13:25,769
that my grand matre --ks in layer l for

2699
02:13:22,920 --> 02:13:27,300
the eighth channel

2700
02:13:25,770 --> 02:13:29,910
well there's out channels anymore in the

2701
02:13:27,300 --> 02:13:35,390
eighth position in one axis and the j DH

2702
02:13:29,909 --> 02:13:40,050
position and another axis is equal to my

2703
02:13:35,390 --> 02:13:45,270
F matrix so my flattened out matrix for

2704
02:13:40,050 --> 02:13:49,070
the eighth channel in that layer versus

2705
02:13:45,270 --> 02:13:51,960
the jafe channel and the same layer and

2706
02:13:49,069 --> 02:13:53,939
then I'm going to sum over I'm going to

2707
02:13:51,960 --> 02:13:56,520
say see this K in this case are the same

2708
02:13:53,939 --> 02:13:59,189
letter right so we're going to take the

2709
02:13:56,520 --> 02:14:02,580
k DH position and multiply them together

2710
02:13:59,189 --> 02:14:04,139
and then add them all up all right so

2711
02:14:02,579 --> 02:14:06,059
that's exactly what we just did before

2712
02:14:04,140 --> 02:14:09,350
when we calculated our own matrix right

2713
02:14:06,060 --> 02:14:12,770
so like this there's a lot going on

2714
02:14:09,350 --> 02:14:15,539
because of some like to me very neat

2715
02:14:12,770 --> 02:14:18,360
notation right which is there are three

2716
02:14:15,539 --> 02:14:21,000
implicit loops or going on at the same

2717
02:14:18,359 --> 02:14:23,219
time plus one explicit loop in the Sun

2718
02:14:21,000 --> 02:14:26,010
and then they all work together to

2719
02:14:23,220 --> 02:14:28,650
create this grand matrix for every layer

2720
02:14:26,010 --> 02:14:38,699
that's so let's go back and see if you

2721
02:14:28,649 --> 02:14:40,859
can match this yeah so so oh that's kind

2722
02:14:38,699 --> 02:14:47,099
of happening all at once which i think

2723
02:14:40,859 --> 02:14:48,710
is pretty great okay so that's it so

2724
02:14:47,100 --> 02:14:51,500
next week we're going to be looking

2725
02:14:48,710 --> 02:14:53,989
at a very similar approach basically

2726
02:14:51,500 --> 02:14:55,279
doing style transfer all over again but

2727
02:14:53,988 --> 02:14:57,799
in a way where we were actually going to

2728
02:14:55,279 --> 02:14:59,000
train a neural network to do it for us

2729
02:14:57,800 --> 02:15:01,190
rather than having to do the

2730
02:14:59,000 --> 02:15:03,229
optimization and we'll also see that you

2731
02:15:01,189 --> 02:15:05,719
can do the same thing to do super

2732
02:15:03,229 --> 02:15:10,059
resolution and we're also going to go

2733
02:15:05,719 --> 02:15:14,350
back and revisit some of that SSD stuff

2734
02:15:10,060 --> 02:15:18,650
as well as doing some some segmentation

2735
02:15:14,350 --> 02:15:20,420
so if you're if you've forgotten SSD

2736
02:15:18,649 --> 02:15:23,119
might be worth doing a little bit of

2737
02:15:20,420 --> 02:15:26,109
revision this week all right thanks

2738
02:15:23,119 --> 02:15:26,109
everybody see you next week

2739
02:15:26,590 --> 02:15:29,439
[Applause]

