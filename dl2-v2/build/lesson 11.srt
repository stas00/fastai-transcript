1
00:00:01,949 --> 00:00:04,980
what a start pointing out a couple of

2
00:00:03,509 --> 00:00:07,918
the many cool things that happen this

3
00:00:04,980 --> 00:00:11,210
week one thing that I'm really excited

4
00:00:07,918 --> 00:00:15,599
about is we briefly talked about how

5
00:00:11,210 --> 00:00:19,469
Leslie Smith has a new paper out and it

6
00:00:15,599 --> 00:00:21,929
basically the paper goes text is

7
00:00:19,469 --> 00:00:24,710
previous to key papers are cyclic or

8
00:00:21,929 --> 00:00:26,789
learning rates and super convergence and

9
00:00:24,710 --> 00:00:30,660
built on them with a number of

10
00:00:26,789 --> 00:00:33,359
experiments to show how how you can

11
00:00:30,660 --> 00:00:36,119
achieve super convergence and so super

12
00:00:33,359 --> 00:00:40,049
convergence lets you train models five

13
00:00:36,119 --> 00:00:42,628
times faster than previous like kind of

14
00:00:40,049 --> 00:00:45,179
stepwise approaches it's not 5 times

15
00:00:42,628 --> 00:00:47,670
faster than CLR but it's faster than CLR

16
00:00:45,179 --> 00:00:50,759
as well and the key is that super

17
00:00:47,670 --> 00:00:54,649
convergence lets you get up to like

18
00:00:50,759 --> 00:00:59,009
massively high learning rates by

19
00:00:54,649 --> 00:01:01,289
somewhere between 1 and 3 which is quite

20
00:00:59,009 --> 00:01:08,129
amazing and so the interesting thing

21
00:01:01,289 --> 00:01:10,500
about super convergence is that it you

22
00:01:08,129 --> 00:01:11,879
actually train at those very high

23
00:01:10,500 --> 00:01:14,609
learning rates for quite a large

24
00:01:11,879 --> 00:01:17,039
percentage of your ybox and during that

25
00:01:14,609 --> 00:01:20,579
time the loss doesn't really improve

26
00:01:17,040 --> 00:01:22,469
very much but the trick is like it's

27
00:01:20,579 --> 00:01:24,989
doing a lot of searching through the

28
00:01:22,469 --> 00:01:29,099
space to find really generalizable areas

29
00:01:24,989 --> 00:01:31,140
it seems so those we kind of had a lot

30
00:01:29,099 --> 00:01:32,849
of what we needed in fast AI to achieve

31
00:01:31,140 --> 00:01:36,329
this but we're missing a couple of bits

32
00:01:32,849 --> 00:01:38,368
and so silver Google has done an amazing

33
00:01:36,328 --> 00:01:41,548
job of fleshing out the pieces that

34
00:01:38,368 --> 00:01:43,769
we're missing and then confirming that

35
00:01:41,549 --> 00:01:46,079
he has actually achieved super

36
00:01:43,769 --> 00:01:47,459
convergence on training on say 5 10 so I

37
00:01:46,078 --> 00:01:49,618
think this is the first time that this

38
00:01:47,459 --> 00:01:52,289
has been done that I've heard of outside

39
00:01:49,618 --> 00:01:54,899
of Leslie Smith himself and so he's got

40
00:01:52,290 --> 00:01:56,640
a great blog post up now on one cycle

41
00:01:54,899 --> 00:02:00,359
which is what Leslie Smith called this

42
00:01:56,640 --> 00:02:03,890
approach and this is actually it turns

43
00:02:00,359 --> 00:02:08,189
out what one cycle looks like it's a

44
00:02:03,890 --> 00:02:09,989
single cyclic or learning rate but the

45
00:02:08,189 --> 00:02:12,689
key difference here is that the the

46
00:02:09,989 --> 00:02:13,890
going up be it is the same length as

47
00:02:12,689 --> 00:02:15,539
they're going down

48
00:02:13,889 --> 00:02:17,639
right so you go up like really slowly

49
00:02:15,539 --> 00:02:19,889
and then at the end for like a tenth of

50
00:02:17,639 --> 00:02:23,479
the time you you then have this little

51
00:02:19,889 --> 00:02:25,439
bit where you go down even further and

52
00:02:23,479 --> 00:02:27,329
it's interesting obviously this is a

53
00:02:25,439 --> 00:02:30,599
very easy thing to show very easy thing

54
00:02:27,330 --> 00:02:32,910
to explain Sylvia has added at a fast AI

55
00:02:30,599 --> 00:02:37,259
under the temporarily it's it's called

56
00:02:32,909 --> 00:02:39,299
use CLR beta by the time you watch this

57
00:02:37,259 --> 00:02:43,769
on the video it'll probably be called

58
00:02:39,300 --> 00:02:46,650
one cycle something like that but you

59
00:02:43,770 --> 00:02:48,210
can use this right now so that's one key

60
00:02:46,650 --> 00:02:50,520
piece to getting these massively high

61
00:02:48,210 --> 00:02:52,710
learning rates and he shows a number of

62
00:02:50,520 --> 00:02:54,600
experiments when you do that a second

63
00:02:52,710 --> 00:02:57,510
key piece is that as you do this to the

64
00:02:54,599 --> 00:02:59,909
learning rate you do this to the

65
00:02:57,509 --> 00:03:01,769
momentum right so when the loading rates

66
00:02:59,909 --> 00:03:03,780
low it's fine to have a high momentum

67
00:03:01,770 --> 00:03:07,370
but then when the learning rate gets up

68
00:03:03,780 --> 00:03:11,969
really high your momentum needs to be

69
00:03:07,370 --> 00:03:13,920
quite a bit lower so this is also part

70
00:03:11,969 --> 00:03:16,469
of our what he's added to the library is

71
00:03:13,919 --> 00:03:20,099
this cyclic all momentum and so with

72
00:03:16,469 --> 00:03:21,209
with with these two things you can train

73
00:03:20,099 --> 00:03:23,699
for about the fifth of the number of

74
00:03:21,209 --> 00:03:25,770
epochs with stepwise learning rate

75
00:03:23,699 --> 00:03:27,509
schedule then you can drop your weight

76
00:03:25,770 --> 00:03:28,200
decay down by about two orders of

77
00:03:27,509 --> 00:03:30,840
magnitude

78
00:03:28,199 --> 00:03:32,609
you can often remove most or all of your

79
00:03:30,840 --> 00:03:33,930
drop out and so you end up with

80
00:03:32,610 --> 00:03:37,770
something that's trained

81
00:03:33,930 --> 00:03:39,599
faster and generalizes better and it

82
00:03:37,770 --> 00:03:41,520
actually turns out that silver got quite

83
00:03:39,599 --> 00:03:44,879
a bit better accuracy than Leslie

84
00:03:41,520 --> 00:03:47,250
Smith's paper his guess I was pleased to

85
00:03:44,879 --> 00:03:49,229
see is because our data augmentation

86
00:03:47,250 --> 00:03:50,330
defaults are better than less visas I

87
00:03:49,229 --> 00:03:53,699
hope that's true

88
00:03:50,330 --> 00:03:55,500
so check that out another cool thing I

89
00:03:53,699 --> 00:03:56,669
just as I say there's been so many cool

90
00:03:55,500 --> 00:04:01,439
things this week I'm just going to pick

91
00:03:56,669 --> 00:04:05,429
two Hamill who seen who's a works at

92
00:04:01,439 --> 00:04:07,650
github I just really like this there's a

93
00:04:05,430 --> 00:04:11,239
fairly new project called our cube flow

94
00:04:07,650 --> 00:04:16,548
which is basically 10250 for kubernetes

95
00:04:11,239 --> 00:04:18,989
Hamill wrote a very nice article about

96
00:04:16,548 --> 00:04:21,828
magical sequence to sequence models

97
00:04:18,988 --> 00:04:26,538
building data products on that

98
00:04:21,829 --> 00:04:29,930
and using kubernetes to kind of put that

99
00:04:26,538 --> 00:04:32,899
in production and so forth he said that

100
00:04:29,930 --> 00:04:34,959
the Google cou flow team created a demo

101
00:04:32,899 --> 00:04:36,859
based on what he wrote earlier this year

102
00:04:34,959 --> 00:04:39,769
directly based on the skills on moon

103
00:04:36,860 --> 00:04:42,229
fast AI and I will be presenting this

104
00:04:39,769 --> 00:04:46,159
technique at KD DK t DS one of the top

105
00:04:42,228 --> 00:04:47,750
academic conferences so I wanted to

106
00:04:46,160 --> 00:04:50,990
share this as a motivation for folks to

107
00:04:47,750 --> 00:04:52,490
blog which i think is a great point you

108
00:04:50,990 --> 00:04:55,519
know I don't nobody who goes out and

109
00:04:52,490 --> 00:04:57,379
writes a blog things that you know

110
00:04:55,519 --> 00:04:58,430
probably you know none of us really

111
00:04:57,379 --> 00:05:00,168
think our blog is actually going to be

112
00:04:58,430 --> 00:05:02,240
very good probably nobody's gonna read

113
00:05:00,168 --> 00:05:03,740
it you know and then when people

114
00:05:02,240 --> 00:05:05,269
actually do like it and read it it's

115
00:05:03,740 --> 00:05:06,918
like with great surprise you just got

116
00:05:05,269 --> 00:05:10,549
over that's actually something people

117
00:05:06,918 --> 00:05:14,359
were interested to read so here is the

118
00:05:10,550 --> 00:05:16,069
the tool where you can summarize github

119
00:05:14,360 --> 00:05:18,650
issues using this tool which is now

120
00:05:16,069 --> 00:05:20,569
hosted by Google on their Cooper org

121
00:05:18,649 --> 00:05:24,859
domain so I think that's a great story

122
00:05:20,569 --> 00:05:26,720
of getting you know if Emeril didn't put

123
00:05:24,860 --> 00:05:29,000
his work out there none of this would

124
00:05:26,720 --> 00:05:34,539
have happened and yeah you can check out

125
00:05:29,000 --> 00:05:34,538
his post that made it all happen as well

126
00:05:35,529 --> 00:05:45,138
so talking of the magic of sequence to

127
00:05:39,019 --> 00:05:48,549
sequence models let's build one so we're

128
00:05:45,139 --> 00:05:53,060
going to be specifically working on

129
00:05:48,550 --> 00:05:56,000
machine translation so machine

130
00:05:53,060 --> 00:05:57,978
translation is a something that's been

131
00:05:56,000 --> 00:05:59,120
around for a long time but specifically

132
00:05:57,978 --> 00:06:01,129
we're going to look at an approach

133
00:05:59,120 --> 00:06:05,300
called neural translation which is using

134
00:06:01,129 --> 00:06:07,610
neural networks for translation and they

135
00:06:05,300 --> 00:06:10,520
didn't know that wasn't really a thing

136
00:06:07,610 --> 00:06:14,658
in any kind of meaningful way until a

137
00:06:10,519 --> 00:06:16,939
couple of years ago and so thanks to

138
00:06:14,658 --> 00:06:21,468
Chris Manning from Stanford for the next

139
00:06:16,939 --> 00:06:23,478
three slides 2015 Chris pointed out that

140
00:06:21,468 --> 00:06:25,310
neural machine translation kind of first

141
00:06:23,478 --> 00:06:27,109
appeared properly and it was pretty

142
00:06:25,310 --> 00:06:28,699
crappy compared to the statistical

143
00:06:27,110 --> 00:06:30,468
machine translation approaches that use

144
00:06:28,699 --> 00:06:33,020
kind of classic like feature engineering

145
00:06:30,468 --> 00:06:34,248
and standard MLP kind of approaches of

146
00:06:33,019 --> 00:06:37,878
lots of

147
00:06:34,249 --> 00:06:39,528
stemming and fiddling around this work

148
00:06:37,879 --> 00:06:43,579
frequencies and engrams and lots of

149
00:06:39,528 --> 00:06:46,908
stuff by a year later it was better than

150
00:06:43,579 --> 00:06:48,108
everything else this is on a metric

151
00:06:46,908 --> 00:06:49,579
called blue we're not going to discuss

152
00:06:48,108 --> 00:06:51,618
the metric because it's not a very good

153
00:06:49,579 --> 00:06:54,588
metric and it's not very interesting but

154
00:06:51,619 --> 00:06:57,379
it's what everybody uses so that was

155
00:06:54,588 --> 00:07:01,809
blue as of when Chris did this slide as

156
00:06:57,379 --> 00:07:05,569
of now it's about up here it's about 30

157
00:07:01,809 --> 00:07:08,709
so we're kind of seeing machine

158
00:07:05,569 --> 00:07:12,739
translation starting down the path that

159
00:07:08,709 --> 00:07:15,649
we saw starting computer vision object

160
00:07:12,738 --> 00:07:17,778
classification in 2012 I guess which is

161
00:07:15,649 --> 00:07:20,088
you know we kind of just surpassed the

162
00:07:17,778 --> 00:07:24,408
state of the art and now we're zipping

163
00:07:20,088 --> 00:07:26,689
past it at a great rate it's very

164
00:07:24,408 --> 00:07:29,868
unlikely that anybody watching this is

165
00:07:26,689 --> 00:07:33,439
actually gonna build a machine

166
00:07:29,869 --> 00:07:35,689
translation model because you can go to

167
00:07:33,439 --> 00:07:37,759
translate Google calm and use theirs and

168
00:07:35,689 --> 00:07:40,159
it works quite well so why are we

169
00:07:37,759 --> 00:07:41,119
learning about machine translation well

170
00:07:40,158 --> 00:07:43,459
the reason we're learning about machine

171
00:07:41,119 --> 00:07:45,919
translation is that the general idea of

172
00:07:43,459 --> 00:07:49,189
taking some kind of input like a

173
00:07:45,918 --> 00:07:51,498
sentence in french and transforming it

174
00:07:49,189 --> 00:07:54,459
into some other kind of output with

175
00:07:51,499 --> 00:07:57,939
arbitrary length such as a sentence in

176
00:07:54,459 --> 00:08:01,429
english is a really useful thing to do

177
00:07:57,939 --> 00:08:04,579
for example the thing that we just saw

178
00:08:01,428 --> 00:08:07,149
that ham all that github did tex github

179
00:08:04,579 --> 00:08:10,158
issues and turns them into summaries

180
00:08:07,149 --> 00:08:15,228
other examples is taking videos and

181
00:08:10,158 --> 00:08:18,949
turning them into descriptions or taking

182
00:08:15,228 --> 00:08:21,258
a well I don't know I mean like you know

183
00:08:18,949 --> 00:08:23,869
basically anything where you're spitting

184
00:08:21,259 --> 00:08:25,459
out kind of an arbitrary sized output

185
00:08:23,869 --> 00:08:27,949
very often that's a sentence so maybe

186
00:08:25,459 --> 00:08:31,038
taking a CT scan and spitting out a

187
00:08:27,949 --> 00:08:32,269
radiology report you know this is where

188
00:08:31,038 --> 00:08:34,990
you can use sequence to sequence

189
00:08:32,269 --> 00:08:34,990
learning

190
00:08:36,330 --> 00:08:42,990
so the important thing about a neural

191
00:08:41,309 --> 00:08:45,958
machine translation these are more

192
00:08:42,990 --> 00:08:47,820
slides from Chris and and generally six

193
00:08:45,958 --> 00:08:52,429
a sequence of sequence models is that

194
00:08:47,820 --> 00:08:55,350
you know there's no fussing around with

195
00:08:52,429 --> 00:08:56,729
heuristics and Haacke you know feature

196
00:08:55,350 --> 00:08:59,550
engineering whatever it's end-to-end

197
00:08:56,730 --> 00:09:01,470
training we're able to build these

198
00:08:59,549 --> 00:09:03,629
distributed representations which are

199
00:09:01,470 --> 00:09:06,180
shared by lots of kind of concepts

200
00:09:03,629 --> 00:09:09,149
within a single network we're able to

201
00:09:06,179 --> 00:09:11,009
use long term State in the air and ENSO

202
00:09:09,149 --> 00:09:13,379
use a lot more context than kind of

203
00:09:11,009 --> 00:09:15,809
Engram type approaches and in the end

204
00:09:13,379 --> 00:09:17,370
the text we're generating uses an iron

205
00:09:15,809 --> 00:09:21,449
in as well so we can build something

206
00:09:17,370 --> 00:09:25,500
that's more fluid we're going to use a

207
00:09:21,450 --> 00:09:26,070
bi-directional LS TM with attention well

208
00:09:25,500 --> 00:09:27,509
actually were going to use a

209
00:09:26,070 --> 00:09:29,010
bi-directional giu

210
00:09:27,509 --> 00:09:30,649
with attention but basically the same

211
00:09:29,009 --> 00:09:32,970
thing so you already know about

212
00:09:30,649 --> 00:09:35,220
bi-directional recurrent neural networks

213
00:09:32,970 --> 00:09:37,829
and attention we're going to add on top

214
00:09:35,220 --> 00:09:40,560
today these general ideas you can use or

215
00:09:37,828 --> 00:09:50,549
lots of other things as well as Chris

216
00:09:40,559 --> 00:09:55,409
points out on this slide so let's jump

217
00:09:50,549 --> 00:10:04,349
into the code which is in the translate

218
00:09:55,409 --> 00:10:08,370
notebook funnily enough and so we're

219
00:10:04,350 --> 00:10:13,970
going to try to translate French into

220
00:10:08,370 --> 00:10:16,379
English and so the basic idea is that

221
00:10:13,970 --> 00:10:18,899
we're going to try and make this look as

222
00:10:16,379 --> 00:10:21,448
much like a standard neural network

223
00:10:18,899 --> 00:10:23,578
approach as possible so we're going to

224
00:10:21,448 --> 00:10:29,129
need three things you will remember the

225
00:10:23,578 --> 00:10:32,250
three things data a suitable

226
00:10:29,129 --> 00:10:34,169
architecture and a suitable loss

227
00:10:32,250 --> 00:10:38,370
function once you've got these three

228
00:10:34,169 --> 00:10:39,958
things you run fit and all things going

229
00:10:38,370 --> 00:10:43,589
well you end up with something that

230
00:10:39,958 --> 00:10:47,849
solves your problem okay so data you

231
00:10:43,589 --> 00:10:48,610
know we generally need XY pairs okay

232
00:10:47,850 --> 00:10:50,170
because we

233
00:10:48,610 --> 00:10:52,919
need something which we can feed it into

234
00:10:50,169 --> 00:10:57,778
the loss function and say I took my

235
00:10:52,919 --> 00:11:00,399
x-value which was my French sentence and

236
00:10:57,778 --> 00:11:03,338
the loss function says it was meant to

237
00:11:00,399 --> 00:11:06,039
generate this English sentence and then

238
00:11:03,339 --> 00:11:08,320
you had your predictions which you would

239
00:11:06,039 --> 00:11:10,769
then compare and see how good it is okay

240
00:11:08,320 --> 00:11:14,230
so therefore we need lots of these

241
00:11:10,769 --> 00:11:16,600
tuples of french sentences with their

242
00:11:14,230 --> 00:11:19,000
equivalent English sentence that's

243
00:11:16,600 --> 00:11:22,269
called a parallel corpus obviously this

244
00:11:19,000 --> 00:11:23,379
is harder to find than a corpus for a

245
00:11:22,269 --> 00:11:26,578
language model because for a language

246
00:11:23,379 --> 00:11:30,059
model we just need text in some language

247
00:11:26,578 --> 00:11:33,699
which you can basically all for any

248
00:11:30,059 --> 00:11:36,539
living language of which the people that

249
00:11:33,700 --> 00:11:39,910
use that language like use computers

250
00:11:36,539 --> 00:11:41,649
there will be a few gigabytes at least

251
00:11:39,909 --> 00:11:43,179
of text floating around the internet for

252
00:11:41,649 --> 00:11:47,708
you to grab okay so building a language

253
00:11:43,179 --> 00:11:50,049
model is only challenging corpus wise or

254
00:11:47,708 --> 00:11:51,879
you know ancient languages one of our

255
00:11:50,049 --> 00:11:54,490
students is trying to do a Sanskrit one

256
00:11:51,879 --> 00:11:57,490
for example at the moment but that's

257
00:11:54,490 --> 00:11:59,289
very rarely a problem for translation

258
00:11:57,490 --> 00:12:01,750
there are actually some pretty good

259
00:11:59,289 --> 00:12:03,639
parallel corpus is available for

260
00:12:01,750 --> 00:12:06,250
European languages the European

261
00:12:03,639 --> 00:12:09,129
Parliament basically has every sentence

262
00:12:06,250 --> 00:12:11,440
in every European language anything that

263
00:12:09,129 --> 00:12:14,799
goes through the UN is translated to

264
00:12:11,440 --> 00:12:17,050
lots of languages for French to English

265
00:12:14,799 --> 00:12:20,729
we have a particularly nice thing which

266
00:12:17,049 --> 00:12:23,859
is pretty much any semi official

267
00:12:20,730 --> 00:12:26,889
Canadian web site I will have a French

268
00:12:23,860 --> 00:12:29,620
version and an English version and so

269
00:12:26,889 --> 00:12:31,448
this chap kursk Ellison birch did a cool

270
00:12:29,620 --> 00:12:33,759
thing which is basically to try to

271
00:12:31,448 --> 00:12:37,509
transform French URLs into English URLs

272
00:12:33,759 --> 00:12:39,250
by like replacing - if I am and hoping

273
00:12:37,509 --> 00:12:42,429
that that retrieves the equivalent

274
00:12:39,250 --> 00:12:44,820
document and then did that for lots and

275
00:12:42,429 --> 00:12:48,669
lots of web sites and into that creating

276
00:12:44,820 --> 00:12:50,350
a huge corpus based on millions of web

277
00:12:48,669 --> 00:12:54,759
pages so a French to English we have

278
00:12:50,350 --> 00:12:55,959
this particularly nice resource so we're

279
00:12:54,759 --> 00:12:57,549
going to start out by talking about how

280
00:12:55,958 --> 00:12:59,139
to create the data then we'll look at

281
00:12:57,549 --> 00:13:02,599
the architecture and then we'll look at

282
00:12:59,139 --> 00:13:05,448
the loss function and so for

283
00:13:02,600 --> 00:13:08,240
bounding boxes all of the interesting

284
00:13:05,448 --> 00:13:09,948
stuff was in the loss function but for

285
00:13:08,240 --> 00:13:11,539
New York translation all of the

286
00:13:09,948 --> 00:13:16,429
interesting stuff is going to be in the

287
00:13:11,539 --> 00:13:17,958
architecture okay so let's zip through

288
00:13:16,429 --> 00:13:18,979
this pretty quickly and one of the

289
00:13:17,958 --> 00:13:21,739
things I want you to think about

290
00:13:18,980 --> 00:13:23,659
particularly is what are the

291
00:13:21,740 --> 00:13:25,698
relationships the similarities in terms

292
00:13:23,659 --> 00:13:28,909
of the tasks we're doing and how we do

293
00:13:25,698 --> 00:13:32,318
it between language modeling versus euro

294
00:13:28,909 --> 00:13:32,318
translation okay

295
00:13:33,068 --> 00:13:40,909
so the basic approach here is that we're

296
00:13:38,120 --> 00:13:43,459
going to take a sentence so this case

297
00:13:40,909 --> 00:13:45,519
this example is English to German and

298
00:13:43,458 --> 00:13:48,789
this slides through Mon Steven emeriti

299
00:13:45,519 --> 00:13:51,919
we steal everything we can from Steven

300
00:13:48,789 --> 00:13:54,049
we start with some sentence in English

301
00:13:51,919 --> 00:13:56,179
and the first step is to do basically

302
00:13:54,049 --> 00:13:58,879
the exact same thing we do in a language

303
00:13:56,179 --> 00:14:04,809
model which is to chuck it through an R

304
00:13:58,879 --> 00:14:06,769
in it now with our language model

305
00:14:04,809 --> 00:14:08,179
actually that's not even think that

306
00:14:06,769 --> 00:14:10,129
language model let's start even easier

307
00:14:08,179 --> 00:14:13,039
the classification model okay so

308
00:14:10,129 --> 00:14:17,799
something that turns some this sentence

309
00:14:13,039 --> 00:14:26,809
into positive or negative sentiment we

310
00:14:17,799 --> 00:14:31,639
had a a decoder you know something which

311
00:14:26,809 --> 00:14:33,500
basically took the RNN output and from

312
00:14:31,639 --> 00:14:35,930
our paper we grabbed three things we

313
00:14:33,500 --> 00:14:37,669
took a max pull over all of the time

314
00:14:35,929 --> 00:14:39,828
steps we took a mean port over there all

315
00:14:37,669 --> 00:14:42,649
the time steps and we took the value of

316
00:14:39,828 --> 00:14:44,568
the iron in at the last time step stack

317
00:14:42,649 --> 00:14:48,110
all those together and put it through a

318
00:14:44,568 --> 00:14:51,500
linear layer most people don't do that

319
00:14:48,110 --> 00:14:54,259
in most NLP stuff this is a like I think

320
00:14:51,500 --> 00:14:57,110
it's something we invented people pretty

321
00:14:54,259 --> 00:14:58,129
much always use the last time step so

322
00:14:57,110 --> 00:15:02,329
all the stuff we'll be talking about

323
00:14:58,129 --> 00:15:04,458
today uses the last time step so we

324
00:15:02,328 --> 00:15:07,028
start out by chucking this sentence

325
00:15:04,458 --> 00:15:11,149
through an R and N and out of it comes

326
00:15:07,028 --> 00:15:14,179
some state right so some state meaning

327
00:15:11,149 --> 00:15:16,190
some hidden state some vector that

328
00:15:14,179 --> 00:15:19,039
represents the output of an hour

329
00:15:16,190 --> 00:15:20,480
that is encoded that sentence you'll see

330
00:15:19,039 --> 00:15:23,959
the word that Steven used here was

331
00:15:20,480 --> 00:15:26,539
encoder we've tended to use the word

332
00:15:23,960 --> 00:15:28,850
backbone right so like when we've talked

333
00:15:26,539 --> 00:15:30,500
about like adding a custom head to an

334
00:15:28,850 --> 00:15:32,750
existing model like you know the

335
00:15:30,500 --> 00:15:34,039
existing pre-trained imagenet model for

336
00:15:32,750 --> 00:15:36,080
example we kind of say that's our

337
00:15:34,039 --> 00:15:38,149
backbone and then we stick on top of it

338
00:15:36,080 --> 00:15:42,190
some-some head that does the task we

339
00:15:38,149 --> 00:15:44,809
want in sequence to sequence learning

340
00:15:42,190 --> 00:15:46,760
they use the word encoder but it

341
00:15:44,809 --> 00:15:48,529
basically it's the same thing it's some

342
00:15:46,759 --> 00:15:51,939
piece of a neural network architecture

343
00:15:48,529 --> 00:15:55,039
that takes the input and turns it into

344
00:15:51,940 --> 00:15:56,510
you know some representation which we

345
00:15:55,039 --> 00:15:59,779
can then stick a few more layers on top

346
00:15:56,509 --> 00:16:03,110
of to grab something out of it such as

347
00:15:59,779 --> 00:16:05,720
we did for the classifier where we stuck

348
00:16:03,110 --> 00:16:12,850
a linear layer on top over to turn it

349
00:16:05,720 --> 00:16:15,889
into a sentiment positive or negative so

350
00:16:12,850 --> 00:16:18,740
this time though we have something

351
00:16:15,889 --> 00:16:21,019
that's a little bit harder than just

352
00:16:18,740 --> 00:16:23,330
kiding sentiment which is I want to turn

353
00:16:21,019 --> 00:16:25,429
this state not into a positive or

354
00:16:23,330 --> 00:16:27,920
negative sentiment but into a sequence

355
00:16:25,429 --> 00:16:29,929
of tokens where that sequence of tokens

356
00:16:27,919 --> 00:16:33,860
is the German in this case the German

357
00:16:29,929 --> 00:16:35,689
sentence that we want so this is

358
00:16:33,860 --> 00:16:37,759
sounding more like the language model

359
00:16:35,690 --> 00:16:40,490
than the classifier because the language

360
00:16:37,759 --> 00:16:43,009
model had multiple tokens for every

361
00:16:40,490 --> 00:16:45,529
input word there was an output word but

362
00:16:43,009 --> 00:16:48,139
the language model was also much easier

363
00:16:45,529 --> 00:16:51,049
because the the number of tokens in the

364
00:16:48,139 --> 00:16:52,909
language model output was the same

365
00:16:51,049 --> 00:16:55,370
length as the number of tokens in the

366
00:16:52,909 --> 00:16:57,199
language model input and not only were

367
00:16:55,370 --> 00:16:59,360
there the same length they exactly

368
00:16:57,200 --> 00:17:02,030
matched up it's like after word one

369
00:16:59,360 --> 00:17:03,560
comes word two afterward two comes word

370
00:17:02,029 --> 00:17:07,970
three and so forth right

371
00:17:03,559 --> 00:17:11,000
but for translating language you don't

372
00:17:07,970 --> 00:17:12,828
necessarily know that the word he will

373
00:17:11,000 --> 00:17:14,568
be translated as the first word in the

374
00:17:12,828 --> 00:17:15,769
output and that love will be the second

375
00:17:14,568 --> 00:17:17,299
word in the output I mean in this

376
00:17:15,769 --> 00:17:21,009
particular case unfortunately they are

377
00:17:17,299 --> 00:17:22,938
the same but very often you know the

378
00:17:21,009 --> 00:17:24,349
subject object order will be

379
00:17:22,939 --> 00:17:27,679
differential there will be some extra

380
00:17:24,349 --> 00:17:29,859
words inserted or some pronouns we'll

381
00:17:27,679 --> 00:17:33,640
need to add some gendered article

382
00:17:29,859 --> 00:17:35,079
or whatever okay so this is the key

383
00:17:33,640 --> 00:17:36,850
issue we're gonna have to deal with is

384
00:17:35,079 --> 00:17:40,480
the fact that we have an arbitrary

385
00:17:36,849 --> 00:17:42,849
length output where the tokens in the

386
00:17:40,480 --> 00:17:45,610
output do not correspond to the same

387
00:17:42,849 --> 00:17:48,789
order you know specific tokens in the

388
00:17:45,609 --> 00:17:52,209
input okay but the general idea is the

389
00:17:48,789 --> 00:17:55,839
same here's an RNN to encode the input

390
00:17:52,210 --> 00:17:57,039
turns it into some hidden state and then

391
00:17:55,839 --> 00:18:00,519
this is the new thing we're going to

392
00:17:57,039 --> 00:18:04,589
learn is generating a sequence output so

393
00:18:00,519 --> 00:18:08,048
we already know sequence two plus that's

394
00:18:04,589 --> 00:18:10,379
IMDB classifier we already know sequence

395
00:18:08,048 --> 00:18:13,210
two equal length sequence where

396
00:18:10,380 --> 00:18:15,340
corresponds to the same items that's the

397
00:18:13,210 --> 00:18:17,019
language model for example but we don't

398
00:18:15,339 --> 00:18:18,879
know yet how to do a general-purpose

399
00:18:17,019 --> 00:18:22,179
sequence to sequence so that's the new

400
00:18:18,880 --> 00:18:26,740
thing today very little of this will

401
00:18:22,179 --> 00:18:32,169
make sense unless you really understand

402
00:18:26,740 --> 00:18:34,839
lesson six how an RNN works okay so if

403
00:18:32,169 --> 00:18:36,220
some of this lesson doesn't make sense

404
00:18:34,839 --> 00:18:37,959
to you and you find yourself wondering

405
00:18:36,220 --> 00:18:40,900
what does he mean by hidden state

406
00:18:37,960 --> 00:18:43,569
exactly how's that working go back and

407
00:18:40,900 --> 00:18:48,269
re-watch lesson six to give you a very

408
00:18:43,569 --> 00:18:51,009
quick review we learnt that and are an N

409
00:18:48,269 --> 00:18:53,349
at its heart is a standard fully

410
00:18:51,009 --> 00:18:57,129
connected Network so here's one with one

411
00:18:53,349 --> 00:18:59,129
two three four layers right takes an

412
00:18:57,130 --> 00:19:03,100
input and puts it through four layers

413
00:18:59,130 --> 00:19:05,140
but then at the second layer it can just

414
00:19:03,099 --> 00:19:07,178
concatenate in the second important

415
00:19:05,140 --> 00:19:09,450
third layer concatenate in a third input

416
00:19:07,179 --> 00:19:13,090
but we actually wrote this in Python as

417
00:19:09,450 --> 00:19:15,039
just literally a four layer neural

418
00:19:13,089 --> 00:19:19,529
network okay there's nothing else we

419
00:19:15,039 --> 00:19:22,029
used other than linear layers and values

420
00:19:19,529 --> 00:19:23,798
we used the same weight matrix every

421
00:19:22,029 --> 00:19:25,869
time an input came in we used the same

422
00:19:23,798 --> 00:19:27,849
matrix every time we went from one of

423
00:19:25,869 --> 00:19:29,798
these states to the next and that's why

424
00:19:27,849 --> 00:19:32,918
there's errors of the same color and so

425
00:19:29,798 --> 00:19:34,269
we can redraw that previous thing like

426
00:19:32,919 --> 00:19:37,900
this yeah

427
00:19:34,269 --> 00:19:41,259
and so we not only did we redraw it but

428
00:19:37,900 --> 00:19:43,660
we took the you know four lines of

429
00:19:41,259 --> 00:19:48,069
linear linear linear linear code

430
00:19:43,660 --> 00:19:51,220
in pi torch and we replaced it with a

431
00:19:48,069 --> 00:19:52,480
for loop okay so remember we had

432
00:19:51,220 --> 00:19:55,930
something that did exactly the same

433
00:19:52,480 --> 00:19:59,470
thing as this but it just had four lines

434
00:19:55,930 --> 00:20:01,600
of code saying linear linear linear

435
00:19:59,470 --> 00:20:04,180
layer and we really literally replaced

436
00:20:01,599 --> 00:20:07,029
it with a for loop because that's nice

437
00:20:04,180 --> 00:20:10,210
to refactor so like literally that

438
00:20:07,029 --> 00:20:12,369
refactoring which doesn't change any of

439
00:20:10,210 --> 00:20:15,059
the math any of the ideas and if the

440
00:20:12,369 --> 00:20:18,789
outputs that refactoring is entirely

441
00:20:15,059 --> 00:20:21,549
okay turning a bunch of separate lines

442
00:20:18,789 --> 00:20:26,740
in the code into a Python corner okay

443
00:20:21,549 --> 00:20:28,659
and so that's how we can draw it we

444
00:20:26,740 --> 00:20:31,660
could take the output so that it's not

445
00:20:28,660 --> 00:20:35,080
outside the loop and put it inside the

446
00:20:31,660 --> 00:20:37,870
loop like so right and if we do that

447
00:20:35,079 --> 00:20:44,859
we're now going to generate a separate

448
00:20:37,869 --> 00:20:47,769
output for every input so in this case

449
00:20:44,859 --> 00:20:50,319
this particular one here the hidden

450
00:20:47,769 --> 00:20:52,329
state gets replaced each time and we end

451
00:20:50,319 --> 00:20:52,750
up just spitting out the final hidden

452
00:20:52,329 --> 00:20:56,799
State

453
00:20:52,750 --> 00:21:00,309
so this one is this example okay but if

454
00:20:56,799 --> 00:21:03,970
instead we had something that said you

455
00:21:00,309 --> 00:21:06,819
know h's dot append h and returned H's

456
00:21:03,970 --> 00:21:09,279
at the end that would be this picture

457
00:21:06,819 --> 00:21:11,049
yeah and so go back and relook at that

458
00:21:09,279 --> 00:21:12,879
notebook if this is unclear I think the

459
00:21:11,049 --> 00:21:16,109
main thing to remember is when we say

460
00:21:12,880 --> 00:21:17,890
hidden state we're referring to a vector

461
00:21:16,109 --> 00:21:21,129
okay see you

462
00:21:17,890 --> 00:21:25,180
here's the vector right H equals torch

463
00:21:21,130 --> 00:21:26,440
zeroes okay and hidden now of course

464
00:21:25,180 --> 00:21:29,890
it's a vector for each thing in the mini

465
00:21:26,440 --> 00:21:31,600
bash so it's it's a matrix but I'm

466
00:21:29,890 --> 00:21:33,759
generally when I speak about these

467
00:21:31,599 --> 00:21:35,769
things I ignore them in each piece and

468
00:21:33,759 --> 00:21:42,099
treat it for just a single item okay so

469
00:21:35,769 --> 00:21:44,589
it's just a vector of this length we

470
00:21:42,099 --> 00:21:46,149
also learned that you can stack these

471
00:21:44,589 --> 00:21:48,609
layers on top of each other so rather

472
00:21:46,150 --> 00:21:50,920
than this first errand ends bidding our

473
00:21:48,609 --> 00:21:54,809
output there could just spit out inputs

474
00:21:50,920 --> 00:21:54,810
into a second area and

475
00:21:54,910 --> 00:21:59,500
if you're thinking at this point I think

476
00:21:57,400 --> 00:22:01,870
I understand this but I'm not quite sure

477
00:21:59,500 --> 00:22:03,670
if you're anything like that me that

478
00:22:01,869 --> 00:22:05,949
means you don't understand this right

479
00:22:03,670 --> 00:22:07,060
and the only way you know and that you

480
00:22:05,950 --> 00:22:10,750
actually understand it is to go and

481
00:22:07,059 --> 00:22:13,359
write this in from scratch in PI torch

482
00:22:10,750 --> 00:22:14,980
or an umpire okay and if you can't do

483
00:22:13,359 --> 00:22:16,869
that then you know okay you don't

484
00:22:14,980 --> 00:22:18,730
understand it and you can go back and

485
00:22:16,869 --> 00:22:20,409
re-watch the lesson 6 and check out the

486
00:22:18,730 --> 00:22:22,720
notebook and copy some of the ideas

487
00:22:20,410 --> 00:22:24,730
until you can it's really important that

488
00:22:22,720 --> 00:22:28,180
you can write that from scratch it's

489
00:22:24,730 --> 00:22:29,529
less than a screen of code okay

490
00:22:28,180 --> 00:22:34,450
so you want to make sure you can create

491
00:22:29,529 --> 00:22:39,329
a two layer iron okay and this is what

492
00:22:34,450 --> 00:22:41,950
it looks like if you unroll it okay so

493
00:22:39,329 --> 00:22:44,500
that's the goal is to get to a point

494
00:22:41,950 --> 00:22:46,569
that we first of all have these XY pairs

495
00:22:44,500 --> 00:22:48,819
of sentences and we're going to do

496
00:22:46,569 --> 00:22:54,089
French to English so we're going to

497
00:22:48,819 --> 00:22:56,409
start by downloading this data set and

498
00:22:54,089 --> 00:22:58,659
training a translation model takes a

499
00:22:56,410 --> 00:23:00,430
long time

500
00:22:58,660 --> 00:23:02,529
Google's translation model has eight

501
00:23:00,430 --> 00:23:07,090
layers of RNN stacked on top of each

502
00:23:02,529 --> 00:23:08,889
other there's no conceptual difference

503
00:23:07,089 --> 00:23:10,480
between eight layers and two layers it's

504
00:23:08,890 --> 00:23:12,490
just like if you're google and you have

505
00:23:10,480 --> 00:23:14,200
more GPUs GPUs and you know what to do

506
00:23:12,490 --> 00:23:16,569
with then you're fine doing that where

507
00:23:14,200 --> 00:23:17,890
else in our case it's pretty likely that

508
00:23:16,569 --> 00:23:20,169
the kind of sequence to sequence models

509
00:23:17,890 --> 00:23:23,080
we're building are not going to require

510
00:23:20,170 --> 00:23:25,390
that level of computation so to keep

511
00:23:23,079 --> 00:23:26,769
things simple let's do a cut-down thing

512
00:23:25,390 --> 00:23:29,740
where rather than learning how to

513
00:23:26,769 --> 00:23:32,019
translate French into English for any

514
00:23:29,740 --> 00:23:34,599
sentence let's learn to translate French

515
00:23:32,019 --> 00:23:36,069
questions into English questions okay

516
00:23:34,599 --> 00:23:38,439
and specifically questions that start

517
00:23:36,069 --> 00:23:39,789
with what where which when okay so you

518
00:23:38,440 --> 00:23:42,400
can see here I've got a regex it looks

519
00:23:39,789 --> 00:23:44,079
for things at start of WH and in with a

520
00:23:42,400 --> 00:23:46,480
question mark so I just go through the

521
00:23:44,079 --> 00:23:50,859
corpus open up each of the two files

522
00:23:46,480 --> 00:23:52,599
each line is one parallel text written

523
00:23:50,859 --> 00:23:54,549
together I grab the English question the

524
00:23:52,599 --> 00:23:57,789
French question and check whether they

525
00:23:54,549 --> 00:23:59,349
match the regular submissions okay dump

526
00:23:57,789 --> 00:24:01,359
that out was the pickle and so they

527
00:23:59,349 --> 00:24:05,079
don't have to do it again and so we now

528
00:24:01,359 --> 00:24:07,269
have 52,000 sentences and here are some

529
00:24:05,079 --> 00:24:08,980
examples with us well sentence pairs and

530
00:24:07,269 --> 00:24:11,710
here are some examples of those

531
00:24:08,980 --> 00:24:13,660
one nice thing about this is that what

532
00:24:11,710 --> 00:24:18,370
who where clap questions tend to be

533
00:24:13,660 --> 00:24:21,580
fairly short which is nice but I would

534
00:24:18,369 --> 00:24:24,189
say the idea that we could learn from

535
00:24:21,579 --> 00:24:26,379
scratch with no previous understanding

536
00:24:24,190 --> 00:24:28,450
of the idea of language let alone of

537
00:24:26,380 --> 00:24:30,400
English or a French that we could create

538
00:24:28,450 --> 00:24:32,860
something that can translate one to the

539
00:24:30,400 --> 00:24:34,390
other for any arbitrary question with

540
00:24:32,859 --> 00:24:36,939
only 50,000 sentences

541
00:24:34,390 --> 00:24:40,240
it sounds like a ludus cursory difficult

542
00:24:36,940 --> 00:24:42,130
thing to ask us to do right so I will be

543
00:24:40,240 --> 00:24:45,069
impressed if we can make any progress

544
00:24:42,130 --> 00:24:49,419
whatsoever this is very little data to

545
00:24:45,069 --> 00:24:52,089
do a very complex exercise correct so

546
00:24:49,419 --> 00:24:54,788
this contains the tuples of French and

547
00:24:52,089 --> 00:24:56,619
English you can use this handy idiom

548
00:24:54,788 --> 00:24:58,058
just pick them apart into a list of

549
00:24:56,619 --> 00:25:00,729
English questions and list of french

550
00:24:58,058 --> 00:25:02,740
questions and then we tokenize the

551
00:25:00,730 --> 00:25:05,169
English question questions and we

552
00:25:02,740 --> 00:25:06,640
tokenize the French questions okay so

553
00:25:05,169 --> 00:25:10,659
remember that just means splitting them

554
00:25:06,640 --> 00:25:12,280
up into separate words or word like

555
00:25:10,659 --> 00:25:15,460
things

556
00:25:12,279 --> 00:25:16,899
by default the tokenizer that we have

557
00:25:15,460 --> 00:25:19,690
here and remember this is a wrapper

558
00:25:16,900 --> 00:25:21,250
around the Spacey tokenizer which is a

559
00:25:19,690 --> 00:25:24,058
fantastic tokenizer

560
00:25:21,250 --> 00:25:26,919
this wrapper by default assumes English

561
00:25:24,058 --> 00:25:29,048
okay so to ask for French you just add

562
00:25:26,919 --> 00:25:30,580
an extra parameter the first time you do

563
00:25:29,048 --> 00:25:32,319
this you'll get an error saying that you

564
00:25:30,579 --> 00:25:35,079
don't have the space you French model

565
00:25:32,319 --> 00:25:37,538
installed and you can Google to get the

566
00:25:35,079 --> 00:25:39,129
command something Python - MS BAE see

567
00:25:37,538 --> 00:25:44,798
download French or something like that

568
00:25:39,130 --> 00:25:45,909
to grab the French model okay I don't

569
00:25:44,798 --> 00:25:47,950
think any of your going to have RAM

570
00:25:45,909 --> 00:25:49,750
problems here because this is not

571
00:25:47,950 --> 00:25:52,029
particularly big corpus but I know that

572
00:25:49,750 --> 00:25:53,558
some of you we're trying to train new

573
00:25:52,029 --> 00:25:56,230
language models during the week and

574
00:25:53,558 --> 00:25:58,359
we're having RAM problems if you do it's

575
00:25:56,230 --> 00:26:00,308
worth knowing what these functions are

576
00:25:58,359 --> 00:26:02,949
actually doing so for example these ones

577
00:26:00,308 --> 00:26:05,019
here is processing every sentence across

578
00:26:02,950 --> 00:26:07,240
multiple processes as well the NP means

579
00:26:05,019 --> 00:26:12,000
and remember you know Farsi our code is

580
00:26:07,240 --> 00:26:12,000
designed to be pretty easy to read so

581
00:26:13,859 --> 00:26:17,559
you know three or four lines of code so

582
00:26:16,269 --> 00:26:20,920
here's the three lines of code to

583
00:26:17,559 --> 00:26:23,259
process or MP find out how many CPUs you

584
00:26:20,920 --> 00:26:24,759
have divided by two because normally

585
00:26:23,259 --> 00:26:29,190
with hyper-threading they don't actually

586
00:26:24,759 --> 00:26:33,819
all work in parallel then in in parallel

587
00:26:29,190 --> 00:26:35,259
run this process function so that's

588
00:26:33,819 --> 00:26:37,779
going to spit out a whole separate

589
00:26:35,259 --> 00:26:39,039
Python process for every CPU you have if

590
00:26:37,779 --> 00:26:41,170
you have a lot of cause that's a lot of

591
00:26:39,039 --> 00:26:43,440
Python processes everyone's going to

592
00:26:41,170 --> 00:26:46,060
load the whole you know all this data in

593
00:26:43,440 --> 00:26:47,830
and that can potentially use up all your

594
00:26:46,059 --> 00:26:50,559
ramped so you could replace that with

595
00:26:47,829 --> 00:26:57,009
just proc all rather than pro or MP to

596
00:26:50,559 --> 00:26:59,470
use less RAM or you could just pros use

597
00:26:57,009 --> 00:27:02,200
less cause so but you know at the moment

598
00:26:59,470 --> 00:27:05,559
we were calling this function partition

599
00:27:02,200 --> 00:27:08,140
by cause which calls partition on a list

600
00:27:05,559 --> 00:27:10,839
and asks to split it into a number of

601
00:27:08,140 --> 00:27:12,970
equal length things according to how

602
00:27:10,839 --> 00:27:14,609
many CPUs you have so you could replace

603
00:27:12,970 --> 00:27:18,539
that you're not splitting it into a

604
00:27:14,609 --> 00:27:22,899
smaller list and read it on less things

605
00:27:18,539 --> 00:27:24,730
yes Rachel was an intention layer tried

606
00:27:22,900 --> 00:27:26,700
in the language model do you think it

607
00:27:24,730 --> 00:27:28,809
would be a good idea to try and add one

608
00:27:26,700 --> 00:27:30,940
we haven't had learned about attention

609
00:27:28,809 --> 00:27:34,419
yet so let's ask about things that we

610
00:27:30,940 --> 00:27:36,340
have cut to not things we haven't the

611
00:27:34,420 --> 00:27:38,259
short answer is no I haven't tried it

612
00:27:36,339 --> 00:27:42,069
properly yes you should try it because

613
00:27:38,259 --> 00:27:43,390
it might help okay and you know in

614
00:27:42,069 --> 00:27:45,669
general there's going to be a lot of

615
00:27:43,390 --> 00:27:47,350
things that we covered a day which if

616
00:27:45,670 --> 00:27:49,180
you've done some sequence to sequence

617
00:27:47,349 --> 00:27:50,980
stuff before you're want to know about

618
00:27:49,180 --> 00:27:52,150
something we haven't covered yet I'm

619
00:27:50,980 --> 00:27:54,370
going to cover all the sequence of

620
00:27:52,150 --> 00:27:56,230
sequence things ok so at the end of this

621
00:27:54,369 --> 00:27:57,909
if I haven't covered the thing you

622
00:27:56,230 --> 00:27:59,860
wanted to know about please ask me then

623
00:27:57,910 --> 00:28:01,690
if you ask me before I'll be answering

624
00:27:59,859 --> 00:28:05,439
something based on something that I'm

625
00:28:01,690 --> 00:28:06,160
about to teach you ok so having

626
00:28:05,440 --> 00:28:09,190
tokenized

627
00:28:06,160 --> 00:28:10,870
the english and french you can see how

628
00:28:09,190 --> 00:28:13,269
it gets bit out and you can see the

629
00:28:10,869 --> 00:28:15,099
tokenization for french is quite

630
00:28:13,269 --> 00:28:16,869
different looking because french loves

631
00:28:15,099 --> 00:28:18,939
their apostrophes and their hi friends

632
00:28:16,869 --> 00:28:20,709
and stuff right so if you try to use in

633
00:28:18,940 --> 00:28:24,120
english tokenizer for a french sentence

634
00:28:20,710 --> 00:28:26,890
you're going to get it pretty crappy ok

635
00:28:24,119 --> 00:28:30,219
so like I don't find you need to know

636
00:28:26,890 --> 00:28:32,679
heaps of NLP ideas to use deep learning

637
00:28:30,220 --> 00:28:35,710
for NLP but just some basic stuff like

638
00:28:32,679 --> 00:28:38,649
you know use the right tokenize of your

639
00:28:35,710 --> 00:28:40,149
language is important and so some of the

640
00:28:38,648 --> 00:28:42,009
students this week in our study group

641
00:28:40,148 --> 00:28:45,518
have been trying to work build language

642
00:28:42,009 --> 00:28:48,250
models for Chinese instance which of

643
00:28:45,519 --> 00:28:50,679
course doesn't really have the concept

644
00:28:48,250 --> 00:28:52,148
of a tokenizer in the same way so we've

645
00:28:50,679 --> 00:28:54,880
been starting to look at it briefly

646
00:28:52,148 --> 00:28:57,189
mentioned last week this google thing

647
00:28:54,880 --> 00:28:59,769
called sentence peace which basically

648
00:28:57,190 --> 00:29:03,460
splits things into arbitrary sub word

649
00:28:59,769 --> 00:29:05,019
units and so when I say tokenize if

650
00:29:03,460 --> 00:29:07,419
you're using a language that doesn't

651
00:29:05,019 --> 00:29:09,700
have spaces in you should probably be

652
00:29:07,419 --> 00:29:11,860
checking out sentence peace or some

653
00:29:09,700 --> 00:29:14,798
other similar sub word unit thing

654
00:29:11,859 --> 00:29:16,689
instead and hopefully in the next week

655
00:29:14,798 --> 00:29:18,398
or two we'll be able to report back with

656
00:29:16,690 --> 00:29:25,380
some early results of these experiments

657
00:29:18,398 --> 00:29:25,379
with Chinese okay

658
00:29:25,419 --> 00:29:28,659
so have you tokenized to it will save

659
00:29:26,888 --> 00:29:31,719
that disk and then remember the next

660
00:29:28,659 --> 00:29:33,519
step after we create tokens is to turn

661
00:29:31,720 --> 00:29:35,798
them into numbers and turn them into

662
00:29:33,519 --> 00:29:38,079
numbers we have two steps the first is

663
00:29:35,798 --> 00:29:40,990
to get a list of all of the words that

664
00:29:38,079 --> 00:29:44,769
appear and then we turn every word into

665
00:29:40,990 --> 00:29:46,538
the index into that list right if there

666
00:29:44,769 --> 00:29:48,730
are more than 40,000 words that appear

667
00:29:46,538 --> 00:29:52,119
then let's cut it off there so it

668
00:29:48,730 --> 00:29:55,048
doesn't go too crazy and we insert a few

669
00:29:52,119 --> 00:30:01,569
extra tokens for beginning of stream

670
00:29:55,048 --> 00:30:03,638
padding end of stream and okay so if we

671
00:30:01,569 --> 00:30:06,069
try to look up something that wasn't in

672
00:30:03,638 --> 00:30:09,099
the 40,000 most common then we use a

673
00:30:06,069 --> 00:30:13,168
default dicked to return three which is

674
00:30:09,099 --> 00:30:16,209
unknown so now we can go ahead and turn

675
00:30:13,169 --> 00:30:18,970
every token into an ID by putting it

676
00:30:16,210 --> 00:30:21,460
through the string to integer dictionary

677
00:30:18,970 --> 00:30:24,000
we just created and then at the end of

678
00:30:21,460 --> 00:30:27,340
that let's add the number two which is

679
00:30:24,000 --> 00:30:30,669
industry and you'll see like this kind

680
00:30:27,339 --> 00:30:32,019
the code you see here is the code I

681
00:30:30,669 --> 00:30:35,139
write when I'm iterating in

682
00:30:32,019 --> 00:30:36,429
experimenting right because like 99% of

683
00:30:35,138 --> 00:30:38,439
the code I write when I'm either writing

684
00:30:36,429 --> 00:30:40,130
experimenting it turns out to be totally

685
00:30:38,440 --> 00:30:41,630
wrong or stupid or embarrass

686
00:30:40,130 --> 00:30:45,400
seeing and you don't get to see it right

687
00:30:41,630 --> 00:30:48,320
but like there's no point you know

688
00:30:45,400 --> 00:30:50,090
refactoring that and making it beautiful

689
00:30:48,319 --> 00:30:52,429
when I'm riding it's kind of wanting you

690
00:30:50,089 --> 00:30:54,199
to see all the little shortcuts I have

691
00:30:52,430 --> 00:30:55,789
so like rather than doing this properly

692
00:30:54,200 --> 00:30:57,590
and actually find you know having some

693
00:30:55,789 --> 00:31:00,559
constant or something for end of stream

694
00:30:57,589 --> 00:31:04,789
marker and using it when I'm prototyping

695
00:31:00,559 --> 00:31:07,759
I just do the easy stuff you know I mean

696
00:31:04,789 --> 00:31:10,549
not not so much that I end up with

697
00:31:07,759 --> 00:31:12,319
broken code you know but I I don't you

698
00:31:10,549 --> 00:31:16,099
know try to find I try to find some

699
00:31:12,319 --> 00:31:20,359
middle ground between beautiful code and

700
00:31:16,099 --> 00:31:23,119
you know code that was just heard him

701
00:31:20,359 --> 00:31:24,829
mention that we divide number of CPUs by

702
00:31:23,119 --> 00:31:26,269
two because with hyper-threading we

703
00:31:24,829 --> 00:31:28,399
don't get a speed-up using all the hyper

704
00:31:26,269 --> 00:31:30,170
threaded cores is this based on

705
00:31:28,400 --> 00:31:31,790
practical experience or is there some

706
00:31:30,170 --> 00:31:33,830
underlying reason why we wouldn't get

707
00:31:31,789 --> 00:31:37,490
additional speed-up yeah it's just

708
00:31:33,829 --> 00:31:39,230
practical experience and it's like a lot

709
00:31:37,490 --> 00:31:41,140
of things kind of seem like this but I

710
00:31:39,230 --> 00:31:43,309
definitely noticed with tokenization

711
00:31:41,140 --> 00:31:47,320
hyper threading seem to slow things down

712
00:31:43,309 --> 00:31:49,250
a little bit also if I use all the cause

713
00:31:47,319 --> 00:31:51,619
you know like often I want to do

714
00:31:49,250 --> 00:31:53,359
something else at the same time like

715
00:31:51,619 --> 00:31:55,819
generally run some interactive notebook

716
00:31:53,359 --> 00:32:03,349
and I don't have any spare room to do

717
00:31:55,819 --> 00:32:05,329
that it's a minor issue yeah okay so now

718
00:32:03,349 --> 00:32:08,480
for our English and our French we can

719
00:32:05,329 --> 00:32:09,889
grab our list of IDs and when we do that

720
00:32:08,480 --> 00:32:11,809
of course we need to make sure that we

721
00:32:09,890 --> 00:32:14,180
also store the vocabulary there's no

722
00:32:11,809 --> 00:32:15,889
point having IDs if we don't know like

723
00:32:14,180 --> 00:32:17,810
what the number five represents there's

724
00:32:15,890 --> 00:32:20,090
no point having a number five so that's

725
00:32:17,809 --> 00:32:22,730
our vocabulary it's a string and the

726
00:32:20,089 --> 00:32:24,769
reverse mapping string to int that we

727
00:32:22,730 --> 00:32:29,539
can use to convert more courses in the

728
00:32:24,769 --> 00:32:30,829
future okay so just to confirm it's

729
00:32:29,539 --> 00:32:34,069
working we can go through each ID

730
00:32:30,829 --> 00:32:36,769
convert the into a string and spit that

731
00:32:34,069 --> 00:32:39,909
out and there we have our thing back now

732
00:32:36,769 --> 00:32:43,730
with an industry marker at the end

733
00:32:39,910 --> 00:32:47,120
English vocab is 17,000 our French vocab

734
00:32:43,730 --> 00:32:49,250
is 25,000 so you know there's not too

735
00:32:47,119 --> 00:32:51,049
big you know there's not too complex a

736
00:32:49,250 --> 00:32:53,250
vocab that we're dealing with which is

737
00:32:51,049 --> 00:32:57,839
nice to know

738
00:32:53,250 --> 00:32:59,940
okay so we spent a lot of time on the

739
00:32:57,839 --> 00:33:01,798
forums during the week discussing how

740
00:32:59,940 --> 00:33:03,390
pointless what vectors are and how you

741
00:33:01,798 --> 00:33:06,509
should stop getting so excited about

742
00:33:03,390 --> 00:33:09,750
them and we're now going to use them why

743
00:33:06,509 --> 00:33:11,669
is that basically all the stuff we've

744
00:33:09,750 --> 00:33:14,099
been learning about using language

745
00:33:11,669 --> 00:33:16,259
models and pre-trained proper models

746
00:33:14,099 --> 00:33:18,269
rather than pre-trained you know linear

747
00:33:16,259 --> 00:33:20,970
single layers which is what word vectors

748
00:33:18,269 --> 00:33:23,908
are I think applies equally well to

749
00:33:20,970 --> 00:33:27,419
sequence to sequence but I haven't tried

750
00:33:23,909 --> 00:33:29,370
it yet yet so Sebastian and I are you

751
00:33:27,419 --> 00:33:31,620
know starting to look at that and

752
00:33:29,369 --> 00:33:33,058
slightly distracted by preparing this

753
00:33:31,619 --> 00:33:35,668
class at the moment but after this class

754
00:33:33,058 --> 00:33:38,119
is done so there's a whole thing for

755
00:33:35,669 --> 00:33:41,100
anybody interested in creating some

756
00:33:38,119 --> 00:33:44,399
genuinely new like highly publishable

757
00:33:41,099 --> 00:33:46,408
results the entire area of sequence to

758
00:33:44,400 --> 00:33:49,740
sequence with pre-trained language

759
00:33:46,409 --> 00:33:51,419
models hasn't been touched yet and I

760
00:33:49,740 --> 00:33:54,960
strongly believe is going to be just as

761
00:33:51,419 --> 00:33:58,080
good as as classification style and if

762
00:33:54,960 --> 00:33:59,519
you you know work on this and you get to

763
00:33:58,079 --> 00:34:01,439
the point where you have something

764
00:33:59,519 --> 00:34:03,450
that's looking exciting and you want

765
00:34:01,440 --> 00:34:06,750
help publishing it you know I'm very

766
00:34:03,450 --> 00:34:09,088
happy to help co-author papers you know

767
00:34:06,750 --> 00:34:12,210
that on stuff that's looking good you

768
00:34:09,088 --> 00:34:14,088
know so feel free to reach out if and

769
00:34:12,210 --> 00:34:17,909
when you have some interesting results

770
00:34:14,088 --> 00:34:21,029
so at this stage we don't have any of

771
00:34:17,909 --> 00:34:24,690
that so we're going to use you know very

772
00:34:21,030 --> 00:34:27,599
little fast I I actually and very little

773
00:34:24,690 --> 00:34:31,039
in terms of kind of fast AI ideas so we

774
00:34:27,599 --> 00:34:33,330
you know all we've got is word vectors

775
00:34:31,039 --> 00:34:35,849
anyway so let's at least use decent word

776
00:34:33,329 --> 00:34:37,769
vectors so word Tyvek is very old where

777
00:34:35,849 --> 00:34:39,809
vectors there are better word vectors

778
00:34:37,769 --> 00:34:41,699
now and fast text is a pretty good

779
00:34:39,809 --> 00:34:43,440
source of word vectors

780
00:34:41,699 --> 00:34:45,299
there's hundreds of languages available

781
00:34:43,440 --> 00:34:49,230
for them your language is likely to be

782
00:34:45,300 --> 00:34:51,419
represented so to grab them you can

783
00:34:49,230 --> 00:34:54,019
click on this link download word vectors

784
00:34:51,418 --> 00:34:59,909
for a language that you're interested in

785
00:34:54,019 --> 00:35:03,150
install install the fast text Python

786
00:34:59,909 --> 00:35:05,190
library it's not available on pi PI but

787
00:35:03,150 --> 00:35:07,269
here's a handy trick if there is a

788
00:35:05,190 --> 00:35:10,840
github

789
00:35:07,269 --> 00:35:12,849
repo that has like a setup PI inert and

790
00:35:10,840 --> 00:35:16,660
a requirements text in it you can just

791
00:35:12,849 --> 00:35:18,670
chuck get Plus at the start and then

792
00:35:16,659 --> 00:35:21,190
stick that in your pip install and it

793
00:35:18,670 --> 00:35:23,289
works like hardly anybody seems to know

794
00:35:21,190 --> 00:35:24,940
this and like it never even like if you

795
00:35:23,289 --> 00:35:25,809
go to the fast text repo they won't tell

796
00:35:24,940 --> 00:35:27,550
you this they'll say you have to

797
00:35:25,809 --> 00:35:29,019
download it and CD into it and blah blah

798
00:35:27,550 --> 00:35:31,780
blah but you're done you can just run

799
00:35:29,019 --> 00:35:33,940
that ok which you can also use for the

800
00:35:31,780 --> 00:35:35,320
first AI library by the way if you want

801
00:35:33,940 --> 00:35:39,250
to pip install the latest version of

802
00:35:35,320 --> 00:35:42,430
past pay I even totally do this so you

803
00:35:39,250 --> 00:35:44,500
grab the library import it load the

804
00:35:42,429 --> 00:35:47,559
model so here's my English model and

805
00:35:44,500 --> 00:35:49,480
here's my French you'll see there's a

806
00:35:47,559 --> 00:35:51,279
text version and a binary version the

807
00:35:49,480 --> 00:35:52,659
binary versions a bit faster we're going

808
00:35:51,280 --> 00:35:56,440
to use that the text version is also a

809
00:35:52,659 --> 00:35:59,109
bit buggy and then I'm going to convert

810
00:35:56,440 --> 00:36:00,610
it into a standard Python dictionary to

811
00:35:59,110 --> 00:36:01,660
make it a bit easier to work with so

812
00:36:00,610 --> 00:36:03,519
this is just going to grow through each

813
00:36:01,659 --> 00:36:08,199
word with a dictionary comprehension and

814
00:36:03,519 --> 00:36:11,650
save it as a pickle dictionary ok so now

815
00:36:08,199 --> 00:36:13,480
we've got our pickle dictionary we can

816
00:36:11,650 --> 00:36:16,740
go ahead and look up a word for example

817
00:36:13,480 --> 00:36:18,760
come up and that will return a vector

818
00:36:16,739 --> 00:36:21,759
the length of that vector is the

819
00:36:18,760 --> 00:36:23,230
dimensionality of this set of word

820
00:36:21,760 --> 00:36:25,090
vectors so in this case we've got three

821
00:36:23,230 --> 00:36:29,570
hundred dimensional English and French

822
00:36:25,090 --> 00:36:31,050
words okay

823
00:36:29,570 --> 00:36:33,130
[Music]

824
00:36:31,050 --> 00:36:35,289
for reasons that you'll see in a moment

825
00:36:33,130 --> 00:36:37,240
I also want to find out what the mean of

826
00:36:35,289 --> 00:36:39,039
my vectors are and the standard

827
00:36:37,239 --> 00:36:41,379
deviation of my vectors are so the means

828
00:36:39,039 --> 00:36:49,769
about 0 and the standard deviation is

829
00:36:41,380 --> 00:36:52,360
about point three so remember that often

830
00:36:49,769 --> 00:36:56,619
corpuses have a pretty long tailed

831
00:36:52,360 --> 00:36:58,870
distribution of sequence length and it's

832
00:36:56,619 --> 00:37:01,029
the longest sequences that kind of tend

833
00:36:58,869 --> 00:37:02,710
to overwhelm how long things take and

834
00:37:01,030 --> 00:37:03,910
you know how much memory is used and

835
00:37:02,710 --> 00:37:06,519
stuff like that

836
00:37:03,909 --> 00:37:10,210
so I'm going to grab you know in this

837
00:37:06,519 --> 00:37:14,980
case the 99th to 97th percentile of the

838
00:37:10,210 --> 00:37:17,559
English and French and truncate them to

839
00:37:14,980 --> 00:37:19,059
that amount originally I was using the

840
00:37:17,559 --> 00:37:20,288
90th percentile so these are poorly

841
00:37:19,059 --> 00:37:22,900
named variable

842
00:37:20,289 --> 00:37:25,630
so apologies for that okay so that's

843
00:37:22,900 --> 00:37:28,900
just truncating them so we're nearly

844
00:37:25,630 --> 00:37:33,939
there we've got our tokenized numeric

845
00:37:28,900 --> 00:37:37,599
alized English and French data set we've

846
00:37:33,938 --> 00:37:40,178
got some word vectors so now we need to

847
00:37:37,599 --> 00:37:44,099
get it ready for play torch so app a

848
00:37:40,179 --> 00:37:46,838
torch expects a data set object and

849
00:37:44,099 --> 00:37:48,818
hopefully by now you all can tell me

850
00:37:46,838 --> 00:37:53,349
that a data set object requires two

851
00:37:48,818 --> 00:37:54,849
things a length and an indexer so I

852
00:37:53,349 --> 00:37:56,410
started route writing this now it's like

853
00:37:54,849 --> 00:37:58,088
okay I need a sector sector dataset and

854
00:37:56,409 --> 00:37:59,348
I started out writing it and I thought

855
00:37:58,088 --> 00:38:01,869
okay we're going to have to pass it out

856
00:37:59,349 --> 00:38:04,809
X's now wise and store them away and

857
00:38:01,869 --> 00:38:08,019
then my indexer is going to need to

858
00:38:04,809 --> 00:38:09,849
return a numpy array of the X's at that

859
00:38:08,018 --> 00:38:12,308
point in an umpire row of the Y's at

860
00:38:09,849 --> 00:38:14,920
that point and oh that's it

861
00:38:12,309 --> 00:38:16,359
so then after I wrote this I realized I

862
00:38:14,920 --> 00:38:18,068
haven't really written a sector sector

863
00:38:16,358 --> 00:38:20,858
dataset I've just written a totally

864
00:38:18,068 --> 00:38:23,469
generic data set so here's like the

865
00:38:20,858 --> 00:38:26,920
simplest possible data set that works

866
00:38:23,469 --> 00:38:29,798
for any pair of arrays so it's now

867
00:38:26,920 --> 00:38:31,539
poorly named it's much more general than

868
00:38:29,798 --> 00:38:36,099
a sector sick data set but that's what I

869
00:38:31,539 --> 00:38:38,920
needed it for this a function remember

870
00:38:36,099 --> 00:38:40,749
we've got V variables teeth tensors a4

871
00:38:38,920 --> 00:38:42,880
arrays so this basically goes through

872
00:38:40,748 --> 00:38:44,948
each of the things you pass it if it's

873
00:38:42,880 --> 00:38:46,900
not already in numpy array it converts

874
00:38:44,949 --> 00:38:49,329
it into a numpy array and returns back

875
00:38:46,900 --> 00:38:51,369
at a pool of all of the things that you

876
00:38:49,329 --> 00:38:55,089
passed it which are now guaranteed to be

877
00:38:51,369 --> 00:39:01,329
mud pirates so that's a VT 3 very handy

878
00:38:55,088 --> 00:39:07,228
little functions ok so that's it that's

879
00:39:01,329 --> 00:39:11,140
our data set so now we need to grab our

880
00:39:07,228 --> 00:39:13,509
English and French IDs and get a

881
00:39:11,139 --> 00:39:15,518
training set and a validation set and so

882
00:39:13,509 --> 00:39:17,920
one of the things which is pretty

883
00:39:15,518 --> 00:39:19,868
disappointing about a lot of code out

884
00:39:17,920 --> 00:39:22,329
there on the Internet is that they don't

885
00:39:19,869 --> 00:39:24,778
follow us and simple best practices for

886
00:39:22,329 --> 00:39:28,528
example if you go to the Play Torche

887
00:39:24,778 --> 00:39:31,150
website they have an example section for

888
00:39:28,528 --> 00:39:32,559
sequence a sequence translation there

889
00:39:31,150 --> 00:39:33,700
example does not have a separate

890
00:39:32,559 --> 00:39:36,220
validation set

891
00:39:33,699 --> 00:39:38,289
I tried it training according to their

892
00:39:36,219 --> 00:39:39,699
settings and I tested it with their

893
00:39:38,289 --> 00:39:42,610
validation set it turned out that it

894
00:39:39,699 --> 00:39:44,469
overfit massively so this is not just a

895
00:39:42,610 --> 00:39:47,130
theoretical problem the actual pipe

896
00:39:44,469 --> 00:39:49,000
torch repo has the actual official

897
00:39:47,130 --> 00:39:50,710
sequence the sequence translation

898
00:39:49,000 --> 00:39:54,309
example which does not check for

899
00:39:50,710 --> 00:39:56,289
overfitting and overfits horribly also

900
00:39:54,309 --> 00:39:58,920
it fails to use mini batches so it

901
00:39:56,289 --> 00:40:01,779
actually fails to utilize any of the

902
00:39:58,920 --> 00:40:03,880
efficiency of Pi torch whatsoever so

903
00:40:01,780 --> 00:40:06,280
there's a lot of like even if you find

904
00:40:03,880 --> 00:40:08,860
code in the official pipe torch repo

905
00:40:06,280 --> 00:40:10,980
don't assume it's any good at all right

906
00:40:08,860 --> 00:40:14,230
the other thing you'll notice is that

907
00:40:10,980 --> 00:40:15,969
everybody were when they like pretty

908
00:40:14,230 --> 00:40:18,369
much every other sequence the sequence

909
00:40:15,969 --> 00:40:20,980
model I've found in Peyer torch anywhere

910
00:40:18,369 --> 00:40:23,559
on the internet has clearly copied from

911
00:40:20,980 --> 00:40:24,909
that shitty pipe or epoch isn't all the

912
00:40:23,559 --> 00:40:28,449
same variable names it has the same

913
00:40:24,909 --> 00:40:31,239
problems it has the same mistakes like

914
00:40:28,449 --> 00:40:32,919
another example nearly every PI torch

915
00:40:31,239 --> 00:40:35,409
convolutional neural network I found

916
00:40:32,920 --> 00:40:37,990
does not use an adaptive pooling layer

917
00:40:35,409 --> 00:40:41,559
so in other words the final layer is

918
00:40:37,989 --> 00:40:43,629
always like average paul 7 comma 7 right

919
00:40:41,559 --> 00:40:46,690
so they assume that the previous layer

920
00:40:43,630 --> 00:40:49,690
is 7 by 7 and if you use any other size

921
00:40:46,690 --> 00:40:51,579
input you get an exception and therefore

922
00:40:49,690 --> 00:40:53,110
nearly everybody i've spoken to that

923
00:40:51,579 --> 00:40:55,119
uses Piatt torch thinks that there is a

924
00:40:53,110 --> 00:40:57,640
fundamental limitation of CN NS that

925
00:40:55,119 --> 00:41:00,279
they are tied to the input size and that

926
00:40:57,639 --> 00:41:02,379
has not been true since vgg right so

927
00:41:00,280 --> 00:41:03,880
every time we grab a new model and stick

928
00:41:02,380 --> 00:41:07,210
it in the first day i repo i have to go

929
00:41:03,880 --> 00:41:09,220
in search for paul and add adaptive to

930
00:41:07,210 --> 00:41:12,099
the start and replace the 7 with a 1 and

931
00:41:09,219 --> 00:41:14,679
now it works on any sized object all

932
00:41:12,099 --> 00:41:17,199
right so just be careful you know it's

933
00:41:14,679 --> 00:41:18,899
still early days and and believe it or

934
00:41:17,199 --> 00:41:21,009
not even though most of you have only

935
00:41:18,900 --> 00:41:23,920
started in the last year your deep

936
00:41:21,010 --> 00:41:25,990
learning journey you know quite a lot

937
00:41:23,920 --> 00:41:27,639
more about a lot of the more important

938
00:41:25,989 --> 00:41:29,949
practical aspects and the vast majority

939
00:41:27,639 --> 00:41:32,109
of people that are like publishing and

940
00:41:29,949 --> 00:41:34,539
writing stuff in official repos and

941
00:41:32,110 --> 00:41:36,970
stuff so you kind of need to have a

942
00:41:34,539 --> 00:41:38,259
little more self-confidence than you

943
00:41:36,969 --> 00:41:39,909
might expect when it comes to reading

944
00:41:38,260 --> 00:41:42,580
other people's code if you find yourself

945
00:41:39,909 --> 00:41:47,099
thinking that looks odd it's not

946
00:41:42,579 --> 00:41:47,099
necessarily you it might well be then

947
00:41:48,139 --> 00:41:56,029
okay

948
00:41:49,320 --> 00:41:58,650
so yeah I would say like at least 90% of

949
00:41:56,030 --> 00:42:02,010
deep learning code that I start looking

950
00:41:58,650 --> 00:42:05,280
at turns out to have like you know like

951
00:42:02,010 --> 00:42:08,190
deathly serious problems that make it

952
00:42:05,280 --> 00:42:10,320
completely unusable for anything and so

953
00:42:08,190 --> 00:42:12,900
I kind of been telling people that I've

954
00:42:10,320 --> 00:42:14,640
been working with recently you know if

955
00:42:12,900 --> 00:42:16,410
if the repo you're looking at doesn't

956
00:42:14,639 --> 00:42:18,150
have a section on it saying here's the

957
00:42:16,409 --> 00:42:20,009
test we did where we got the same

958
00:42:18,150 --> 00:42:22,050
results as the paper that suspend to be

959
00:42:20,010 --> 00:42:23,280
implementing that almost certainly means

960
00:42:22,050 --> 00:42:24,510
they haven't got the same results in the

961
00:42:23,280 --> 00:42:26,880
paper they're implementing they probably

962
00:42:24,510 --> 00:42:28,980
haven't even checked okay and if you run

963
00:42:26,880 --> 00:42:31,170
it it definitely won't get those results

964
00:42:28,980 --> 00:42:32,969
because it's it's hard to get things

965
00:42:31,170 --> 00:42:35,519
right the first time it takes me 12 goes

966
00:42:32,969 --> 00:42:38,098
you know probably takes the normal

967
00:42:35,519 --> 00:42:40,108
smarter people than me six goes but if

968
00:42:38,099 --> 00:42:44,010
they haven't tested it once it's almost

969
00:42:40,108 --> 00:42:46,139
certainly won't work okay so there's our

970
00:42:44,010 --> 00:42:48,240
sequence sequence data set let's get the

971
00:42:46,139 --> 00:42:49,920
training and validation sets here's an

972
00:42:48,239 --> 00:42:51,989
easy way to do that we have a bunch of

973
00:42:49,920 --> 00:42:54,800
random numbers one feature of your data

974
00:42:51,989 --> 00:42:57,809
see if they're bigger than 0.1 or not

975
00:42:54,800 --> 00:42:59,310
that gives you a list of balls index

976
00:42:57,809 --> 00:43:01,858
into your array with that list of balls

977
00:42:59,309 --> 00:43:03,869
to grab a training set index into that

978
00:43:01,858 --> 00:43:05,670
array with the opposite of that list of

979
00:43:03,869 --> 00:43:07,858
balls to get your validation set there's

980
00:43:05,670 --> 00:43:09,180
a nice easy way there's lots of ways of

981
00:43:07,858 --> 00:43:11,269
doing it I just like to do different

982
00:43:09,179 --> 00:43:14,269
ways to you can see a few approaches

983
00:43:11,269 --> 00:43:16,949
okay so now we can create our data set

984
00:43:14,269 --> 00:43:19,050
with our X's in our Y's French and

985
00:43:16,949 --> 00:43:20,879
English if you want to translate instead

986
00:43:19,050 --> 00:43:24,570
English to French switch these two

987
00:43:20,880 --> 00:43:27,838
around and you're done okay now we need

988
00:43:24,570 --> 00:43:30,450
to create data loaders we can just grab

989
00:43:27,838 --> 00:43:36,199
our data loader and pass in our data set

990
00:43:30,449 --> 00:43:38,939
and match size we actually have to

991
00:43:36,199 --> 00:43:41,189
transpose the arrays I'm not going to go

992
00:43:38,940 --> 00:43:42,179
into the details about why we can talk

993
00:43:41,190 --> 00:43:44,159
about it during the week if you're

994
00:43:42,179 --> 00:43:45,980
interested but have a think about why we

995
00:43:44,159 --> 00:43:49,679
might need to transpose their

996
00:43:45,980 --> 00:43:51,750
orientation but there's a few more

997
00:43:49,679 --> 00:43:52,980
things I want to do one is that since

998
00:43:51,750 --> 00:43:55,559
we've already done all the

999
00:43:52,980 --> 00:43:57,480
pre-processing there's no point spawning

1000
00:43:55,559 --> 00:43:59,340
off multiple workers to do like

1001
00:43:57,480 --> 00:44:01,650
augmentation or whatever because there

1002
00:43:59,340 --> 00:44:04,710
know what to do so making them workers

1003
00:44:01,650 --> 00:44:06,119
equals one will save you some time

1004
00:44:04,710 --> 00:44:08,420
we have to tell it what our padding

1005
00:44:06,119 --> 00:44:10,799
index is that's actually pretty

1006
00:44:08,420 --> 00:44:12,690
important because what's going to happen

1007
00:44:10,800 --> 00:44:15,690
is that we've got different length

1008
00:44:12,690 --> 00:44:17,490
sentences and faster I I think it's

1009
00:44:15,690 --> 00:44:19,590
pretty much the only baby that does this

1010
00:44:17,489 --> 00:44:21,629
past day I will just automatically stick

1011
00:44:19,590 --> 00:44:23,820
them together and pad the shorter ones

1012
00:44:21,630 --> 00:44:25,500
to be so that they're all in that equal

1013
00:44:23,820 --> 00:44:29,390
length because remember a tense has to

1014
00:44:25,500 --> 00:44:29,389
be rectangular okay

1015
00:44:31,320 --> 00:44:36,330
in the decoder in particularly I

1016
00:44:33,929 --> 00:44:38,940
actually want my padding to be at the

1017
00:44:36,329 --> 00:44:41,219
end not at the start like for a

1018
00:44:38,940 --> 00:44:44,369
classifier I want the padding at the

1019
00:44:41,219 --> 00:44:46,019
start because I want that final token to

1020
00:44:44,369 --> 00:44:49,380
represent the last word of the movie

1021
00:44:46,019 --> 00:44:50,759
review but in the decoder as you'll see

1022
00:44:49,380 --> 00:44:52,230
it actually is going to work out a bit

1023
00:44:50,760 --> 00:44:54,480
better to have the padding at the end so

1024
00:44:52,230 --> 00:44:56,789
I say prepaired equals false and then

1025
00:44:54,480 --> 00:44:59,039
finally since we've got sentences of

1026
00:44:56,789 --> 00:45:01,079
different lengths coming in and they all

1027
00:44:59,039 --> 00:45:03,960
have to be put together in a mini batch

1028
00:45:01,079 --> 00:45:06,269
to be the same size by padding we would

1029
00:45:03,960 --> 00:45:08,269
much prefer that the sentence in a mini

1030
00:45:06,269 --> 00:45:10,829
batch are of similar sizes already

1031
00:45:08,269 --> 00:45:12,570
because otherwise that it's going to be

1032
00:45:10,829 --> 00:45:14,429
as long as the longest sentence and

1033
00:45:12,570 --> 00:45:17,039
that's going to end up wasting time and

1034
00:45:14,429 --> 00:45:18,569
memory okay so therefore I'm going to

1035
00:45:17,039 --> 00:45:21,509
use the sample of tricks that we learnt

1036
00:45:18,570 --> 00:45:23,490
last time which is the validation set

1037
00:45:21,510 --> 00:45:27,930
we're going to ask it to sort everything

1038
00:45:23,489 --> 00:45:29,899
by length first okay and then for the

1039
00:45:27,929 --> 00:45:32,879
training set we're going to ask it to

1040
00:45:29,900 --> 00:45:34,440
randomize the order of things but to

1041
00:45:32,880 --> 00:45:36,090
roughly make it so that things of

1042
00:45:34,440 --> 00:45:38,099
similar length are about in the same

1043
00:45:36,090 --> 00:45:39,840
spot okay that's how we got our sort

1044
00:45:38,099 --> 00:45:43,829
sample and a sort assembler

1045
00:45:39,840 --> 00:45:45,600
okay and then at that point we can

1046
00:45:43,829 --> 00:45:48,389
create a model data object remember a

1047
00:45:45,599 --> 00:45:50,579
model data object really does one thing

1048
00:45:48,389 --> 00:45:52,619
which is it says I have a trading set

1049
00:45:50,579 --> 00:45:53,940
and a validation set and an optional

1050
00:45:52,619 --> 00:45:57,150
test set and sticks them into a single

1051
00:45:53,940 --> 00:45:59,190
object we also have a path so that it

1052
00:45:57,150 --> 00:46:02,760
has somewhere to store temporary files

1053
00:45:59,190 --> 00:46:05,789
models stuff like that right so you know

1054
00:46:02,760 --> 00:46:07,440
we're doing we're not using fast AI for

1055
00:46:05,789 --> 00:46:10,409
very much at all in this example just

1056
00:46:07,440 --> 00:46:12,500
kind of a minimal set to show you like

1057
00:46:10,409 --> 00:46:15,529
you know

1058
00:46:12,500 --> 00:46:17,090
how to you know kind of get your model

1059
00:46:15,530 --> 00:46:19,190
data objects in the end once you've got

1060
00:46:17,090 --> 00:46:21,710
a model data object you can then create

1061
00:46:19,190 --> 00:46:26,079
a learner and you can then call fit okay

1062
00:46:21,710 --> 00:46:28,699
so that's kind of like minimal amount of

1063
00:46:26,079 --> 00:46:31,219
faster faster I stuff here this is a

1064
00:46:28,699 --> 00:46:33,619
standard height watch compatible data

1065
00:46:31,219 --> 00:46:35,929
set this is a standard plate or

1066
00:46:33,619 --> 00:46:37,909
compatible data loader behind the scenes

1067
00:46:35,929 --> 00:46:39,889
it's actually using the class AI version

1068
00:46:37,909 --> 00:46:41,779
because I do need to do this automatic

1069
00:46:39,889 --> 00:46:43,579
padding for convenience so there's a few

1070
00:46:41,780 --> 00:46:47,540
tweaks in our version that are a bit

1071
00:46:43,579 --> 00:46:50,079
faster a bit more convenient the faster

1072
00:46:47,539 --> 00:46:52,550
ice samplers we're using but you know

1073
00:46:50,079 --> 00:46:55,219
there's not too much going on here so

1074
00:46:52,550 --> 00:46:58,840
now we've got our model data object we

1075
00:46:55,219 --> 00:47:02,049
can basically tick off number one okay

1076
00:46:58,840 --> 00:47:07,730
so as I said most of the work is in the

1077
00:47:02,050 --> 00:47:12,789
architecture and so the architecture is

1078
00:47:07,730 --> 00:47:18,429
going to take our sequence of tokens

1079
00:47:12,789 --> 00:47:22,579
okay it's going to spit them in to a

1080
00:47:18,429 --> 00:47:23,629
encoder or you know in kind of computer

1081
00:47:22,579 --> 00:47:25,279
vision turns what we've been calling a

1082
00:47:23,630 --> 00:47:27,410
backbone you know something that's going

1083
00:47:25,280 --> 00:47:29,090
to try and turn this into some kind of

1084
00:47:27,409 --> 00:47:32,509
representation so that's just going to

1085
00:47:29,090 --> 00:47:37,070
be an iron in okay that's going to spit

1086
00:47:32,510 --> 00:47:40,150
out the final hidden state which for

1087
00:47:37,070 --> 00:47:43,160
each sentence it's just a vector single

1088
00:47:40,150 --> 00:47:44,900
okay and so that's all going to take

1089
00:47:43,159 --> 00:47:47,750
that's none of this is going to be do

1090
00:47:44,900 --> 00:47:48,980
that's all going to be using very direct

1091
00:47:47,750 --> 00:47:51,019
simple techniques that we've already

1092
00:47:48,980 --> 00:47:53,289
learnt and then we're going to take that

1093
00:47:51,019 --> 00:47:56,480
and we're going to spread it into a

1094
00:47:53,289 --> 00:47:57,590
different era tan which is a decoder and

1095
00:47:56,480 --> 00:47:59,300
that's going to have some new stuff

1096
00:47:57,590 --> 00:48:03,920
because we need something that can go

1097
00:47:59,300 --> 00:48:05,630
through one word at a time okay and it's

1098
00:48:03,920 --> 00:48:07,940
got to keep going until it thinks it's

1099
00:48:05,630 --> 00:48:09,200
finished the sentence it doesn't know

1100
00:48:07,940 --> 00:48:11,240
how long the sentence is going to be

1101
00:48:09,199 --> 00:48:12,559
ahead of time keeps going until it

1102
00:48:11,239 --> 00:48:14,329
thinks it's finished the sentence and

1103
00:48:12,559 --> 00:48:17,389
then it stops and returns a sentence

1104
00:48:14,329 --> 00:48:22,099
okay so let's start with the with the

1105
00:48:17,389 --> 00:48:24,769
end coder so in terms of variable naming

1106
00:48:22,099 --> 00:48:25,779
here there's basically identical

1107
00:48:24,769 --> 00:48:28,389
variable

1108
00:48:25,780 --> 00:48:30,670
for encoder and decoder buttes for

1109
00:48:28,389 --> 00:48:33,279
encoder and decoder the encoder versions

1110
00:48:30,670 --> 00:48:36,570
have Inc the decoder versions have dead

1111
00:48:33,280 --> 00:48:41,650
okay so for the N coder here's our

1112
00:48:36,570 --> 00:48:43,960
embeddings and so like I always try to

1113
00:48:41,650 --> 00:48:45,519
mention like what the mnemonics are you

1114
00:48:43,960 --> 00:48:49,510
know rather than writing things out you

1115
00:48:45,519 --> 00:48:51,219
know so in turn longhand so you know

1116
00:48:49,510 --> 00:48:53,790
just remember anchors and encoder

1117
00:48:51,219 --> 00:48:56,759
deckers of decoder and visit embedding

1118
00:48:53,789 --> 00:49:00,369
the final thing that comes out is out

1119
00:48:56,760 --> 00:49:01,750
the r and n in this case is a gr u not

1120
00:49:00,369 --> 00:49:04,210
an LST M

1121
00:49:01,750 --> 00:49:05,199
they're nearly the same thing so don't

1122
00:49:04,210 --> 00:49:06,670
worry about the difference you could

1123
00:49:05,199 --> 00:49:08,889
replace it with an LST m and you'll get

1124
00:49:06,670 --> 00:49:18,180
basically the same results to replace it

1125
00:49:08,889 --> 00:49:22,119
with an LST M simply type OST M okay so

1126
00:49:18,179 --> 00:49:23,379
we need to create an embedding layer to

1127
00:49:22,119 --> 00:49:25,900
take because remember what we're being

1128
00:49:23,380 --> 00:49:27,789
passed is the index of the words into a

1129
00:49:25,900 --> 00:49:30,849
vocabulary and we want to grab there

1130
00:49:27,789 --> 00:49:34,119
fast text embedding and then over time

1131
00:49:30,849 --> 00:49:38,259
we might want to also fine tune to train

1132
00:49:34,119 --> 00:49:40,179
that embedding n to it so to create an

1133
00:49:38,260 --> 00:49:42,810
embedding we'll call create embedding up

1134
00:49:40,179 --> 00:49:47,019
here so we'll just say n n dot embedding

1135
00:49:42,809 --> 00:49:48,699
so it's important that you know now how

1136
00:49:47,019 --> 00:49:50,500
to set the rows and columns for your

1137
00:49:48,699 --> 00:49:52,329
embedding so the number of rows has to

1138
00:49:50,500 --> 00:49:55,389
be equal to your vocabulary size

1139
00:49:52,329 --> 00:49:58,509
so each vocab riordan has a word vector

1140
00:49:55,389 --> 00:50:01,480
and the how big is your embedding well

1141
00:49:58,510 --> 00:50:03,790
in this case it was determined by fast

1142
00:50:01,480 --> 00:50:06,340
text and the first text embedding size

1143
00:50:03,789 --> 00:50:08,440
300 so we have to use size 300 as well

1144
00:50:06,340 --> 00:50:14,500
otherwise we can't start out by using

1145
00:50:08,440 --> 00:50:15,970
their betting's okay now so what we want

1146
00:50:14,500 --> 00:50:18,969
to do is this is initially going to give

1147
00:50:15,969 --> 00:50:20,169
us a random set of embeddings and so

1148
00:50:18,969 --> 00:50:22,719
we're going to now go through each one

1149
00:50:20,170 --> 00:50:24,159
of these and if we find it in fast text

1150
00:50:22,719 --> 00:50:27,609
we'll replace it with the first text

1151
00:50:24,159 --> 00:50:30,909
admitting okay so again something that

1152
00:50:27,610 --> 00:50:34,450
you should already know is that a PI

1153
00:50:30,909 --> 00:50:36,670
torch module that is learn about has a

1154
00:50:34,449 --> 00:50:39,339
weight attribute and the weight

1155
00:50:36,670 --> 00:50:42,220
attribute is a variable and that

1156
00:50:39,340 --> 00:50:44,800
variables have a data attribute and the

1157
00:50:42,219 --> 00:50:46,629
data attribute is a tensor now your

1158
00:50:44,800 --> 00:50:48,670
notice very often today I'm saying here

1159
00:50:46,630 --> 00:50:50,260
is something you should know not so that

1160
00:50:48,670 --> 00:50:53,260
you think oh I don't know that I'm a bad

1161
00:50:50,260 --> 00:50:56,560
person right but so that you think okay

1162
00:50:53,260 --> 00:50:59,500
this is a concept that you know I

1163
00:50:56,559 --> 00:51:01,719
haven't learnt yet and Jeremy thinks I

1164
00:50:59,500 --> 00:51:03,519
ought to know about and so I've got to

1165
00:51:01,719 --> 00:51:05,379
write that down and I'm gonna go home

1166
00:51:03,519 --> 00:51:07,750
and I'm gonna like Google because like

1167
00:51:05,380 --> 00:51:09,579
this is a normal pie Torche

1168
00:51:07,750 --> 00:51:12,429
attribute in every single learning

1169
00:51:09,579 --> 00:51:14,739
platform module this is a normal plate

1170
00:51:12,429 --> 00:51:16,899
or attribute in every single pipe torch

1171
00:51:14,739 --> 00:51:18,879
variable and so if you don't know how to

1172
00:51:16,900 --> 00:51:20,289
graph the weights out of a module or you

1173
00:51:18,880 --> 00:51:22,630
don't know how to grab the tensor out of

1174
00:51:20,289 --> 00:51:24,699
a variable it's gonna be hard for you to

1175
00:51:22,630 --> 00:51:26,680
build new things or to debug things or

1176
00:51:24,699 --> 00:51:29,019
maintain things or whatever yes so if I

1177
00:51:26,679 --> 00:51:31,119
say you ought to know this and you're

1178
00:51:29,019 --> 00:51:33,489
thinking I don't know this don't run

1179
00:51:31,119 --> 00:51:35,049
away and hide go home and learn the

1180
00:51:33,489 --> 00:51:36,609
thing and if you're having trouble

1181
00:51:35,050 --> 00:51:38,650
learning the thing because you can't

1182
00:51:36,610 --> 00:51:40,269
find documentation about it or you don't

1183
00:51:38,650 --> 00:51:41,619
understand that documentation or you

1184
00:51:40,269 --> 00:51:43,449
don't know why Jeremy thought it was

1185
00:51:41,619 --> 00:51:46,420
important you know it jump on the forum

1186
00:51:43,449 --> 00:51:48,489
and say like please explain this thing

1187
00:51:46,420 --> 00:51:49,990
here's my best understanding of that

1188
00:51:48,489 --> 00:51:52,599
thing as I have it at the moment here's

1189
00:51:49,989 --> 00:51:53,619
the resources I grew up that helped film

1190
00:51:52,599 --> 00:51:57,369
you okay

1191
00:51:53,619 --> 00:51:59,529
and normally if I respond it's very

1192
00:51:57,369 --> 00:52:02,319
likely I will not tell you the answer

1193
00:51:59,530 --> 00:52:04,810
but I will instead give you something a

1194
00:52:02,320 --> 00:52:07,180
problem that you could solve that if you

1195
00:52:04,809 --> 00:52:09,039
solver will solve it for you because I

1196
00:52:07,179 --> 00:52:10,869
know that that that way it'll be

1197
00:52:09,039 --> 00:52:12,880
something you remember okay so again

1198
00:52:10,869 --> 00:52:14,769
don't be put off if I'm like okay you

1199
00:52:12,880 --> 00:52:16,510
like go read this link try and summarize

1200
00:52:14,769 --> 00:52:18,579
that thing tell us what you think like

1201
00:52:16,510 --> 00:52:21,340
I'm trying to be helpful not unhelpful

1202
00:52:18,579 --> 00:52:23,259
and if you're still not following just

1203
00:52:21,340 --> 00:52:25,329
come back and say like I had to look

1204
00:52:23,260 --> 00:52:26,440
honestly that link you sent I don't know

1205
00:52:25,329 --> 00:52:29,319
what I knew that means I wouldn't know

1206
00:52:26,440 --> 00:52:31,360
where to start whatever like I'll keep

1207
00:52:29,320 --> 00:52:33,940
trying to help you until you fully

1208
00:52:31,360 --> 00:52:37,510
understand it okay

1209
00:52:33,940 --> 00:52:40,300
so so now that we've got our weight

1210
00:52:37,510 --> 00:52:43,770
tensor we can just go through our

1211
00:52:40,300 --> 00:52:47,560
vocabulary and we can look at the word

1212
00:52:43,769 --> 00:52:49,389
in our pre-trained vectors and if we

1213
00:52:47,559 --> 00:52:52,559
find it we will replace the random

1214
00:52:49,389 --> 00:52:54,569
weights with that pre-trade vector

1215
00:52:52,559 --> 00:52:58,440
the random weights have a standard

1216
00:52:54,570 --> 00:52:59,880
deviation of 1 our pre-trained vectors

1217
00:52:58,440 --> 00:53:02,250
it turned out how to standard deviation

1218
00:52:59,880 --> 00:53:04,050
of about 0.3 so again this is the kind

1219
00:53:02,250 --> 00:53:06,480
of hacky thing I do when I'm prototyping

1220
00:53:04,050 --> 00:53:09,539
stuff I just multiply two by three okay

1221
00:53:06,480 --> 00:53:10,949
obviously by the time you you know see

1222
00:53:09,539 --> 00:53:12,360
the video of this mean way we'll have

1223
00:53:10,949 --> 00:53:14,489
put all this sequence to sequence stuff

1224
00:53:12,360 --> 00:53:17,220
into the faster library you won't find

1225
00:53:14,489 --> 00:53:20,219
horrible paths like that and there sure

1226
00:53:17,219 --> 00:53:24,089
hope but hack away when you're

1227
00:53:20,219 --> 00:53:26,129
prototyping some things won't be in fast

1228
00:53:24,090 --> 00:53:28,260
text in which case we'll just keep track

1229
00:53:26,130 --> 00:53:30,900
of it and I've just added this print

1230
00:53:28,260 --> 00:53:32,580
statement here just so that I can kind

1231
00:53:30,900 --> 00:53:35,670
of see what's going like why am I

1232
00:53:32,579 --> 00:53:37,769
missing stuff basically when you know

1233
00:53:35,670 --> 00:53:41,579
I'll probably comment it out when I

1234
00:53:37,769 --> 00:53:43,800
actually commit this to github that's

1235
00:53:41,579 --> 00:53:46,139
why that's there okay so we create those

1236
00:53:43,800 --> 00:53:48,200
embeddings and so when we actually

1237
00:53:46,139 --> 00:53:51,900
create the sequence to sequence RNN

1238
00:53:48,199 --> 00:53:54,089
it'll print out how many or missed and

1239
00:53:51,900 --> 00:53:57,090
so remember we had like about 30,000

1240
00:53:54,090 --> 00:53:58,400
words so we're not missing too many and

1241
00:53:57,090 --> 00:54:01,019
interesting the things that are missing

1242
00:53:58,400 --> 00:54:03,360
well there's our special toque there's a

1243
00:54:01,019 --> 00:54:06,539
special token for uppercase not

1244
00:54:03,360 --> 00:54:09,269
surprising that's missing also remember

1245
00:54:06,539 --> 00:54:11,130
it's not token Tyvek it's not token text

1246
00:54:09,269 --> 00:54:12,630
it's you know it does words so L

1247
00:54:11,130 --> 00:54:14,610
apostrophe and D apostrophe and

1248
00:54:12,630 --> 00:54:16,590
apostrophe s they're not appearing

1249
00:54:14,610 --> 00:54:18,450
either so that's interesting that does

1250
00:54:16,590 --> 00:54:21,510
suggest that maybe we could have

1251
00:54:18,449 --> 00:54:23,339
slightly better embeddings if we try to

1252
00:54:21,510 --> 00:54:26,840
find some which would being tokenized

1253
00:54:23,340 --> 00:54:30,210
the same way we tokenize that's okay

1254
00:54:26,840 --> 00:54:32,250
Rachel do we just keep embedding vectors

1255
00:54:30,210 --> 00:54:34,289
from training why don't we keep all word

1256
00:54:32,250 --> 00:54:43,050
embeddings in case you have new words in

1257
00:54:34,289 --> 00:54:48,509
the test set oh I mean we're gonna be

1258
00:54:43,050 --> 00:54:49,410
fine-tuning them you know and so yeah I

1259
00:54:48,510 --> 00:54:53,520
don't know I mean it's an interesting

1260
00:54:49,409 --> 00:54:58,429
idea maybe that would work I haven't

1261
00:54:53,519 --> 00:55:01,380
tried it I mean obviously you wouldn't

1262
00:54:58,429 --> 00:55:04,529
so can you use that

1263
00:55:01,380 --> 00:55:07,110
I asked the question so you can also add

1264
00:55:04,530 --> 00:55:10,080
random embedding to those and the

1265
00:55:07,110 --> 00:55:12,150
beginning just keep them random on but

1266
00:55:10,079 --> 00:55:13,889
you're gonna have bigs gonna make it an

1267
00:55:12,150 --> 00:55:18,119
effect in the sense that you are going

1268
00:55:13,889 --> 00:55:20,099
to be using those words yeah yep I think

1269
00:55:18,119 --> 00:55:23,009
it's an interesting line of inquiry but

1270
00:55:20,099 --> 00:55:25,409
I will say this the vast majority of the

1271
00:55:23,010 --> 00:55:28,080
time when you're kind of doing this in

1272
00:55:25,409 --> 00:55:30,210
the real world your vocabulary will be

1273
00:55:28,079 --> 00:55:32,119
bigger than 40-thousand and once your

1274
00:55:30,210 --> 00:55:36,329
vocab areas bigger than 40-thousand

1275
00:55:32,119 --> 00:55:38,190
using the standard techniques you the

1276
00:55:36,329 --> 00:55:39,869
embedding layers gets so big that it

1277
00:55:38,190 --> 00:55:42,179
takes up all your memory it takes up all

1278
00:55:39,869 --> 00:55:44,309
of the time and the backdrop there are

1279
00:55:42,179 --> 00:55:46,349
tricks to dealing with very large vocab

1280
00:55:44,309 --> 00:55:49,650
Riis I don't think we'll have time to

1281
00:55:46,349 --> 00:55:51,750
handle them in this session but you

1282
00:55:49,650 --> 00:55:54,210
definitely would not want to have all

1283
00:55:51,750 --> 00:55:59,039
three and a half million fast text

1284
00:55:54,210 --> 00:56:01,889
vectors in a in an embedding layer so I

1285
00:55:59,039 --> 00:56:04,500
I wonder so if you're not touching a

1286
00:56:01,889 --> 00:56:06,809
word it's not gonna change right like

1287
00:56:04,500 --> 00:56:11,010
you and we are fine-tuning right you are

1288
00:56:06,809 --> 00:56:12,960
not it's in GPU Ram and you're gonna

1289
00:56:11,010 --> 00:56:16,590
remember three and a half million times

1290
00:56:12,960 --> 00:56:19,019
three hundred times the size of a single

1291
00:56:16,590 --> 00:56:20,820
precision floating point vector plus all

1292
00:56:19,019 --> 00:56:24,690
of the gradients for them even if it's

1293
00:56:20,820 --> 00:56:27,600
not touched like they're without being

1294
00:56:24,690 --> 00:56:32,970
very careful and adding a lot more code

1295
00:56:27,599 --> 00:56:35,250
and stuff it is slow and hard and when

1296
00:56:32,969 --> 00:56:36,809
we wouldn't touch it for now but as I

1297
00:56:35,250 --> 00:56:38,969
say I think there's an interesting path

1298
00:56:36,809 --> 00:56:41,009
of inquiry but it's the kind of path of

1299
00:56:38,969 --> 00:56:43,529
inquiry that leads to like multiple

1300
00:56:41,010 --> 00:56:45,690
academic papers not you know something

1301
00:56:43,530 --> 00:56:48,600
that you do on a weekend but I think

1302
00:56:45,690 --> 00:56:51,900
would be very interesting for ya maybe

1303
00:56:48,599 --> 00:56:53,940
we can look at at some time you know and

1304
00:56:51,900 --> 00:56:56,280
as I say I have actually started doing

1305
00:56:53,940 --> 00:56:58,230
some stuff around incorporating large

1306
00:56:56,280 --> 00:57:01,110
for cavalry handing handling into fast

1307
00:56:58,230 --> 00:57:03,329
AI it's not finished but hopefully by

1308
00:57:01,110 --> 00:57:08,760
the time we get here this kind of stuff

1309
00:57:03,329 --> 00:57:11,489
would be possible ok so we create our

1310
00:57:08,760 --> 00:57:14,970
encoder embedding add a bit of drop out

1311
00:57:11,489 --> 00:57:17,879
ok and then we create our an end

1312
00:57:14,969 --> 00:57:20,129
this input to the RNN obviously is the

1313
00:57:17,880 --> 00:57:22,050
size of the embedding by Bodie by

1314
00:57:20,130 --> 00:57:24,440
definition number of hidden is whatever

1315
00:57:22,050 --> 00:57:29,280
we watch so we set up to 256 for now

1316
00:57:24,440 --> 00:57:30,960
however many layers we want hands and

1317
00:57:29,280 --> 00:57:32,610
drop out inside the arent as well okay

1318
00:57:30,960 --> 00:57:34,289
so this is all standard height watch

1319
00:57:32,610 --> 00:57:36,420
stuff you could use ur LS TM here as

1320
00:57:34,289 --> 00:57:39,599
well and then finally we need to turn

1321
00:57:36,420 --> 00:57:41,190
that into some output that we're going

1322
00:57:39,599 --> 00:57:43,139
to feed to the decoder so let's use a

1323
00:57:41,190 --> 00:57:46,500
linear layer to convert the number of

1324
00:57:43,139 --> 00:57:50,969
hidden into the decoder embedding sites

1325
00:57:46,500 --> 00:57:54,329
okay so in the forward pass here's how

1326
00:57:50,969 --> 00:57:57,719
that's used we first of all initialize

1327
00:57:54,329 --> 00:58:01,340
our hidden state to a bunch of zeros

1328
00:57:57,719 --> 00:58:04,980
okay so we've now had a vector of zeros

1329
00:58:01,340 --> 00:58:06,000
which we and then we're going to take

1330
00:58:04,980 --> 00:58:08,219
our input and put it through our

1331
00:58:06,000 --> 00:58:10,969
embedding we're going to put that

1332
00:58:08,219 --> 00:58:13,859
through drop out we then pass our

1333
00:58:10,969 --> 00:58:16,049
currently zeros hidden state and our

1334
00:58:13,860 --> 00:58:18,780
embeddings into our R and N and it's

1335
00:58:16,050 --> 00:58:22,320
going to spit out the usual stuff that I

1336
00:58:18,780 --> 00:58:25,950
ran in spit up which includes the final

1337
00:58:22,320 --> 00:58:27,990
hidden state we're then going to take

1338
00:58:25,949 --> 00:58:30,419
that final hidden stake and stick it

1339
00:58:27,989 --> 00:58:31,919
through that linear layer so we now have

1340
00:58:30,420 --> 00:58:35,220
something of the right size to feature

1341
00:58:31,920 --> 00:58:38,970
our decoder okay so that's that's it and

1342
00:58:35,219 --> 00:58:40,649
again this is like ought to be very

1343
00:58:38,969 --> 00:58:43,799
familiar and very comfortable it's like

1344
00:58:40,650 --> 00:58:45,539
the most simple possible iron n so if

1345
00:58:43,800 --> 00:58:46,769
it's not go back check out lesson six

1346
00:58:45,539 --> 00:58:49,679
make sure you can write it from scratch

1347
00:58:46,769 --> 00:58:53,780
and that you understand what it does but

1348
00:58:49,679 --> 00:58:53,779
the key thing to know is that it takes

1349
00:58:53,840 --> 00:59:04,050
our inputs and spits out a hidden vector

1350
00:58:59,789 --> 00:59:07,679
that hopefully will learn to contain all

1351
00:59:04,050 --> 00:59:11,400
of the information about what that

1352
00:59:07,679 --> 00:59:14,269
sentence says and how it says it because

1353
00:59:11,400 --> 00:59:14,269
if it can't do that

1354
00:59:15,650 --> 00:59:20,760
all right if we can't do that then we

1355
00:59:18,659 --> 00:59:23,519
can't feed it into a decoder and hope it

1356
00:59:20,760 --> 00:59:26,250
to spit out our sentence in a different

1357
00:59:23,519 --> 00:59:28,259
language so that's what we want it to

1358
00:59:26,250 --> 00:59:29,369
learn to do

1359
00:59:28,260 --> 00:59:30,870
and we're not going to do anything

1360
00:59:29,369 --> 00:59:33,569
special to make it learn to do that

1361
00:59:30,869 --> 00:59:36,089
we're just gonna do you know the three

1362
00:59:33,570 --> 00:59:42,539
things and cross our fingers because

1363
00:59:36,090 --> 00:59:47,640
that's what we do all right so that's H

1364
00:59:42,539 --> 00:59:48,449
is is that yes all right so it's a

1365
00:59:47,639 --> 00:59:50,639
hidden stick

1366
00:59:48,449 --> 00:59:53,609
I guess Stephen used s for state I used

1367
00:59:50,639 --> 00:59:55,049
HB hidden but there you go you would

1368
00:59:53,610 --> 00:59:56,809
think the two Australians could agree on

1369
00:59:55,050 --> 01:00:03,210
something like that but apparently not

1370
00:59:56,809 --> 01:00:05,789
so how do we now do the new bit right

1371
01:00:03,210 --> 01:00:07,920
and so the basic idea of the new bit is

1372
01:00:05,789 --> 01:00:11,070
the same we're going to do exactly the

1373
01:00:07,920 --> 01:00:14,610
same thing but we're going to write our

1374
01:00:11,070 --> 01:00:16,860
own forward okay and so the full loop is

1375
01:00:14,610 --> 01:00:19,920
going to do exactly what the for loop

1376
01:00:16,860 --> 01:00:21,300
inside pi torch does here but we're

1377
01:00:19,920 --> 01:00:23,340
going to do it manually right so we've

1378
01:00:21,300 --> 01:00:24,740
got to go through the forward and how

1379
01:00:23,340 --> 01:00:28,440
big is the for loop

1380
01:00:24,739 --> 01:00:30,359
it's a output sequence length well what

1381
01:00:28,440 --> 01:00:32,179
is output sequence length that's

1382
01:00:30,360 --> 01:00:37,470
something that passed to the constructor

1383
01:00:32,179 --> 01:00:39,899
and it is equal to the length of the

1384
01:00:37,469 --> 01:00:43,169
largest English sentence okay

1385
01:00:39,900 --> 01:00:45,480
so we're going to do this for loop as

1386
01:00:43,170 --> 01:00:46,680
long as the largest English sentence

1387
01:00:45,480 --> 01:00:48,659
because we're translating into English

1388
01:00:46,679 --> 01:00:50,869
right so we can't possibly be longer

1389
01:00:48,659 --> 01:00:50,869
than that

1390
01:00:52,170 --> 01:00:56,820
at least not in this corpus if we then

1391
01:00:55,409 --> 01:01:00,779
used it on some different corpus that

1392
01:00:56,820 --> 01:01:02,880
was longer this is going to fail so but

1393
01:01:00,780 --> 01:01:05,490
you could make this you know you could

1394
01:01:02,880 --> 01:01:08,280
always pass in a different parameter of

1395
01:01:05,489 --> 01:01:09,689
course all right so the basic idea is

1396
01:01:08,280 --> 01:01:11,630
the same we're going to go through and

1397
01:01:09,690 --> 01:01:13,889
put it through the in the embedding

1398
01:01:11,630 --> 01:01:15,269
we're going to stick it through the R

1399
01:01:13,889 --> 01:01:17,159
and n we're going to stick it through

1400
01:01:15,269 --> 01:01:19,230
drop out and we're going to stick it

1401
01:01:17,159 --> 01:01:23,279
through a linear layer all right so the

1402
01:01:19,230 --> 01:01:24,900
basic four steps are the same and once

1403
01:01:23,280 --> 01:01:29,700
we've done that we're then going to

1404
01:01:24,900 --> 01:01:30,750
append that output to a list fat and

1405
01:01:29,699 --> 01:01:32,699
then when we're going to finish we're

1406
01:01:30,750 --> 01:01:35,460
going to stack that list up into a

1407
01:01:32,699 --> 01:01:37,969
single tensor and return it okay that's

1408
01:01:35,460 --> 01:01:41,139
the basic idea

1409
01:01:37,969 --> 01:01:42,789
normally a recurrent neural network

1410
01:01:41,139 --> 01:01:45,400
here is our decoder current neural

1411
01:01:42,789 --> 01:01:47,619
network recurrent neural network works

1412
01:01:45,400 --> 01:01:49,539
on a whole sequence at a time but we've

1413
01:01:47,619 --> 01:01:52,150
got a for loop to go through each part

1414
01:01:49,539 --> 01:01:55,920
of the sequence separately so we have to

1415
01:01:52,150 --> 01:01:58,840
add a leading unit access to the start

1416
01:01:55,920 --> 01:02:01,090
to basically say this is a sequence of

1417
01:01:58,840 --> 01:02:03,640
length 1 okay so we're not really taking

1418
01:02:01,090 --> 01:02:05,710
advantage of the recurrent net much at

1419
01:02:03,639 --> 01:02:07,539
all we could easily rewrite this with a

1420
01:02:05,710 --> 01:02:09,010
linear layer actually that would be an

1421
01:02:07,539 --> 01:02:13,449
interesting experiment if you wanted to

1422
01:02:09,010 --> 01:02:18,700
try it so we basically take our input

1423
01:02:13,449 --> 01:02:20,439
and we feed it into our embedding and we

1424
01:02:18,699 --> 01:02:22,869
add something to the front saying treat

1425
01:02:20,440 --> 01:02:28,530
this as a sequence of length 1 and then

1426
01:02:22,869 --> 01:02:31,630
we pass that to our M we then get the

1427
01:02:28,530 --> 01:02:35,230
output of that RNN feed it into our

1428
01:02:31,630 --> 01:02:36,730
dropout and 15:20 me a layer so there's

1429
01:02:35,230 --> 01:02:39,250
two extra things to know that be aware

1430
01:02:36,730 --> 01:02:43,840
of well I guess it's really one thing

1431
01:02:39,250 --> 01:02:46,809
the one thing is what's this what is the

1432
01:02:43,840 --> 01:02:51,340
input to that embedding okay and the

1433
01:02:46,809 --> 01:02:54,369
answer is it's the previous word that we

1434
01:02:51,340 --> 01:02:57,070
translated see how the input here is the

1435
01:02:54,369 --> 01:02:59,079
previous word here the input here is the

1436
01:02:57,070 --> 01:03:02,680
previous word here so the basic idea is

1437
01:02:59,079 --> 01:03:05,319
if you're trying to translate if you're

1438
01:03:02,679 --> 01:03:07,719
about to translate you know tell me the

1439
01:03:05,320 --> 01:03:09,430
fourth word of the new sentence but you

1440
01:03:07,719 --> 01:03:11,559
don't know what the third word you just

1441
01:03:09,429 --> 01:03:15,699
said was that's going to be really hard

1442
01:03:11,559 --> 01:03:17,769
all right so we're gonna feed that in at

1443
01:03:15,699 --> 01:03:19,689
each time step let's make it as easy as

1444
01:03:17,769 --> 01:03:21,610
possible okay and so what was the

1445
01:03:19,690 --> 01:03:22,059
previous word at the start for the Rawls

1446
01:03:21,610 --> 01:03:25,750
month

1447
01:03:22,059 --> 01:03:36,840
okay so specifically we're gonna start

1448
01:03:25,750 --> 01:03:39,309
out with a beginning of stream took it

1449
01:03:36,840 --> 01:03:45,400
okay so the beginning of stream token is

1450
01:03:39,309 --> 01:03:48,039
a zero so let's start out our decoder

1451
01:03:45,400 --> 01:03:49,599
with a beginning of stream token which

1452
01:03:48,039 --> 01:03:50,889
is zero okay

1453
01:03:49,599 --> 01:03:53,500
and of course we're doing a mini batch

1454
01:03:50,889 --> 01:03:55,150
so we need batch size number of them but

1455
01:03:53,500 --> 01:03:57,539
let's just think about one part

1456
01:03:55,150 --> 01:04:00,369
- so we've got we start out with a zero

1457
01:03:57,539 --> 01:04:02,739
we look at that zero in our in our

1458
01:04:00,369 --> 01:04:04,839
embedding matrix to find out what the

1459
01:04:02,739 --> 01:04:07,839
vector for the beginning a stream token

1460
01:04:04,840 --> 01:04:09,970
is we stick a unit axis on the front to

1461
01:04:07,840 --> 01:04:12,970
say we have a single sequence length of

1462
01:04:09,969 --> 01:04:16,839
beginning of stream token we stick that

1463
01:04:12,969 --> 01:04:19,029
through our RM which gets not only the

1464
01:04:16,840 --> 01:04:22,300
fact that there's a zero is beginning of

1465
01:04:19,030 --> 01:04:25,269
stream but also the hidden state which

1466
01:04:22,300 --> 01:04:29,800
at this point is whatever came out of

1467
01:04:25,269 --> 01:04:34,690
our encoder okay so this now its job is

1468
01:04:29,800 --> 01:04:37,330
to try and figure out what it's the

1469
01:04:34,690 --> 01:04:40,240
first word okay what's the first word to

1470
01:04:37,329 --> 01:04:43,480
translate the sentence pop through some

1471
01:04:40,239 --> 01:04:45,189
drop out go through one linear layer in

1472
01:04:43,480 --> 01:04:48,490
order to convert that into the correct

1473
01:04:45,190 --> 01:04:52,079
size for our decoder embedding matrix

1474
01:04:48,489 --> 01:04:56,199
okay append that to our list of

1475
01:04:52,079 --> 01:04:58,269
translated words and now we need to

1476
01:04:56,199 --> 01:05:02,500
figure out what word that was because we

1477
01:04:58,269 --> 01:05:03,639
need to feed it to the next time step we

1478
01:05:02,500 --> 01:05:08,050
need to feed it to the next time step

1479
01:05:03,639 --> 01:05:10,629
okay so remember what we actually output

1480
01:05:08,050 --> 01:05:13,330
here and and look at use a debugger

1481
01:05:10,630 --> 01:05:18,099
right pdb dot set trace put it here

1482
01:05:13,329 --> 01:05:19,960
what is at P now P is a tensor how big

1483
01:05:18,099 --> 01:05:22,000
is the tensor so before you look it up

1484
01:05:19,960 --> 01:05:23,590
in the debugger try and figure it out

1485
01:05:22,000 --> 01:05:27,280
from first principles and check you're

1486
01:05:23,590 --> 01:05:30,190
right so our P is a tensor whose length

1487
01:05:27,280 --> 01:05:32,800
is equal to the number of words in our

1488
01:05:30,190 --> 01:05:34,750
English vocabulary and it contains the

1489
01:05:32,800 --> 01:05:38,230
probability for every one of those words

1490
01:05:34,750 --> 01:05:44,500
that it is that word makes sense right

1491
01:05:38,230 --> 01:05:47,440
so then if we now say at P dot max that

1492
01:05:44,500 --> 01:05:50,800
looks in its tensor to find out which

1493
01:05:47,440 --> 01:05:53,559
word has the highest probability okay

1494
01:05:50,800 --> 01:05:55,840
and max imply Torche returns two things

1495
01:05:53,559 --> 01:05:57,969
the first thing is what is that max

1496
01:05:55,840 --> 01:06:00,070
probability and the second is what is

1497
01:05:57,969 --> 01:06:02,409
the index into the array of that mass

1498
01:06:00,070 --> 01:06:05,019
probability and so we want that second

1499
01:06:02,409 --> 01:06:08,799
item index number one which is the word

1500
01:06:05,019 --> 01:06:13,300
index with the largest thing okay so now

1501
01:06:08,800 --> 01:06:17,140
that contains the word well the word

1502
01:06:13,300 --> 01:06:18,910
index into a VOC a pre of the word if

1503
01:06:17,139 --> 01:06:20,949
it's a one right

1504
01:06:18,909 --> 01:06:22,929
you might remember one was padding then

1505
01:06:20,949 --> 01:06:24,339
that means we're done right that means

1506
01:06:22,929 --> 01:06:27,099
we've reached the end because we

1507
01:06:24,340 --> 01:06:29,070
finished with a bunch of padding okay if

1508
01:06:27,099 --> 01:06:35,500
it's not one let's go back and continue

1509
01:06:29,070 --> 01:06:38,200
but now Dec M is whatever the highest

1510
01:06:35,500 --> 01:06:40,739
probability word was but so we keep

1511
01:06:38,199 --> 01:06:44,279
looping through either until we get to

1512
01:06:40,739 --> 01:06:47,769
the largest length of a sentence or

1513
01:06:44,280 --> 01:06:51,130
until everything in our mini batch is

1514
01:06:47,769 --> 01:06:54,639
padding and each time we've appended our

1515
01:06:51,130 --> 01:06:57,490
outputs each time not not the word with

1516
01:06:54,639 --> 01:07:00,699
the probabilities okay to this list

1517
01:06:57,489 --> 01:07:02,769
which we stack up into a tensor and we

1518
01:07:00,699 --> 01:07:06,000
can now go ahead and feed that to a loss

1519
01:07:02,769 --> 01:07:11,409
function so before we go to a break

1520
01:07:06,000 --> 01:07:13,690
since we've done one and two let's do

1521
01:07:11,409 --> 01:07:16,690
three which is the last function the

1522
01:07:13,690 --> 01:07:18,849
last function is categorical

1523
01:07:16,690 --> 01:07:21,820
cross-entropy loss okay we've got a list

1524
01:07:18,849 --> 01:07:24,849
of probabilities for each of our classes

1525
01:07:21,820 --> 01:07:27,160
that the classes are all the words in

1526
01:07:24,849 --> 01:07:29,380
our English vocab and we have a target

1527
01:07:27,159 --> 01:07:31,779
which is which is the correct class ie

1528
01:07:29,380 --> 01:07:35,230
which is the correct word at this

1529
01:07:31,780 --> 01:07:36,430
location there's two tweaks which is why

1530
01:07:35,230 --> 01:07:38,170
we need to write our own little loss

1531
01:07:36,429 --> 01:07:40,029
function but you can see basically it's

1532
01:07:38,170 --> 01:07:42,340
going to be cross interview that's right

1533
01:07:40,030 --> 01:07:45,550
and the tweaks are as follows tweak

1534
01:07:42,340 --> 01:07:48,250
number one is we might have stopped a

1535
01:07:45,550 --> 01:07:50,440
little bit early right and so the

1536
01:07:48,250 --> 01:07:52,360
sequence length that we generated may be

1537
01:07:50,440 --> 01:07:54,400
different to the sequence length of the

1538
01:07:52,360 --> 01:07:58,090
target in which case we need to add some

1539
01:07:54,400 --> 01:08:01,900
padding right height or padding function

1540
01:07:58,090 --> 01:08:08,740
is weird if you have a rank three cancer

1541
01:08:01,900 --> 01:08:11,460
which we do we have batch size by sorry

1542
01:08:08,739 --> 01:08:14,829
we have sequence length by batch size by

1543
01:08:11,460 --> 01:08:19,720
number of words in the vocab Iraq three

1544
01:08:14,829 --> 01:08:21,489
tensor requires a six tupple each pair

1545
01:08:19,720 --> 01:08:22,659
and things in that topple is the padding

1546
01:08:21,489 --> 01:08:26,170
before and

1547
01:08:22,659 --> 01:08:28,420
the padding after that that dimension

1548
01:08:26,170 --> 01:08:29,800
all right so in this case the first

1549
01:08:28,420 --> 01:08:31,539
dimension has no padding the second

1550
01:08:29,800 --> 01:08:33,730
dimension has no padding the third

1551
01:08:31,539 --> 01:08:35,979
dimension has no padding on the left and

1552
01:08:33,729 --> 01:08:38,769
as much padding is required on the right

1553
01:08:35,979 --> 01:08:42,039
okay so it's good to know how to use

1554
01:08:38,770 --> 01:08:44,290
that function now that we've added any

1555
01:08:42,039 --> 01:08:46,090
padding that's necessary the only other

1556
01:08:44,289 --> 01:08:49,180
thing we need to do is cross entropy

1557
01:08:46,090 --> 01:08:51,909
loss expects a rank two tensor I

1558
01:08:49,180 --> 01:08:54,070
mentioned matrix but we've got sequence

1559
01:08:51,909 --> 01:08:55,689
length by batch size so let's just

1560
01:08:54,069 --> 01:08:58,840
flatten out the sequence length and

1561
01:08:55,689 --> 01:09:01,719
batch size into a that's what that minus

1562
01:08:58,840 --> 01:09:03,789
one in view does okay so flatten out

1563
01:09:01,720 --> 01:09:05,789
that for both of them and now we can go

1564
01:09:03,789 --> 01:09:10,539
ahead and call cross-entropy

1565
01:09:05,789 --> 01:09:14,140
that's it so now we can just use the

1566
01:09:10,539 --> 01:09:16,779
standard approach here's our sequence of

1567
01:09:14,140 --> 01:09:19,829
sequence R and n that's this one yeah so

1568
01:09:16,779 --> 01:09:23,649
that is a standard pipe watch module

1569
01:09:19,829 --> 01:09:27,010
stick it on the GPU hopefully by now

1570
01:09:23,649 --> 01:09:30,039
you've noticed you you can call CUDA but

1571
01:09:27,010 --> 01:09:32,140
if you call to GPU then it doesn't put

1572
01:09:30,039 --> 01:09:35,260
it on the GPU if you don't have one you

1573
01:09:32,140 --> 01:09:37,390
can also set faster I don't use GPU to

1574
01:09:35,260 --> 01:09:40,380
false to force it to not use the GPU and

1575
01:09:37,390 --> 01:09:43,570
that can be super handy for debugging

1576
01:09:40,380 --> 01:09:46,510
we then need something that tells it how

1577
01:09:43,569 --> 01:09:48,909
to handle learning rates learning rate

1578
01:09:46,510 --> 01:09:50,739
groups so there's a thing called single

1579
01:09:48,909 --> 01:09:52,090
model that you can pass it to which

1580
01:09:50,739 --> 01:09:54,579
treats the whole thing as a single

1581
01:09:52,090 --> 01:09:56,710
learning rate group so this is like this

1582
01:09:54,579 --> 01:10:01,420
easiest way to turn a height watch

1583
01:09:56,710 --> 01:10:05,199
module into a fast AI model here's the

1584
01:10:01,420 --> 01:10:06,909
model data object we created before we

1585
01:10:05,199 --> 01:10:10,239
could then just call lerner to turn that

1586
01:10:06,909 --> 01:10:16,510
into a learner but if we call our NN

1587
01:10:10,239 --> 01:10:18,309
learner our NN learner is a learner it

1588
01:10:16,510 --> 01:10:20,470
defines cross-entropy as the default

1589
01:10:18,310 --> 01:10:22,090
criteria this case we're overriding that

1590
01:10:20,470 --> 01:10:25,720
anyway so that's not what we care about

1591
01:10:22,090 --> 01:10:29,140
but it does add in these save encoder

1592
01:10:25,720 --> 01:10:32,530
and load encoder things that can be any

1593
01:10:29,140 --> 01:10:35,800
sometimes so we could have in this case

1594
01:10:32,529 --> 01:10:38,859
we're really pretty to set learner but

1595
01:10:35,800 --> 01:10:42,400
Aaron Lerner also works ok so here's how

1596
01:10:38,859 --> 01:10:46,659
we turn our height watch module into a

1597
01:10:42,399 --> 01:10:50,589
fast AO model into a and once we have a

1598
01:10:46,659 --> 01:10:53,920
learner give it our new loss function

1599
01:10:50,590 --> 01:10:56,949
and then we can call LR find and we can

1600
01:10:53,920 --> 01:10:59,829
call Fitch and it runs through awhile

1601
01:10:56,949 --> 01:11:02,979
and we can save it you know the normal

1602
01:10:59,829 --> 01:11:04,569
learn stuff now works the remember the

1603
01:11:02,979 --> 01:11:06,909
model attribute of a learner is a

1604
01:11:04,569 --> 01:11:11,229
standard piped watch model so we can

1605
01:11:06,909 --> 01:11:13,750
pass that sum X which we can grab out of

1606
01:11:11,229 --> 01:11:15,429
our validation set or you could use lo

1607
01:11:13,750 --> 01:11:20,229
not predict array or whatever you like

1608
01:11:15,430 --> 01:11:22,480
if you get some predictions and then we

1609
01:11:20,229 --> 01:11:25,629
can convert those predictions into words

1610
01:11:22,479 --> 01:11:28,149
by grabbing going dot max 1 to grab the

1611
01:11:25,630 --> 01:11:30,819
index of the highest probability words

1612
01:11:28,149 --> 01:11:33,429
to get some predictions and then we can

1613
01:11:30,819 --> 01:11:37,840
go through a few examples and print out

1614
01:11:33,430 --> 01:11:41,200
the French the correct English and the

1615
01:11:37,840 --> 01:11:46,619
predicted English for things that are

1616
01:11:41,199 --> 01:11:49,500
not padding and here we go alright so

1617
01:11:46,619 --> 01:11:53,349
amazingly enough this kind of like

1618
01:11:49,500 --> 01:11:56,050
simplest possible written largely from

1619
01:11:53,350 --> 01:11:59,230
scratch PI torch module and only fifty

1620
01:11:56,050 --> 01:12:00,820
thousand sentences is sometimes capable

1621
01:11:59,229 --> 01:12:02,789
on a validation set of giving you

1622
01:12:00,819 --> 01:12:06,279
exactly the right answer

1623
01:12:02,789 --> 01:12:09,430
sometimes the right answer in slightly

1624
01:12:06,279 --> 01:12:11,319
different wording and sometimes

1625
01:12:09,430 --> 01:12:13,060
sentences that really are grammatically

1626
01:12:11,319 --> 01:12:15,519
sensible or even have too many question

1627
01:12:13,060 --> 01:12:19,510
marks so we're we're well on the right

1628
01:12:15,520 --> 01:12:21,580
track I think you would agree so you

1629
01:12:19,510 --> 01:12:24,340
know even the simplest possible sector

1630
01:12:21,579 --> 01:12:28,659
SiC trained for a very small number of

1631
01:12:24,340 --> 01:12:30,900
epochs without any you know pre-training

1632
01:12:28,659 --> 01:12:33,189
other than the use of word embeddings

1633
01:12:30,899 --> 01:12:34,569
surprisingly good so I think you know

1634
01:12:33,189 --> 01:12:36,219
the message here and we're going to

1635
01:12:34,569 --> 01:12:38,849
improve this for the moment after the

1636
01:12:36,220 --> 01:12:41,470
break but I think the message here is

1637
01:12:38,850 --> 01:12:43,240
even sequence to sequence models you

1638
01:12:41,470 --> 01:12:45,850
think as simple of them to possibly work

1639
01:12:43,239 --> 01:12:49,090
even with less data than you think you

1640
01:12:45,850 --> 01:12:51,940
could learn from can be surprisingly

1641
01:12:49,090 --> 01:12:54,190
and in certain situations this main even

1642
01:12:51,939 --> 01:12:58,289
you know be enough for your needs

1643
01:12:54,189 --> 01:13:01,559
so we're going to learn a few tricks

1644
01:12:58,289 --> 01:13:03,010
after the break which will make this

1645
01:13:01,560 --> 01:13:11,110
much better

1646
01:13:03,010 --> 01:13:13,300
so let's come back at 750 so one

1647
01:13:11,109 --> 01:13:20,529
question that came up during the break

1648
01:13:13,300 --> 01:13:25,599
is that some of the tokens that are

1649
01:13:20,529 --> 01:13:27,759
missing in fast text like had a a curly

1650
01:13:25,599 --> 01:13:30,460
quote rather than a straight quote for

1651
01:13:27,760 --> 01:13:36,310
example and the question was would it

1652
01:13:30,460 --> 01:13:37,569
help to normalize punctuation and the

1653
01:13:36,310 --> 01:13:39,940
answer for this particular case is

1654
01:13:37,569 --> 01:13:41,769
probably yes the difference between

1655
01:13:39,939 --> 01:13:45,039
curly quotes and straight quotes is

1656
01:13:41,770 --> 01:13:48,070
rarely semantics you do have to be very

1657
01:13:45,039 --> 01:13:51,639
careful though because like it may turn

1658
01:13:48,069 --> 01:13:54,039
out that people using beautiful curly

1659
01:13:51,639 --> 01:13:55,690
quotes like using more formal language

1660
01:13:54,039 --> 01:13:59,050
and they're actually writing in a

1661
01:13:55,689 --> 01:14:00,598
different way so I generally you know if

1662
01:13:59,050 --> 01:14:02,860
you're going to do some kind of

1663
01:14:00,599 --> 01:14:05,079
pre-processing like punctuation

1664
01:14:02,859 --> 01:14:06,658
normalization you should definitely

1665
01:14:05,079 --> 01:14:09,819
check your results with and without

1666
01:14:06,658 --> 01:14:11,888
because like nearly always that kind of

1667
01:14:09,819 --> 01:14:14,519
pre-processing makes things worse even

1668
01:14:11,889 --> 01:14:14,520
when I'm sure it won't

1669
01:14:15,719 --> 01:14:21,789
hello what would be some ways over what

1670
01:14:19,238 --> 01:14:25,559
I seen these sequence of sequence

1671
01:14:21,789 --> 01:14:25,560
besides through power and weight again

1672
01:14:27,300 --> 01:14:37,449
let me think about that during the week

1673
01:14:29,289 --> 01:14:39,729
yeah it's like you know a wdl STM which

1674
01:14:37,448 --> 01:14:42,488
we've been relying on a lot has so many

1675
01:14:39,729 --> 01:14:44,709
great I mean it's it's all drop out well

1676
01:14:42,488 --> 01:14:47,289
not all drop out those drop out of many

1677
01:14:44,710 --> 01:14:48,939
different kinds there's and then there's

1678
01:14:47,289 --> 01:14:51,269
the we haven't talked about it much but

1679
01:14:48,939 --> 01:14:55,269
there's also a kind of a regularization

1680
01:14:51,270 --> 01:14:56,409
based on activations and stuff like that

1681
01:14:55,270 --> 01:15:00,310
as well

1682
01:14:56,408 --> 01:15:03,069
and on changes and whatever I just

1683
01:15:00,310 --> 01:15:04,360
haven't seen anybody put in a

1684
01:15:03,069 --> 01:15:06,130
thing like that amount of work into

1685
01:15:04,359 --> 01:15:07,539
regularization of sequence to sequence

1686
01:15:06,130 --> 01:15:10,720
models and I think there's a huge

1687
01:15:07,539 --> 01:15:14,560
opportunity for somebody to do like the

1688
01:15:10,720 --> 01:15:16,810
AWD LS TM of sectors ik which might be

1689
01:15:14,560 --> 01:15:19,390
as simple as dealing all the ideas from

1690
01:15:16,810 --> 01:15:21,610
a top UDS VLS TM and using them directly

1691
01:15:19,390 --> 01:15:26,110
in Sector SEC that would be pretty easy

1692
01:15:21,609 --> 01:15:28,149
to try I think and there's been an

1693
01:15:26,109 --> 01:15:29,949
interesting paper that actually Steven

1694
01:15:28,149 --> 01:15:33,029
Rarity's added in the last couple of

1695
01:15:29,949 --> 01:15:35,500
weeks where he used an idea which I

1696
01:15:33,029 --> 01:15:36,789
don't know if he stole it from me but it

1697
01:15:35,500 --> 01:15:37,989
was certainly something I had also

1698
01:15:36,789 --> 01:15:38,319
recently done and talked about on

1699
01:15:37,989 --> 01:15:40,479
Twitter

1700
01:15:38,319 --> 01:15:44,049
either way I'm thrilled that he's done

1701
01:15:40,479 --> 01:15:46,959
it which was to take all of those

1702
01:15:44,050 --> 01:15:49,119
different AWD LS TM hyper parameters and

1703
01:15:46,960 --> 01:15:51,939
train a bunch of different models and

1704
01:15:49,119 --> 01:15:53,800
then I use a random forest to find out

1705
01:15:51,939 --> 01:15:55,389
with feature importance which ones

1706
01:15:53,800 --> 01:15:59,199
actually met at the most and then figure

1707
01:15:55,390 --> 01:16:03,010
out like how to set them yeah so I think

1708
01:15:59,199 --> 01:16:05,139
you could totally you know use this

1709
01:16:03,010 --> 01:16:06,280
approach to figure out you know for

1710
01:16:05,140 --> 01:16:07,900
sequence the sequence regularization

1711
01:16:06,279 --> 01:16:12,960
approaches which one's the best and

1712
01:16:07,899 --> 01:16:12,960
optimize them and that would be amazing

1713
01:16:13,439 --> 01:16:17,769
yeah but at the moment I think you know

1714
01:16:15,970 --> 01:16:19,090
I I don't know that there are additional

1715
01:16:17,770 --> 01:16:20,710
ideas to sequence the sequence

1716
01:16:19,090 --> 01:16:23,289
regularization that I can think of

1717
01:16:20,710 --> 01:16:25,930
beyond what's in that paper for regular

1718
01:16:23,289 --> 01:16:28,289
language models stuff and probably all

1719
01:16:25,930 --> 01:16:34,900
those same approaches would would work

1720
01:16:28,289 --> 01:16:38,109
okay so tricks trick number one go

1721
01:16:34,899 --> 01:16:40,589
bi-directional okay so for

1722
01:16:38,109 --> 01:16:40,589
classification

1723
01:16:41,430 --> 01:16:47,350
my approach to bi-directional that I

1724
01:16:44,140 --> 01:16:50,500
suggested you use is take all of your

1725
01:16:47,350 --> 01:16:52,660
token sequences spin them around and

1726
01:16:50,500 --> 01:16:54,430
train a new language model and train a

1727
01:16:52,659 --> 01:16:57,760
new traffic classifier and I also

1728
01:16:54,430 --> 01:17:01,450
mentioned the wiki text pre train model

1729
01:16:57,760 --> 01:17:03,670
if you replace FWD with vwd in the name

1730
01:17:01,449 --> 01:17:05,380
you'll get the pre-trained backward

1731
01:17:03,670 --> 01:17:08,170
model I created for you okay so you can

1732
01:17:05,380 --> 01:17:10,090
use that get a set of predictions and

1733
01:17:08,170 --> 01:17:12,609
then average the predictions just like a

1734
01:17:10,090 --> 01:17:15,100
normal ensemble okay and that's kind of

1735
01:17:12,609 --> 01:17:16,420
how we do Baidu for that kind of

1736
01:17:15,100 --> 01:17:19,989
classification there

1737
01:17:16,420 --> 01:17:21,550
maybe ways to do it end to end but I

1738
01:17:19,988 --> 01:17:23,019
haven't quite figured them out yet

1739
01:17:21,550 --> 01:17:24,190
they're not in first AI yet and I don't

1740
01:17:23,020 --> 01:17:26,710
think anybody's written a paper about

1741
01:17:24,189 --> 01:17:29,819
them yet so if you figure it out

1742
01:17:26,710 --> 01:17:29,819
that's an interesting line of research

1743
01:17:30,659 --> 01:17:37,210
but because we're not doing you know

1744
01:17:34,469 --> 01:17:39,039
massive documents where we have to kind

1745
01:17:37,210 --> 01:17:41,380
of chunk it into separate bits and then

1746
01:17:39,039 --> 01:17:45,399
pall over them and whatever we can do by

1747
01:17:41,380 --> 01:17:46,719
do very easily in this case which is

1748
01:17:45,399 --> 01:17:52,198
literally as simple as adding

1749
01:17:46,719 --> 01:17:52,198
bidirectional equals true to our encoder

1750
01:17:53,039 --> 01:17:59,738
people tend not to do bi-directional for

1751
01:17:57,310 --> 01:18:05,560
the decoder I think partly because it's

1752
01:17:59,738 --> 01:18:07,539
kind of considered cheating but I don't

1753
01:18:05,560 --> 01:18:09,039
know like I was just talking to somebody

1754
01:18:07,539 --> 01:18:13,779
to break about it there you know maybe

1755
01:18:09,039 --> 01:18:15,819
it can work in some situations although

1756
01:18:13,779 --> 01:18:17,649
it might need to be more of a ensemble

1757
01:18:15,819 --> 01:18:19,299
approach in the decoder because you kind

1758
01:18:17,649 --> 01:18:21,519
of it's a bit less obvious anyway and

1759
01:18:19,300 --> 01:18:21,909
the ink into the encoder it's very very

1760
01:18:21,520 --> 01:18:24,190
simple

1761
01:18:21,909 --> 01:18:30,010
bi-directional equals true and we now

1762
01:18:24,189 --> 01:18:33,189
have with bi-directional equals true

1763
01:18:30,010 --> 01:18:36,159
rather than just having an RNN which is

1764
01:18:33,189 --> 01:18:40,719
going this direction we have a second

1765
01:18:36,159 --> 01:18:47,439
RNN that's going in this direction and

1766
01:18:40,719 --> 01:18:50,109
so that second RNN literally is visiting

1767
01:18:47,439 --> 01:18:52,869
them each token in the opposing order so

1768
01:18:50,109 --> 01:18:56,889
when we get the final here in state it's

1769
01:18:52,869 --> 01:19:00,219
here rather than here right but the

1770
01:18:56,890 --> 01:19:02,170
hidden state is of the same size so the

1771
01:19:00,219 --> 01:19:05,980
final result is that we end up with a

1772
01:19:02,170 --> 01:19:07,600
tensor that's got an extra to long axis

1773
01:19:05,979 --> 01:19:09,369
right and you know depending on what

1774
01:19:07,600 --> 01:19:11,770
library you use often that will be then

1775
01:19:09,369 --> 01:19:13,750
combined with the number of layers

1776
01:19:11,770 --> 01:19:16,929
things so if you've got two layers and

1777
01:19:13,750 --> 01:19:20,948
bi-directional that tensor dimension is

1778
01:19:16,929 --> 01:19:24,069
now length four with PI torch it kind of

1779
01:19:20,948 --> 01:19:25,689
depends which bit of the process you're

1780
01:19:24,069 --> 01:19:27,519
looking at as to whether you get a

1781
01:19:25,689 --> 01:19:29,559
separate result for each layer and offer

1782
01:19:27,520 --> 01:19:29,930
each bi-directional bit and so forth you

1783
01:19:29,560 --> 01:19:31,580
have to

1784
01:19:29,930 --> 01:19:35,090
cut the docs and it will tell you

1785
01:19:31,579 --> 01:19:36,409
inputs/outputs cancer sizes appropriate

1786
01:19:35,090 --> 01:19:39,140
for the number of layers and whether you

1787
01:19:36,409 --> 01:19:41,539
have bi-directional equals true in this

1788
01:19:39,140 --> 01:19:45,350
particular case you'll basically see all

1789
01:19:41,539 --> 01:19:46,640
the changes I've had to make so for

1790
01:19:45,350 --> 01:19:49,070
example you'll see when I added

1791
01:19:46,640 --> 01:19:51,350
bi-directional it was true my linear

1792
01:19:49,069 --> 01:19:53,960
layer now needs number of hidden times

1793
01:19:51,350 --> 01:19:57,670
to to reflect the fact that we have that

1794
01:19:53,960 --> 01:20:02,000
second direction in our hidden state now

1795
01:19:57,670 --> 01:20:04,640
you'll see in in it hidden it's now self

1796
01:20:02,000 --> 01:20:06,829
dot number of layers times two here okay

1797
01:20:04,640 --> 01:20:10,119
so you'll see there's a few places where

1798
01:20:06,829 --> 01:20:16,100
there's been an extra two that has to be

1799
01:20:10,119 --> 01:20:17,750
thrown in yes your net um why making any

1800
01:20:16,100 --> 01:20:21,950
color by the original is considered

1801
01:20:17,750 --> 01:20:25,010
cheating well it's it's not just this

1802
01:20:21,949 --> 01:20:29,869
cheating it's like we have this loop

1803
01:20:25,010 --> 01:20:34,610
going on you know it's not as simple as

1804
01:20:29,869 --> 01:20:38,000
just kind of having two tenses and then

1805
01:20:34,609 --> 01:20:41,689
like how do you turn those two separate

1806
01:20:38,000 --> 01:20:42,979
loops into a final result hey you know

1807
01:20:41,689 --> 01:20:46,759
after talking about it during the break

1808
01:20:42,979 --> 01:20:48,679
I've kind of gone from like hey

1809
01:20:46,760 --> 01:20:51,860
everybody knows it doesn't work to like

1810
01:20:48,680 --> 01:20:53,180
oh maybe it kind of could work but it

1811
01:20:51,859 --> 01:20:55,099
requires more thought it's quite

1812
01:20:53,180 --> 01:20:57,230
possible during the week I realize it's

1813
01:20:55,100 --> 01:20:59,420
a dumb idea and I was being stupid but

1814
01:20:57,229 --> 01:21:01,639
well think about it another question

1815
01:20:59,420 --> 01:21:05,329
people had why do you need to have an

1816
01:21:01,640 --> 01:21:07,340
into that look why do I have a watch of

1817
01:21:05,329 --> 01:21:09,710
the loop why do you need to like have a

1818
01:21:07,340 --> 01:21:13,659
an end to that look you have like a

1819
01:21:09,710 --> 01:21:17,060
range if your range yeah oh I mean it's

1820
01:21:13,659 --> 01:21:19,639
because when I start training

1821
01:21:17,060 --> 01:21:24,620
everything's random so this will

1822
01:21:19,640 --> 01:21:26,600
probably never be true so later on it'll

1823
01:21:24,619 --> 01:21:30,289
pretty much always break out eventually

1824
01:21:26,600 --> 01:21:34,430
but yeah it's basically like we're going

1825
01:21:30,289 --> 01:21:36,079
to go for it it's really important to

1826
01:21:34,430 --> 01:21:38,240
remember like when you're designing an

1827
01:21:36,079 --> 01:21:40,609
architecture that when you start the

1828
01:21:38,239 --> 01:21:42,889
model knows nothing about anything right

1829
01:21:40,609 --> 01:21:43,579
so you kind of want to make sure it's

1830
01:21:42,890 --> 01:21:46,039
doing

1831
01:21:43,579 --> 01:21:49,909
something at least vaguely sensible okay

1832
01:21:46,039 --> 01:21:53,409
so bi-directional means we had you know

1833
01:21:49,909 --> 01:21:58,220
let's see how we go here we got out to

1834
01:21:53,409 --> 01:22:00,409
358 cross entropy loss okay with a

1835
01:21:58,220 --> 01:22:03,619
single direction with fire direction

1836
01:22:00,409 --> 01:22:05,569
gets down to 351 yeah so that improved

1837
01:22:03,619 --> 01:22:09,019
it a bit that's good and as I say the

1838
01:22:05,569 --> 01:22:11,539
only you know it shouldn't really slow

1839
01:22:09,020 --> 01:22:14,600
things down too much

1840
01:22:11,539 --> 01:22:16,130
you know bidirectional does mean there's

1841
01:22:14,600 --> 01:22:18,710
a little bit more sequential processing

1842
01:22:16,130 --> 01:22:21,260
have to happen but you know it's

1843
01:22:18,710 --> 01:22:24,170
generally a good win in the Google

1844
01:22:21,260 --> 01:22:26,500
Translation model of the eight layers

1845
01:22:24,170 --> 01:22:28,550
only the first layer is bi-directional

1846
01:22:26,500 --> 01:22:30,770
because it allows it to do more in

1847
01:22:28,550 --> 01:22:32,840
parallel so if you create really deep

1848
01:22:30,770 --> 01:22:34,670
models you may need to think about which

1849
01:22:32,840 --> 01:22:38,500
ones are bi-directional otherwise we

1850
01:22:34,670 --> 01:22:42,800
have performance issues okay and so 351

1851
01:22:38,500 --> 01:22:45,859
now let's talk about teacher for C so

1852
01:22:42,800 --> 01:22:50,810
teacher forcing is I'm going to come

1853
01:22:45,859 --> 01:22:53,089
back to this idea that when the model

1854
01:22:50,810 --> 01:22:55,400
starts learning it knows nothing about

1855
01:22:53,090 --> 01:22:58,060
nothing so when the fertile starts

1856
01:22:55,399 --> 01:23:00,739
learning it is not going to spit out ah

1857
01:22:58,060 --> 01:23:04,190
at this point it's going to spit out

1858
01:23:00,739 --> 01:23:05,630
some random meaningless work acts it

1859
01:23:04,189 --> 01:23:06,859
doesn't know anything about German or

1860
01:23:05,630 --> 01:23:08,480
about English or about the idea of

1861
01:23:06,859 --> 01:23:10,279
language or anything and then it's going

1862
01:23:08,479 --> 01:23:12,739
to feed it down here as an input and be

1863
01:23:10,279 --> 01:23:15,170
totally unhelpful yeah and so that means

1864
01:23:12,739 --> 01:23:17,179
that early learning is going to be very

1865
01:23:15,170 --> 01:23:19,550
very difficult because it's feeding in

1866
01:23:17,180 --> 01:23:21,560
an input that's stupid into a model that

1867
01:23:19,550 --> 01:23:24,710
knows nothing and somehow it says get

1868
01:23:21,560 --> 01:23:27,200
better right so that's it's not asking

1869
01:23:24,710 --> 01:23:29,390
too much eventually it gets there but

1870
01:23:27,199 --> 01:23:37,399
it's definitely not as helpful as we can

1871
01:23:29,390 --> 01:23:40,340
be so what if instead of feeding in what

1872
01:23:37,399 --> 01:23:43,729
if instead of feeding in the thing I

1873
01:23:40,340 --> 01:23:47,150
predicted just now right what if instead

1874
01:23:43,729 --> 01:23:51,049
we see it in the actual correct word it

1875
01:23:47,149 --> 01:23:52,909
was meant to be right now we can't do

1876
01:23:51,050 --> 01:23:54,230
that at inference time because by

1877
01:23:52,909 --> 01:23:57,029
definition we don't know the correct

1878
01:23:54,229 --> 01:23:58,979
word it has to translate it

1879
01:23:57,029 --> 01:24:02,069
we can't require the correct translation

1880
01:23:58,979 --> 01:24:04,439
in order to do translation right so the

1881
01:24:02,069 --> 01:24:07,229
way I've set this up is I've got this

1882
01:24:04,439 --> 01:24:09,869
thing called PR force which is

1883
01:24:07,229 --> 01:24:11,819
probability of forcing and if some

1884
01:24:09,869 --> 01:24:15,149
random number is less than that

1885
01:24:11,819 --> 01:24:18,569
probability then I'm going to replace my

1886
01:24:15,149 --> 01:24:21,329
decoder input with the actual correct

1887
01:24:18,569 --> 01:24:23,549
thing right and if we've already gone

1888
01:24:21,329 --> 01:24:24,809
too far and if it's already longer than

1889
01:24:23,550 --> 01:24:26,670
the target sentence I'm just going to

1890
01:24:24,810 --> 01:24:29,490
stop well obviously I can't give it the

1891
01:24:26,670 --> 01:24:31,890
correct thing so you can see how

1892
01:24:29,489 --> 01:24:33,630
beautiful pi torches for this right

1893
01:24:31,890 --> 01:24:36,119
because like if you try to do this with

1894
01:24:33,630 --> 01:24:37,310
some static grafting like like classic

1895
01:24:36,119 --> 01:24:41,069
tensorflow

1896
01:24:37,310 --> 01:24:43,320
well I tried right like one of the key

1897
01:24:41,069 --> 01:24:45,389
reasons that we switched to PI torch at

1898
01:24:43,319 --> 01:24:47,729
this exact point in last year's class

1899
01:24:45,390 --> 01:24:49,470
was because Jeremy tried to implement it

1900
01:24:47,729 --> 01:24:52,019
you're forcing in chaos intensive flow

1901
01:24:49,470 --> 01:24:55,079
and went even more insane and he started

1902
01:24:52,020 --> 01:24:59,520
right and I was like it was weeks of

1903
01:24:55,079 --> 01:25:02,340
getting nowhere and then I literally on

1904
01:24:59,520 --> 01:25:05,760
Twitter I think it was Andre capaci

1905
01:25:02,340 --> 01:25:07,020
eyesore announced say it's something

1906
01:25:05,760 --> 01:25:08,550
about oh there's this thing called PI

1907
01:25:07,020 --> 01:25:12,450
torch just came out and it's really cool

1908
01:25:08,550 --> 01:25:15,150
and I've tried it that day by the next

1909
01:25:12,449 --> 01:25:17,550
day I had teacher flossing would and so

1910
01:25:15,149 --> 01:25:19,589
like I was like oh my gosh you know and

1911
01:25:17,550 --> 01:25:21,390
like all the stuff of trying to debug

1912
01:25:19,590 --> 01:25:23,310
things it was suddenly so much easier

1913
01:25:21,390 --> 01:25:24,930
and this kind of you know dynamic stuff

1914
01:25:23,310 --> 01:25:27,600
is so much easier so this is a great

1915
01:25:24,930 --> 01:25:30,030
example of like hey I get to use random

1916
01:25:27,600 --> 01:25:34,110
numbers and if statements and stuff so

1917
01:25:30,029 --> 01:25:36,989
yeah so here's the basic idea is at the

1918
01:25:34,109 --> 01:25:40,799
start of training let's set P our force

1919
01:25:36,989 --> 01:25:44,099
really high right so that nearly always

1920
01:25:40,800 --> 01:25:46,500
that gets the actual correct you know

1921
01:25:44,100 --> 01:25:48,660
previous word and so it has a useful

1922
01:25:46,500 --> 01:25:52,920
input right and then as I train a bit

1923
01:25:48,659 --> 01:25:56,010
more let's decrease PR force so that by

1924
01:25:52,920 --> 01:25:58,829
the end PF force is zero and it has to

1925
01:25:56,010 --> 01:26:00,690
learn properly which is fine because

1926
01:25:58,829 --> 01:26:04,170
it's now actually feeding in sensible

1927
01:26:00,689 --> 01:26:07,129
inputs most of the time anyway so let's

1928
01:26:04,170 --> 01:26:11,500
now write something such that in the

1929
01:26:07,130 --> 01:26:15,010
training loop it gradually decreases

1930
01:26:11,500 --> 01:26:16,420
pyaare force so how do you do that well

1931
01:26:15,010 --> 01:26:19,960
one approach would be to write our own

1932
01:26:16,420 --> 01:26:21,399
training loop okay but let's not do that

1933
01:26:19,960 --> 01:26:24,220
because we already have a training loop

1934
01:26:21,399 --> 01:26:25,899
that has progress bars and uses

1935
01:26:24,220 --> 01:26:27,550
exponential weighted averages to smooth

1936
01:26:25,899 --> 01:26:29,319
out the losses and keeps track of

1937
01:26:27,550 --> 01:26:31,570
metrics and you know it does a bunch of

1938
01:26:29,319 --> 01:26:33,639
things which they're not rocket science

1939
01:26:31,569 --> 01:26:35,019
but they're kind of convenient and they

1940
01:26:33,640 --> 01:26:37,750
also kind of keep track of you know

1941
01:26:35,020 --> 01:26:39,100
calling the reset hour and ends at the

1942
01:26:37,750 --> 01:26:41,170
start of an epoch to make sure that the

1943
01:26:39,100 --> 01:26:43,510
hidden states set to zeros and you know

1944
01:26:41,170 --> 01:26:47,230
little things like that we'd rather not

1945
01:26:43,510 --> 01:26:50,470
have to write that in scratch so what

1946
01:26:47,229 --> 01:26:53,229
we've tended to find is that as I start

1947
01:26:50,470 --> 01:26:56,980
to kind of write some new thing and I'm

1948
01:26:53,229 --> 01:26:58,719
like oh I need to kind of replace some

1949
01:26:56,979 --> 01:27:01,449
part of the code I then kind of add some

1950
01:26:58,720 --> 01:27:04,090
little hook so that we can all use that

1951
01:27:01,449 --> 01:27:06,159
book to make things easier in this

1952
01:27:04,090 --> 01:27:08,289
particular case there's a book that I've

1953
01:27:06,159 --> 01:27:11,279
ended up using all the damn time now

1954
01:27:08,289 --> 01:27:18,069
which is the hook called the stepper and

1955
01:27:11,279 --> 01:27:21,039
so if you look at our code model dot pi

1956
01:27:18,069 --> 01:27:23,769
is where our fit function lives right

1957
01:27:21,039 --> 01:27:25,840
and so the fit function and model dot pi

1958
01:27:23,770 --> 01:27:27,850
is kind of we've seen it before I think

1959
01:27:25,840 --> 01:27:30,130
it's like the lowest level thing that

1960
01:27:27,850 --> 01:27:31,539
doesn't require and learner it doesn't

1961
01:27:30,130 --> 01:27:34,449
really require anything much at all this

1962
01:27:31,539 --> 01:27:36,189
requires a standard PI torch model and a

1963
01:27:34,449 --> 01:27:38,380
model data object you just need to know

1964
01:27:36,189 --> 01:27:40,299
how many epochs are standard pipe torch

1965
01:27:38,380 --> 01:27:42,789
optimizer and the standard page watch

1966
01:27:40,300 --> 01:27:44,650
boss function all right so you can call

1967
01:27:42,789 --> 01:27:46,630
I don't we've hardly ever used it in the

1968
01:27:44,649 --> 01:27:48,639
class we normally call learn but fit but

1969
01:27:46,630 --> 01:27:50,710
learn dot fit calls this so this is our

1970
01:27:48,640 --> 01:27:51,970
lowest level thing but we filtered the

1971
01:27:50,710 --> 01:27:55,060
source code here sometimes we've seen

1972
01:27:51,970 --> 01:27:56,680
how it loops through each epoch and that

1973
01:27:55,060 --> 01:28:01,780
lives through each thing in our batch

1974
01:27:56,680 --> 01:28:03,130
and calls step or dot step right and so

1975
01:28:01,779 --> 01:28:05,229
step or dot step is the thing that's

1976
01:28:03,130 --> 01:28:06,940
responsible for calling the model

1977
01:28:05,229 --> 01:28:09,269
getting the last finding the last

1978
01:28:06,939 --> 01:28:13,689
function and calling the optimizer and

1979
01:28:09,270 --> 01:28:17,190
so by default step or dot step uses a

1980
01:28:13,689 --> 01:28:18,939
particular class called stepper which

1981
01:28:17,189 --> 01:28:21,729
there's a few things you don't know

1982
01:28:18,939 --> 01:28:25,239
where basically it calls the model all

1983
01:28:21,729 --> 01:28:28,029
right so the model winds up inside M

1984
01:28:25,239 --> 01:28:33,159
Zero's the gradients cause the loss

1985
01:28:28,029 --> 01:28:35,170
function calls backwards does gradient

1986
01:28:33,159 --> 01:28:39,309
flipping if necessary and then calls the

1987
01:28:35,170 --> 01:28:41,230
optimizer alright so you know they're

1988
01:28:39,310 --> 01:28:43,600
the basic steps that back when we looked

1989
01:28:41,229 --> 01:28:47,049
at kind of pi torch from scratch we had

1990
01:28:43,600 --> 01:28:52,210
to do so the nice thing is we can

1991
01:28:47,050 --> 01:28:53,980
replace that with something else rather

1992
01:28:52,210 --> 01:28:58,000
than replacing the training loop right

1993
01:28:53,979 --> 01:29:00,939
so if you inherit from step up and then

1994
01:28:58,000 --> 01:29:02,739
write your own version of step right you

1995
01:29:00,939 --> 01:29:05,979
can just copy and paste the contents of

1996
01:29:02,739 --> 01:29:07,689
step and add whatever you like right or

1997
01:29:05,979 --> 01:29:09,669
if it's something that you're going to

1998
01:29:07,689 --> 01:29:13,479
do before or afterwards your could even

1999
01:29:09,670 --> 01:29:15,100
call super dot step in this case I

2000
01:29:13,479 --> 01:29:18,250
rather suspect

2001
01:29:15,100 --> 01:29:21,310
I've been unnecessarily complicated here

2002
01:29:18,250 --> 01:29:23,800
I probably could have replaced commented

2003
01:29:21,310 --> 01:29:28,560
about all of that and just said super

2004
01:29:23,800 --> 01:29:31,180
darts DEP X's comma Y comma epoch

2005
01:29:28,560 --> 01:29:33,820
because I think this is an exact copy of

2006
01:29:31,180 --> 01:29:35,200
everything right but you know as I say

2007
01:29:33,819 --> 01:29:37,479
when I'm prototyping I don't think

2008
01:29:35,199 --> 01:29:39,609
carefully about how to minimize my code

2009
01:29:37,479 --> 01:29:42,129
I copied and pasted the contents of the

2010
01:29:39,609 --> 01:29:47,409
code from step and I added a single line

2011
01:29:42,130 --> 01:29:51,640
to the top which was to replace PR force

2012
01:29:47,409 --> 01:29:54,849
in my module with something that

2013
01:29:51,640 --> 01:29:58,300
gradually decreased linearly for the

2014
01:29:54,850 --> 01:30:03,130
first 10 a box and after 10 B box it was

2015
01:29:58,300 --> 01:30:05,710
zero okay so total hack but good enough

2016
01:30:03,130 --> 01:30:08,770
to try it out and so the nice thing what

2017
01:30:05,710 --> 01:30:10,659
is that I can now you know everything

2018
01:30:08,770 --> 01:30:12,730
else is the same

2019
01:30:10,659 --> 01:30:18,279
I've replaced I've added these three

2020
01:30:12,729 --> 01:30:19,329
lines of code to my module and the only

2021
01:30:18,279 --> 01:30:21,639
thing I need to do other that's

2022
01:30:19,329 --> 01:30:26,859
differently is when I call fit is I pass

2023
01:30:21,640 --> 01:30:28,119
in my customized step a class okay and

2024
01:30:26,859 --> 01:30:32,829
so that's going to do teacher forcing

2025
01:30:28,119 --> 01:30:34,210
and so we don't have bi-directional so

2026
01:30:32,829 --> 01:30:36,159
we're just changing one thing at a time

2027
01:30:34,210 --> 01:30:38,208
so we should compare this to our

2028
01:30:36,159 --> 01:30:42,788
unidirectional results

2029
01:30:38,208 --> 01:30:45,319
which was three point five eight and

2030
01:30:42,788 --> 01:30:50,118
this is three point four nine okay so

2031
01:30:45,319 --> 01:30:51,590
that was an improvement so that's great

2032
01:30:50,118 --> 01:30:53,359
needed to make sure at least two ten

2033
01:30:51,590 --> 01:30:56,409
epochs because before that it was

2034
01:30:53,359 --> 01:30:58,130
cheating by using the teacher forcing so

2035
01:30:56,408 --> 01:31:01,458
yeah okay

2036
01:30:58,130 --> 01:31:05,029
so that's good that's an improvement so

2037
01:31:01,458 --> 01:31:07,578
we've got another trick and this next

2038
01:31:05,029 --> 01:31:10,670
trick is a it's a bigger trick it's a

2039
01:31:07,578 --> 01:31:13,908
it's a pretty cool trick and it's it's

2040
01:31:10,670 --> 01:31:23,149
called attention and the basic idea of

2041
01:31:13,908 --> 01:31:26,149
attention is this which is expecting the

2042
01:31:23,149 --> 01:31:29,509
entirety of the sentence to be

2043
01:31:26,149 --> 01:31:32,569
summarized into this single hidden

2044
01:31:29,510 --> 01:31:35,689
vector is asking a lot you know it has

2045
01:31:32,569 --> 01:31:37,998
to know what was said and how it was

2046
01:31:35,689 --> 01:31:41,780
said and everything necessary to create

2047
01:31:37,998 --> 01:31:43,340
the sentence in general and so the idea

2048
01:31:41,779 --> 01:31:45,889
of attention is basically like maybe

2049
01:31:43,340 --> 01:31:53,029
we're asking too much all right

2050
01:31:45,889 --> 01:31:55,819
particularly because we could use this

2051
01:31:53,029 --> 01:31:57,738
form of model where we output every step

2052
01:31:55,819 --> 01:31:59,899
of the loop to not just have a hidden

2053
01:31:57,738 --> 01:32:03,458
state at the end but to hit a hidden

2054
01:31:59,899 --> 01:32:06,348
state after every single word and like

2055
01:32:03,458 --> 01:32:09,559
why not try and use that information

2056
01:32:06,349 --> 01:32:12,828
it's it's like it's already there but so

2057
01:32:09,559 --> 01:32:15,380
far we've just been throwing it away and

2058
01:32:12,828 --> 01:32:20,630
not only that but by directional we've

2059
01:32:15,380 --> 01:32:24,590
got every step we've got to you know

2060
01:32:20,630 --> 01:32:27,498
vectors of state that we can use so how

2061
01:32:24,590 --> 01:32:28,849
could we use this piece of state this

2062
01:32:27,498 --> 01:32:30,288
piece of state this piece of state this

2063
01:32:28,849 --> 01:32:34,189
piece of state and this piece of state

2064
01:32:30,288 --> 01:32:36,559
rather than just the final state and so

2065
01:32:34,189 --> 01:32:40,189
the basic idea is well let's say I'm

2066
01:32:36,559 --> 01:32:43,279
doing this word translating this word

2067
01:32:40,189 --> 01:32:46,760
right now which of these five pieces of

2068
01:32:43,279 --> 01:32:50,899
state do I want and of course the answer

2069
01:32:46,760 --> 01:32:52,010
is if I'm doing well actually that's

2070
01:32:50,899 --> 01:32:54,368
bigger more interesting would

2071
01:32:52,010 --> 01:32:57,500
pick this one so if I'm trying to do

2072
01:32:54,368 --> 01:33:00,109
loved then clearly the hidden state I

2073
01:32:57,500 --> 01:33:04,219
want is this one right because this is

2074
01:33:00,109 --> 01:33:06,078
the word okay and then for for this

2075
01:33:04,219 --> 01:33:08,960
preposition of little preposition

2076
01:33:06,078 --> 01:33:10,819
whatever this little word here no it's

2077
01:33:08,960 --> 01:33:13,069
not a preposition I guess it's part of

2078
01:33:10,819 --> 01:33:16,158
the boat so for this part of the verb I

2079
01:33:13,069 --> 01:33:18,170
probably would need like this and this

2080
01:33:16,158 --> 01:33:19,819
and this to kind of make sure that I've

2081
01:33:18,170 --> 01:33:21,559
got kind of the tense right and know

2082
01:33:19,819 --> 01:33:24,590
that I actually need this part of the

2083
01:33:21,559 --> 01:33:27,500
verb and so forth so depending on which

2084
01:33:24,590 --> 01:33:32,210
bit I'm translating I'm going to need

2085
01:33:27,500 --> 01:33:34,609
one or more bits of this of these

2086
01:33:32,210 --> 01:33:37,399
various hidden States and in fact you

2087
01:33:34,609 --> 01:33:40,130
know like I probably want some weighting

2088
01:33:37,399 --> 01:33:42,679
of them so like what I'm doing here I

2089
01:33:40,130 --> 01:33:44,989
probably mainly want this state right

2090
01:33:42,679 --> 01:33:47,960
but I maybe run a little bit of that one

2091
01:33:44,988 --> 01:33:50,178
and a little bit of that one right so in

2092
01:33:47,960 --> 01:33:53,050
other words for these five pieces of

2093
01:33:50,179 --> 01:33:58,010
hidden state we want to wait an average

2094
01:33:53,050 --> 01:34:00,230
right and we wanted waited by something

2095
01:33:58,010 --> 01:34:03,110
that can figure out which bits of the

2096
01:34:00,229 --> 01:34:06,288
sentence the most important right now so

2097
01:34:03,109 --> 01:34:07,729
how do we figure out something like

2098
01:34:06,288 --> 01:34:10,189
which bits are the symptoms are

2099
01:34:07,729 --> 01:34:12,500
important right now we created a neural

2100
01:34:10,189 --> 01:34:14,629
net and we train the neural net to

2101
01:34:12,500 --> 01:34:17,059
figure it out

2102
01:34:14,630 --> 01:34:18,489
when do we train that you're on it and

2103
01:34:17,059 --> 01:34:21,829
to end

2104
01:34:18,488 --> 01:34:22,939
so let's now train to neural nets well

2105
01:34:21,828 --> 01:34:24,380
we've actually already kinda got a bunch

2106
01:34:22,939 --> 01:34:26,719
right we've got an hour and an encoder

2107
01:34:24,380 --> 01:34:29,719
we got an RNN decoder we've got a couple

2108
01:34:26,719 --> 01:34:32,538
of linear layers what the hell let's add

2109
01:34:29,719 --> 01:34:34,578
another neural net into the mix okay and

2110
01:34:32,538 --> 01:34:38,569
this neural net is going to spit out a

2111
01:34:34,578 --> 01:34:39,948
wait for every one of these things and

2112
01:34:38,569 --> 01:34:42,109
we got to take the weighted average at

2113
01:34:39,948 --> 01:34:45,138
every step and it's just another set of

2114
01:34:42,109 --> 01:34:49,210
parameters that we learn all at the same

2115
01:34:45,139 --> 01:34:52,130
time okay and so that's called attention

2116
01:34:49,210 --> 01:34:55,149
so the idea is that once that attentions

2117
01:34:52,130 --> 01:34:58,219
been learned we can see this terrific

2118
01:34:55,149 --> 01:35:00,500
demo from Chris Olerud roncada each

2119
01:34:58,219 --> 01:35:01,880
different word is going to take a

2120
01:35:00,500 --> 01:35:03,500
weighted average see how they're

2121
01:35:01,880 --> 01:35:05,390
weighted the weights are different

2122
01:35:03,500 --> 01:35:07,670
depending on which word is being

2123
01:35:05,390 --> 01:35:09,380
later all right and you can see how it's

2124
01:35:07,670 --> 01:35:10,880
kind of figuring out the color the

2125
01:35:09,380 --> 01:35:13,310
deepness of the blue is how much weight

2126
01:35:10,880 --> 01:35:15,050
it's using you can see that each word is

2127
01:35:13,310 --> 01:35:16,940
basically or here at which word are we

2128
01:35:15,050 --> 01:35:18,770
transferring from so when we say

2129
01:35:16,939 --> 01:35:20,419
European we need to know that both of

2130
01:35:18,770 --> 01:35:22,370
these two parts you only influenced

2131
01:35:20,420 --> 01:35:24,380
ordering economic both these three parts

2132
01:35:22,369 --> 01:35:26,899
are very influenced including the gender

2133
01:35:24,380 --> 01:35:32,060
of the the definite article and so forth

2134
01:35:26,899 --> 01:35:34,309
right so check out this distill the pub

2135
01:35:32,060 --> 01:35:37,930
article are these things are all like

2136
01:35:34,310 --> 01:35:41,840
little Hospital interactive diagrams

2137
01:35:37,930 --> 01:35:43,490
basically shows you how weights how

2138
01:35:41,840 --> 01:35:44,829
attention works and what the actual

2139
01:35:43,489 --> 01:35:48,859
attention looks like and a trained

2140
01:35:44,829 --> 01:35:55,449
translation model okay so let's try and

2141
01:35:48,859 --> 01:35:59,259
implement attention so with attention

2142
01:35:55,449 --> 01:36:08,079
it's basically this is all identical

2143
01:35:59,260 --> 01:36:10,610
right and the encoder is identical and

2144
01:36:08,079 --> 01:36:14,539
all of this bit of the decoder is

2145
01:36:10,609 --> 01:36:24,679
identical there's one difference which

2146
01:36:14,539 --> 01:36:28,659
is that we see where this happens here

2147
01:36:24,680 --> 01:36:31,610
we go we basically are going to take a

2148
01:36:28,659 --> 01:36:33,649
weighted average and the way that we're

2149
01:36:31,609 --> 01:36:35,630
going to do the weighted average is we

2150
01:36:33,649 --> 01:36:38,750
create a little neural net which we're

2151
01:36:35,630 --> 01:36:41,810
going to see here and here and then we

2152
01:36:38,750 --> 01:36:44,260
use softmax because of course the last

2153
01:36:41,810 --> 01:36:47,360
thing about softmax is that we want to

2154
01:36:44,260 --> 01:36:50,750
ensure that all of the weights that

2155
01:36:47,359 --> 01:36:52,639
we're using add up to 1 and we also kind

2156
01:36:50,750 --> 01:36:54,500
of expect that one of those weights

2157
01:36:52,640 --> 01:36:56,660
should probably be quite a bit higher

2158
01:36:54,500 --> 01:37:00,260
than the other ones right and so soft

2159
01:36:56,659 --> 01:37:03,470
mattes gives us the guarantee that they

2160
01:37:00,260 --> 01:37:06,380
add up to 1 and because it's that aid of

2161
01:37:03,470 --> 01:37:08,090
that unit it tends to encourage one of

2162
01:37:06,380 --> 01:37:10,190
the weights to be higher than the other

2163
01:37:08,090 --> 01:37:13,579
ones all right so let's see how this

2164
01:37:10,189 --> 01:37:18,169
works so what's going to happen is we're

2165
01:37:13,579 --> 01:37:19,850
going to take the last layers hidden

2166
01:37:18,170 --> 01:37:21,730
state

2167
01:37:19,850 --> 01:37:24,470
and we're going to stick it into a

2168
01:37:21,729 --> 01:37:28,039
linearlayout and then we're going to

2169
01:37:24,470 --> 01:37:33,050
stick it into a nonlinear activation and

2170
01:37:28,039 --> 01:37:36,140
then we're going to do matrix multiply

2171
01:37:33,050 --> 01:37:38,720
and so if you think about it linear

2172
01:37:36,140 --> 01:37:42,140
layer nonlinear activation matrix

2173
01:37:38,720 --> 01:37:45,140
multiply that's a neural net it's a

2174
01:37:42,140 --> 01:37:48,440
neural net with one hidden layer okay

2175
01:37:45,140 --> 01:37:54,680
stick it into a softmax okay and then we

2176
01:37:48,439 --> 01:37:58,339
can use that to weight our air encoder

2177
01:37:54,680 --> 01:38:01,340
outputs okay so now rather than just

2178
01:37:58,340 --> 01:38:04,159
taking the last encoder output we've got

2179
01:38:01,340 --> 01:38:07,039
this is going to be the whole tensor of

2180
01:38:04,159 --> 01:38:09,199
all of the encoder outputs which I just

2181
01:38:07,039 --> 01:38:13,350
weight by this little neural net that I

2182
01:38:09,199 --> 01:38:16,149
created and that's basically it right so

2183
01:38:13,350 --> 01:38:20,329
[Music]

2184
01:38:16,149 --> 01:38:25,399
okay so what I'll do is I'll put on the

2185
01:38:20,329 --> 01:38:29,210
wiki thread couple of papers to check

2186
01:38:25,399 --> 01:38:31,939
out there was there was basically one

2187
01:38:29,210 --> 01:38:35,270
amazing paper that really originally

2188
01:38:31,939 --> 01:38:36,169
introduced this idea of attention and I

2189
01:38:35,270 --> 01:38:39,230
say amazing because it actually

2190
01:38:36,170 --> 01:38:42,470
introduced a couple of key things which

2191
01:38:39,229 --> 01:38:44,959
have really changed how people work in

2192
01:38:42,470 --> 01:38:49,909
this field they say area of attention

2193
01:38:44,960 --> 01:38:53,630
has been used not just for text but for

2194
01:38:49,909 --> 01:38:55,789
you know things like reading text out of

2195
01:38:53,630 --> 01:38:58,909
pictures or kind of doing various stuff

2196
01:38:55,789 --> 01:39:02,180
with computer vision and stuff like that

2197
01:38:58,909 --> 01:39:03,859
and then there's a second paper which

2198
01:39:02,180 --> 01:39:06,079
actually Geoffrey Hinton was involved in

2199
01:39:03,859 --> 01:39:08,630
called grammar as a foreign language

2200
01:39:06,079 --> 01:39:11,319
which used this idea of Iranians with

2201
01:39:08,630 --> 01:39:14,930
attention to basically try to replace

2202
01:39:11,319 --> 01:39:18,979
rules based grammar with an R and n

2203
01:39:14,930 --> 01:39:22,520
which automatically basically tagged the

2204
01:39:18,979 --> 01:39:24,139
grammatical you know each word based on

2205
01:39:22,520 --> 01:39:26,390
this grammar and turned out to do it

2206
01:39:24,140 --> 01:39:29,000
better than any rules based system which

2207
01:39:26,390 --> 01:39:30,500
today like actually kind of seems

2208
01:39:29,000 --> 01:39:31,500
obvious I think we're now used to the

2209
01:39:30,500 --> 01:39:34,920
idea that

2210
01:39:31,500 --> 01:39:36,869
neural nets do lots of this stuff better

2211
01:39:34,920 --> 01:39:38,789
than rules-based systems but at the time

2212
01:39:36,869 --> 01:39:41,010
I was considered really surprising

2213
01:39:38,789 --> 01:39:43,229
anyway one nice thing is that they're

2214
01:39:41,010 --> 01:39:47,130
kind of summary of how attention works

2215
01:39:43,229 --> 01:39:51,419
is really nice and concise you know can

2216
01:39:47,130 --> 01:39:59,270
you please explain a thing again sure

2217
01:39:51,420 --> 01:40:03,029
so here's the idea I like that nice

2218
01:39:59,270 --> 01:40:08,430
crisp request that's very easy to

2219
01:40:03,029 --> 01:40:12,779
understand okay let's go back and look

2220
01:40:08,430 --> 01:40:16,950
at our original encoder so an eridan

2221
01:40:12,779 --> 01:40:21,389
spits out two things it spits out a list

2222
01:40:16,949 --> 01:40:24,000
of the the state after every time step

2223
01:40:21,390 --> 01:40:27,420
and it also tells you the state at the

2224
01:40:24,000 --> 01:40:30,869
last time step and we used the state at

2225
01:40:27,420 --> 01:40:40,170
the last time step to create the input

2226
01:40:30,869 --> 01:40:46,890
state for our decoder okay which is what

2227
01:40:40,170 --> 01:40:48,359
we see you won but we know that it's

2228
01:40:46,890 --> 01:40:51,300
actually creating a vector at every time

2229
01:40:48,359 --> 01:40:54,329
step so wouldn't it be nice to use them

2230
01:40:51,300 --> 01:40:57,900
all right but wouldn't it be likes to

2231
01:40:54,329 --> 01:41:00,059
use the one or ones that's most relevant

2232
01:40:57,899 --> 01:41:03,750
to translating the word I'm translating

2233
01:41:00,060 --> 01:41:06,180
now so wouldn't it be nice to be able to

2234
01:41:03,750 --> 01:41:09,050
take a weighted average of the hidden

2235
01:41:06,180 --> 01:41:11,789
state at each time step weight it by

2236
01:41:09,050 --> 01:41:13,760
whatever is the appropriate weight right

2237
01:41:11,789 --> 01:41:16,920
now which for example in this case

2238
01:41:13,760 --> 01:41:18,510
litter would definitely be time step

2239
01:41:16,920 --> 01:41:20,779
number two here's what it's all about

2240
01:41:18,510 --> 01:41:27,360
because that's the word I'm translating

2241
01:41:20,779 --> 01:41:29,849
so how do we get how do we get a list of

2242
01:41:27,359 --> 01:41:32,219
weights that is suitable for the word

2243
01:41:29,850 --> 01:41:34,740
we're training right now well the answer

2244
01:41:32,220 --> 01:41:37,650
is by training a neural net to figure

2245
01:41:34,739 --> 01:41:40,289
out the list of weights and so anytime

2246
01:41:37,649 --> 01:41:42,289
we want to figure out how to train a

2247
01:41:40,289 --> 01:41:45,079
little neuron that that does and

2248
01:41:42,289 --> 01:41:48,409
tasks the easiest way normally always to

2249
01:41:45,079 --> 01:41:50,239
do that is to include it in your module

2250
01:41:48,409 --> 01:41:56,949
and train it in line with everything

2251
01:41:50,239 --> 01:42:02,289
else the minimal possible neural net is

2252
01:41:56,949 --> 01:42:09,769
something that contains two layers and

2253
01:42:02,289 --> 01:42:18,439
one nonlinear activation function so

2254
01:42:09,770 --> 01:42:20,630
here is one linear layer okay and in

2255
01:42:18,439 --> 01:42:26,869
fact you know instead of a linear layer

2256
01:42:20,630 --> 01:42:29,600
we can even just grab a random matrix if

2257
01:42:26,869 --> 01:42:32,500
we don't care about bias right and so

2258
01:42:29,600 --> 01:42:35,600
here's a random matrix it's just a

2259
01:42:32,500 --> 01:42:39,500
random tensor wrapped up in a parameter

2260
01:42:35,600 --> 01:42:41,750
a parameter remember is a is just a PI

2261
01:42:39,500 --> 01:42:44,060
torch variable it's like identical to a

2262
01:42:41,750 --> 01:42:46,220
variable that it just tells PI torch I

2263
01:42:44,060 --> 01:42:49,789
want you to learn the weights for this

2264
01:42:46,220 --> 01:42:54,650
place alright so here we've got a linear

2265
01:42:49,789 --> 01:42:57,710
layer here we've got a random matrix and

2266
01:42:54,649 --> 01:43:04,009
so here at this point where we start out

2267
01:42:57,710 --> 01:43:07,220
our decoder let's take that final let's

2268
01:43:04,010 --> 01:43:11,000
take the current hidden state of the

2269
01:43:07,220 --> 01:43:14,000
tked of the decoder right put that into

2270
01:43:11,000 --> 01:43:17,140
a linear layer right because like how

2271
01:43:14,000 --> 01:43:20,420
what's the information we use to decide

2272
01:43:17,140 --> 01:43:21,920
what words we should focus on next well

2273
01:43:20,420 --> 01:43:23,989
we the only information we have to go on

2274
01:43:21,920 --> 01:43:26,899
is what the decoders hidden state is now

2275
01:43:23,989 --> 01:43:30,300
all right so let's grab that put it into

2276
01:43:26,899 --> 01:43:31,779
the linear layer put it through a

2277
01:43:30,300 --> 01:43:35,440
[Music]

2278
01:43:31,779 --> 01:43:37,460
non-linearity put it through one more

2279
01:43:35,439 --> 01:43:38,839
nonlinear layer this one actually

2280
01:43:37,460 --> 01:43:41,539
doesn't have a bias in it so it's

2281
01:43:38,840 --> 01:43:44,239
actually just a matrix multiply put that

2282
01:43:41,539 --> 01:43:49,220
into a soft Max and that's it right

2283
01:43:44,239 --> 01:43:51,920
that's a little neural net it doesn't do

2284
01:43:49,220 --> 01:43:53,900
anything we could it's just a neuron

2285
01:43:51,920 --> 01:43:55,909
that no neuron it's do anything they're

2286
01:43:53,899 --> 01:43:57,710
just linear layers with nonlinear

2287
01:43:55,909 --> 01:44:02,090
activations with random weights right

2288
01:43:57,710 --> 01:44:04,010
but it starts to do something if we give

2289
01:44:02,090 --> 01:44:06,710
it a job to do right and in this case

2290
01:44:04,010 --> 01:44:11,239
the job we give it to do is to say don't

2291
01:44:06,710 --> 01:44:14,539
just take the final state but now let's

2292
01:44:11,239 --> 01:44:17,979
use all of the encoder states and let's

2293
01:44:14,539 --> 01:44:20,800
take all of them and multiply them by

2294
01:44:17,979 --> 01:44:24,500
the output of that little neuron it

2295
01:44:20,800 --> 01:44:25,820
right and so given that the things in

2296
01:44:24,500 --> 01:44:30,319
this little neural net are learnable

2297
01:44:25,819 --> 01:44:30,829
weights hopefully it's going to learn to

2298
01:44:30,319 --> 01:44:32,689
wait

2299
01:44:30,829 --> 01:44:35,300
those encoder outputs those encoder

2300
01:44:32,689 --> 01:44:37,460
hidden States by something useful all

2301
01:44:35,300 --> 01:44:40,340
right that's all in neural net ever does

2302
01:44:37,460 --> 01:44:43,130
is is we give it some random weights to

2303
01:44:40,340 --> 01:44:46,069
start with and a job to do and hope that

2304
01:44:43,130 --> 01:44:49,279
it learns to do the job and the ants and

2305
01:44:46,069 --> 01:44:50,989
it turns out that it does all right so

2306
01:44:49,279 --> 01:44:53,649
everything else in here is identical to

2307
01:44:50,989 --> 01:44:53,649
what it was before

2308
01:44:54,170 --> 01:45:00,050
we've got teacher forcing it's not

2309
01:44:56,689 --> 01:45:04,639
bi-directional so we can see how this

2310
01:45:00,050 --> 01:45:08,300
goes right you can see actually I am

2311
01:45:04,640 --> 01:45:10,329
oh yes here yeah using bi-directional

2312
01:45:08,300 --> 01:45:15,409
that's are using teacher forcing so

2313
01:45:10,329 --> 01:45:18,170
teacher foreseeing had three point four

2314
01:45:15,409 --> 01:45:19,479
nine and so now we've got nearly exactly

2315
01:45:18,170 --> 01:45:23,060
the same thing but we've got this little

2316
01:45:19,479 --> 01:45:27,319
minimal neural net figuring out what

2317
01:45:23,060 --> 01:45:28,670
weightings to give our inputs oh wow

2318
01:45:27,319 --> 01:45:30,679
now it's now down to three point three

2319
01:45:28,670 --> 01:45:35,329
seven all right remember these things

2320
01:45:30,680 --> 01:45:38,210
are logs right so e ^ this is quite a

2321
01:45:35,329 --> 01:45:41,920
significant change so three point three

2322
01:45:38,210 --> 01:45:41,920
seven let's try it out

2323
01:45:44,380 --> 01:45:51,430
not bad right where are they located

2324
01:45:46,699 --> 01:45:51,429
what are their skills what'd you do

2325
01:45:53,710 --> 01:46:00,949
it's still not perfect why or why not

2326
01:45:58,460 --> 01:46:03,770
but it's quite a few of them are correct

2327
01:46:00,949 --> 01:46:05,899
and again considering that we're asking

2328
01:46:03,770 --> 01:46:08,050
it to learn about the very idea of

2329
01:46:05,899 --> 01:46:09,309
language for two different languages and

2330
01:46:08,050 --> 01:46:12,100
how to translate them between the two

2331
01:46:09,310 --> 01:46:14,020
and grammar and vocabulary and we only

2332
01:46:12,100 --> 01:46:17,590
have 50,000 sentences and a lot of the

2333
01:46:14,020 --> 01:46:20,850
words only appear once I would say this

2334
01:46:17,590 --> 01:46:26,560
is actually pretty amazing

2335
01:46:20,850 --> 01:46:32,220
yes Annette why do we use tongue H you

2336
01:46:26,560 --> 01:46:34,750
still free Lu for attention minute I

2337
01:46:32,220 --> 01:46:37,750
don't quite remember it's been a while

2338
01:46:34,750 --> 01:46:39,390
since I looked at it you should totally

2339
01:46:37,750 --> 01:46:43,300
try using value and see how it goes

2340
01:46:39,390 --> 01:46:47,380
obviously then the key difference is

2341
01:46:43,300 --> 01:46:49,210
that it kind of go in each direction and

2342
01:46:47,380 --> 01:46:53,170
it's as limited both at the top and the

2343
01:46:49,210 --> 01:46:54,850
bottom I know very often like in it like

2344
01:46:53,170 --> 01:46:57,460
for the gates inside our own ends and

2345
01:46:54,850 --> 01:47:00,640
Ellice Tian Xin Jie I use fan often

2346
01:46:57,460 --> 01:47:01,810
works out better but it's been about a

2347
01:47:00,640 --> 01:47:03,369
year since I actually doctored that

2348
01:47:01,810 --> 01:47:06,130
specific question so I look at it during

2349
01:47:03,369 --> 01:47:06,970
the week but the short answer is you

2350
01:47:06,130 --> 01:47:09,039
know you should try a different

2351
01:47:06,970 --> 01:47:10,930
activation function and see if you can

2352
01:47:09,039 --> 01:47:14,350
get a better result be interested to

2353
01:47:10,930 --> 01:47:18,310
hear what you find out so what we can do

2354
01:47:14,350 --> 01:47:21,550
also is we can actually grab the

2355
01:47:18,310 --> 01:47:25,600
attentions out of the model right so I

2356
01:47:21,550 --> 01:47:28,750
actually added this return attention

2357
01:47:25,600 --> 01:47:30,520
equals true here look see here in my

2358
01:47:28,750 --> 01:47:32,289
forward like forward you can put

2359
01:47:30,520 --> 01:47:35,620
anything you like in forward so I added

2360
01:47:32,289 --> 01:47:36,819
a return attention parameter false by

2361
01:47:35,619 --> 01:47:38,649
default because obviously the the

2362
01:47:36,819 --> 01:47:41,380
training loop it doesn't know anything

2363
01:47:38,649 --> 01:47:43,179
about it but then I just had something

2364
01:47:41,380 --> 01:47:46,600
here saying if returned attention then

2365
01:47:43,180 --> 01:47:49,570
stick the attentions on as well right

2366
01:47:46,600 --> 01:47:53,770
and the attentions is simply that value

2367
01:47:49,569 --> 01:47:55,599
a just check it in a list okay so we can

2368
01:47:53,770 --> 01:47:57,700
now call the model with returned

2369
01:47:55,600 --> 01:48:00,360
attention equals true and get back the

2370
01:47:57,699 --> 01:48:02,289
probabilities and the attentions

2371
01:48:00,359 --> 01:48:06,429
betweens as well as printing out these

2372
01:48:02,289 --> 01:48:09,130
here we can draw pictures at each time

2373
01:48:06,430 --> 01:48:10,750
step of the attention and so you can see

2374
01:48:09,130 --> 01:48:13,960
at the start the attentions on the first

2375
01:48:10,750 --> 01:48:18,159
word second word third word a couple of

2376
01:48:13,960 --> 01:48:20,649
different words and this is just for one

2377
01:48:18,159 --> 01:48:21,699
particular sentence right but so you can

2378
01:48:20,649 --> 01:48:25,029
kind of see this is

2379
01:48:21,699 --> 01:48:29,470
equivalent this is like you know when

2380
01:48:25,029 --> 01:48:31,439
you're Chris solar and and and and Sean

2381
01:48:29,470 --> 01:48:33,970
kata you make things that look like this

2382
01:48:31,439 --> 01:48:35,769
when you Jeremy Howard the exact same

2383
01:48:33,970 --> 01:48:38,440
information looks like this but it's the

2384
01:48:35,770 --> 01:48:42,940
same thing okay just pretend that it's

2385
01:48:38,439 --> 01:48:44,679
beautiful bit so you can see basically

2386
01:48:42,939 --> 01:48:47,829
at each different time step we've got a

2387
01:48:44,680 --> 01:48:50,710
different a different attention and it's

2388
01:48:47,829 --> 01:48:54,460
really important when you try to build

2389
01:48:50,710 --> 01:48:56,289
something like this like you don't

2390
01:48:54,460 --> 01:48:58,239
really know if it's not working right

2391
01:48:56,289 --> 01:48:59,979
because if it's not working and you know

2392
01:48:58,239 --> 01:49:03,909
as per usual my first twelve attempts

2393
01:48:59,979 --> 01:49:05,139
that this were broken and and they were

2394
01:49:03,909 --> 01:49:06,579
broken in the sense that it wasn't

2395
01:49:05,140 --> 01:49:08,200
really learning anything useful

2396
01:49:06,579 --> 01:49:09,579
and so therefore was basically giving

2397
01:49:08,199 --> 01:49:12,309
equal attention to everything and

2398
01:49:09,579 --> 01:49:14,380
therefore it wasn't worse it just wasn't

2399
01:49:12,310 --> 01:49:18,910
better whenever it wasn't much better

2400
01:49:14,380 --> 01:49:21,760
and so I'm sure you actually find ways

2401
01:49:18,909 --> 01:49:23,109
to visualize the thing in a way that you

2402
01:49:21,760 --> 01:49:24,369
know what it ought to look like ahead of

2403
01:49:23,109 --> 01:49:25,809
time you don't really know if it's

2404
01:49:24,369 --> 01:49:28,029
working so it's really important that

2405
01:49:25,810 --> 01:49:30,370
you try to find ways to kind of check

2406
01:49:28,029 --> 01:49:35,259
your intermediate steps in your outputs

2407
01:49:30,369 --> 01:49:37,000
yes you know so we won't ask you what is

2408
01:49:35,260 --> 01:49:39,730
the last function for the attention on

2409
01:49:37,000 --> 01:49:41,380
your network no no no loss function to

2410
01:49:39,729 --> 01:49:44,739
determine your network right it's

2411
01:49:41,380 --> 01:49:46,329
trained in to end so it's just like it's

2412
01:49:44,739 --> 01:49:49,329
just sitting here inside out decoder

2413
01:49:46,329 --> 01:49:51,750
look right so the loss function for the

2414
01:49:49,329 --> 01:49:54,640
decoder loop is that this result

2415
01:49:51,750 --> 01:49:57,970
contains it's exactly the same as before

2416
01:49:54,640 --> 01:50:00,400
just the outputs the probabilities of

2417
01:49:57,970 --> 01:50:02,409
the words right so like the loss

2418
01:50:00,399 --> 01:50:06,699
function it's it's the same loss

2419
01:50:02,409 --> 01:50:09,220
function right so so how come the how

2420
01:50:06,699 --> 01:50:12,309
come the little little mini neural nets

2421
01:50:09,220 --> 01:50:15,340
learning something well because in order

2422
01:50:12,310 --> 01:50:18,250
to make the outputs better and better it

2423
01:50:15,340 --> 01:50:19,690
it would be great if it made the weights

2424
01:50:18,250 --> 01:50:22,689
of these little weighted-average better

2425
01:50:19,689 --> 01:50:24,819
and better right so part of creating our

2426
01:50:22,689 --> 01:50:26,769
output is to please do a good job of

2427
01:50:24,819 --> 01:50:28,000
finding a good set of weights and if it

2428
01:50:26,770 --> 01:50:29,440
doesn't do a good job of finding good

2429
01:50:28,000 --> 01:50:32,439
set of weights then the loss function

2430
01:50:29,439 --> 01:50:35,169
won't improve from that bit so like

2431
01:50:32,439 --> 01:50:35,439
end-to-end learning means like you throw

2432
01:50:35,170 --> 01:50:38,920
in

2433
01:50:35,439 --> 01:50:43,329
you know everything that you can into

2434
01:50:38,920 --> 01:50:45,520
one loss function and the gradients of

2435
01:50:43,329 --> 01:50:47,500
these of all the different parameters

2436
01:50:45,520 --> 01:50:49,540
point in a direction that says basically

2437
01:50:47,500 --> 01:50:51,899
hey you know if you had put more weight

2438
01:50:49,539 --> 01:50:54,250
over there it would have been better and

2439
01:50:51,899 --> 01:50:55,569
thanks to the magic of the train rule it

2440
01:50:54,250 --> 01:50:57,520
then no it's like oh well it would have

2441
01:50:55,569 --> 01:50:59,319
put more weight over there if you would

2442
01:50:57,520 --> 01:51:01,750
like change the parameter in this matrix

2443
01:50:59,319 --> 01:51:05,250
multiply a little bit over there all

2444
01:51:01,750 --> 01:51:10,180
right and so that's that's the magic of

2445
01:51:05,250 --> 01:51:15,310
end-to-end learning so it's a very

2446
01:51:10,180 --> 01:51:17,079
understandable question of like how did

2447
01:51:15,310 --> 01:51:19,690
this little mini in your network but

2448
01:51:17,079 --> 01:51:21,760
you've got to realize there's nothing

2449
01:51:19,689 --> 01:51:23,649
particularly about this code that says

2450
01:51:21,760 --> 01:51:25,659
hey this particular bits a separate

2451
01:51:23,649 --> 01:51:27,609
little mini neural network anymore than

2452
01:51:25,659 --> 01:51:28,960
the grooc is a separate little neural

2453
01:51:27,609 --> 01:51:33,029
network or this linear layers is a

2454
01:51:28,960 --> 01:51:37,689
little function like it's all ends up

2455
01:51:33,029 --> 01:51:39,429
pushed into one output which is a bunch

2456
01:51:37,689 --> 01:51:40,839
of probabilities which ends up in one

2457
01:51:39,430 --> 01:51:43,750
lost function that returns a single

2458
01:51:40,840 --> 01:51:46,420
number that says this either was or

2459
01:51:43,750 --> 01:51:49,000
wasn't a good translation right and so

2460
01:51:46,420 --> 01:51:52,210
thanks to the magic of the chain rule we

2461
01:51:49,000 --> 01:51:53,738
then back propagate little updates to

2462
01:51:52,210 --> 01:52:01,230
all the parameters to make them a little

2463
01:51:53,738 --> 01:52:03,639
bit better okay so this is a a big weird

2464
01:52:01,229 --> 01:52:07,359
counterintuitive idea and it's totally

2465
01:52:03,640 --> 01:52:10,869
ok if it's a bit mind-bending right and

2466
01:52:07,359 --> 01:52:14,289
it's the bit where even back to lesson 1

2467
01:52:10,869 --> 01:52:17,619
you know it's like how did this how did

2468
01:52:14,289 --> 01:52:21,399
we make it find dogs versus cats so we

2469
01:52:17,619 --> 01:52:23,559
didn't you know all we did was we said

2470
01:52:21,399 --> 01:52:25,599
this is our data this is our

2471
01:52:23,560 --> 01:52:27,730
architecture this is our loss function

2472
01:52:25,600 --> 01:52:29,650
please back propagate into the weights

2473
01:52:27,729 --> 01:52:31,929
to make them better and after you've

2474
01:52:29,649 --> 01:52:34,149
made them better a while it'll start

2475
01:52:31,930 --> 01:52:36,310
finding cats from dogs right that's just

2476
01:52:34,149 --> 01:52:38,139
in this case we haven't used somebody

2477
01:52:36,310 --> 01:52:40,000
else's like convolutional network

2478
01:52:38,140 --> 01:52:42,400
architecture we have said here's like a

2479
01:52:40,000 --> 01:52:43,840
custom architecture which we hope is

2480
01:52:42,399 --> 01:52:45,909
going to be particularly good at this

2481
01:52:43,840 --> 01:52:48,819
problem right and even without this

2482
01:52:45,909 --> 01:52:49,180
custom architecture it was - ok all

2483
01:52:48,819 --> 01:52:53,109
right

2484
01:52:49,180 --> 01:52:54,789
but then when we kind of made it in a

2485
01:52:53,109 --> 01:52:57,159
way that made more sense short we think

2486
01:52:54,789 --> 01:53:01,510
it ought to do it worked even better but

2487
01:52:57,159 --> 01:53:03,550
at no point did we kind of do anything

2488
01:53:01,510 --> 01:53:05,739
different other than say here's a data

2489
01:53:03,550 --> 01:53:07,750
here's an architecture here's a loss

2490
01:53:05,739 --> 01:53:11,319
function go and find the parameters

2491
01:53:07,750 --> 01:53:20,560
please pay ins and it did it because

2492
01:53:11,319 --> 01:53:23,729
that's what your net to do okay so that

2493
01:53:20,560 --> 01:53:28,950
is sequence the sequence planning and

2494
01:53:23,729 --> 01:53:33,099
you know if you want to encode an image

2495
01:53:28,949 --> 01:53:35,229
into you know using CNN backbone of some

2496
01:53:33,100 --> 01:53:37,510
kind and then pass that into a decoder

2497
01:53:35,229 --> 01:53:41,439
which is like a our an N with attention

2498
01:53:37,510 --> 01:53:43,449
and you make your y-values the actual

2499
01:53:41,439 --> 01:53:45,759
correct caption speech of those images

2500
01:53:43,449 --> 01:53:47,739
you will end up with an image caption

2501
01:53:45,760 --> 01:53:49,180
generator if you do the same thing with

2502
01:53:47,739 --> 01:53:50,800
videos and captions you'll end up with a

2503
01:53:49,180 --> 01:53:54,010
video caption generator if you do the

2504
01:53:50,800 --> 01:53:55,420
same thing with 3d CT scans and

2505
01:53:54,010 --> 01:53:57,579
radiology reports you'll end up with a

2506
01:53:55,420 --> 01:54:00,310
radiology report generator if you do the

2507
01:53:57,579 --> 01:54:03,819
same thing with github issues and you

2508
01:54:00,310 --> 01:54:05,590
know people's chosen summaries of them

2509
01:54:03,819 --> 01:54:08,500
you'll get a github issue summary

2510
01:54:05,590 --> 01:54:13,989
generator which you know it sector sick

2511
01:54:08,500 --> 01:54:19,359
I agree you know they're magical but

2512
01:54:13,989 --> 01:54:21,279
they they work you know and I don't feel

2513
01:54:19,359 --> 01:54:23,619
like people have begun to scratch the

2514
01:54:21,279 --> 01:54:26,529
surface of how to use sector SEC models

2515
01:54:23,619 --> 01:54:28,420
in their own domains so that's like not

2516
01:54:26,529 --> 01:54:29,829
being a github person it would never

2517
01:54:28,420 --> 01:54:31,960
have occurred to me that like oh it

2518
01:54:29,829 --> 01:54:33,489
would be kind of cool to start with some

2519
01:54:31,960 --> 01:54:37,000
you know issue and automatically create

2520
01:54:33,489 --> 01:54:39,699
a summary but now I'm like huh of course

2521
01:54:37,000 --> 01:54:41,199
next time I go to github I want to see a

2522
01:54:39,699 --> 01:54:42,670
summary written there for me I don't

2523
01:54:41,199 --> 01:54:45,340
want to write my own damn commit message

2524
01:54:42,670 --> 01:54:47,800
through that you know why should I write

2525
01:54:45,340 --> 01:54:49,150
my own like summary of the code review

2526
01:54:47,800 --> 01:54:50,409
when I finished adding comments just

2527
01:54:49,149 --> 01:54:52,719
lots of lines it should do that for me

2528
01:54:50,409 --> 01:54:54,729
as well now I'm thinking like Oh github

2529
01:54:52,720 --> 01:54:56,949
so behind it could be doing this stuff

2530
01:54:54,729 --> 01:54:58,959
so what are the things in your industry

2531
01:54:56,949 --> 01:55:00,340
you know that you could like start with

2532
01:54:58,960 --> 01:55:02,380
a sequence in

2533
01:55:00,340 --> 01:55:06,190
generate something from it I can't begin

2534
01:55:02,380 --> 01:55:09,250
to imagine right so again it's kind of

2535
01:55:06,189 --> 01:55:12,699
like it's a fairly new area the tools

2536
01:55:09,250 --> 01:55:14,590
for it are not easy to use they're not

2537
01:55:12,699 --> 01:55:16,479
even built into fast AI yet as you can

2538
01:55:14,590 --> 01:55:20,079
see hopefully there will be you know

2539
01:55:16,479 --> 01:55:22,509
soon and like you know I don't think

2540
01:55:20,079 --> 01:55:27,939
anybody knows what the opportunities are

2541
01:55:22,510 --> 01:55:30,039
okay so I've got good news bad news the

2542
01:55:27,939 --> 01:55:33,519
bad news is we have 20 minutes to cover

2543
01:55:30,039 --> 01:55:38,380
a topic which in last year's course took

2544
01:55:33,520 --> 01:55:40,300
a whole lesson the good news is that

2545
01:55:38,380 --> 01:55:42,340
when I went to rewrite this using fast

2546
01:55:40,300 --> 01:55:46,779
AI Empire torch I ended up with almost

2547
01:55:42,340 --> 01:55:49,050
no code so all of the stuff that made it

2548
01:55:46,779 --> 01:55:51,239
hard last year is basically gone now so

2549
01:55:49,050 --> 01:55:54,340
we're going to do something

2550
01:55:51,239 --> 01:55:57,579
bringing together for the first time our

2551
01:55:54,340 --> 01:55:59,440
two little worlds we focused on text and

2552
01:55:57,579 --> 01:56:02,409
images and we're going to try and bring

2553
01:55:59,439 --> 01:56:06,389
them together and so this idea came up

2554
01:56:02,409 --> 01:56:08,500
really in a paper by this extraordinary

2555
01:56:06,390 --> 01:56:11,770
deep learning practitioner and

2556
01:56:08,500 --> 01:56:16,390
researcher named Andrea Framm and Andrea

2557
01:56:11,770 --> 01:56:20,620
was Google at the time and her basic

2558
01:56:16,390 --> 01:56:24,220
crazy idea was to say like you know

2559
01:56:20,619 --> 01:56:26,170
words can have a distributed

2560
01:56:24,220 --> 01:56:27,940
representation a space which

2561
01:56:26,170 --> 01:56:30,810
particularly at that time was you know

2562
01:56:27,939 --> 01:56:33,969
really was just word vectors right and

2563
01:56:30,810 --> 01:56:35,560
images can be represented in a space I

2564
01:56:33,970 --> 01:56:37,539
mean like in the end if we have like a

2565
01:56:35,560 --> 01:56:41,200
fully connected layer they kind of ended

2566
01:56:37,539 --> 01:56:43,510
up as like a vector representation could

2567
01:56:41,199 --> 01:56:46,599
we merge the two could we either it

2568
01:56:43,510 --> 01:56:49,539
could be somehow encourage the vector

2569
01:56:46,600 --> 01:56:51,310
space that the images end up with be the

2570
01:56:49,539 --> 01:56:54,130
same vector space that the words are in

2571
01:56:51,310 --> 01:56:55,720
and if we could do that what would that

2572
01:56:54,130 --> 01:56:59,260
mean what could we do with that

2573
01:56:55,720 --> 01:57:04,060
right so though what could we do with

2574
01:56:59,260 --> 01:57:08,369
that covers things like well what if I'm

2575
01:57:04,060 --> 01:57:08,370
wrong you know what if I'm predicting

2576
01:57:08,819 --> 01:57:15,039
that this image

2577
01:57:11,319 --> 01:57:18,029
is a beagle and I predict jumbo jacked

2578
01:57:15,039 --> 01:57:21,849
you know and you nets model predicts

2579
01:57:18,029 --> 01:57:23,710
Corgi the normal loss function says that

2580
01:57:21,849 --> 01:57:27,639
your net and Jeremy's models are equally

2581
01:57:23,710 --> 01:57:29,469
good ie they're both wrong right but

2582
01:57:27,639 --> 01:57:32,020
what if we could somehow actually say

2583
01:57:29,469 --> 01:57:34,300
though you know what like Corky's closer

2584
01:57:32,020 --> 01:57:37,750
to beagle than it is to jumbo jets so

2585
01:57:34,300 --> 01:57:39,070
units models better than Jeremy's and we

2586
01:57:37,750 --> 01:57:42,639
should be able to do that right because

2587
01:57:39,069 --> 01:57:44,460
in in in in word vector space vehicle

2588
01:57:42,639 --> 01:57:49,150
and Corgi are pretty close together but

2589
01:57:44,460 --> 01:57:51,730
jumbo jet not so much okay so it would

2590
01:57:49,149 --> 01:57:55,000
give us a nice situation where hopefully

2591
01:57:51,729 --> 01:57:57,789
our inferences would be like wrong

2592
01:57:55,000 --> 01:58:00,488
insane aways if they're wrong it would

2593
01:57:57,789 --> 01:58:04,679
also allow us to search for things that

2594
01:58:00,488 --> 01:58:08,289
aren't in our you know an image net

2595
01:58:04,679 --> 01:58:11,949
since set ID you know like a category in

2596
01:58:08,289 --> 01:58:13,510
image net like like dog and cat why did

2597
01:58:11,948 --> 01:58:15,399
I have to train a whole new model to

2598
01:58:13,510 --> 01:58:18,639
find dog vs. cats when we already have

2599
01:58:15,399 --> 01:58:21,250
something that found Corky's and Paddy's

2600
01:58:18,639 --> 01:58:24,609
right why can't I just say find me dogs

2601
01:58:21,250 --> 01:58:26,560
well if I had trained it in in word

2602
01:58:24,609 --> 01:58:28,509
vector space I totally could right

2603
01:58:26,560 --> 01:58:30,610
because like that there there's our word

2604
01:58:28,510 --> 01:58:35,409
vector I can find things with the right

2605
01:58:30,609 --> 01:58:36,819
image vector and so forth so we'll look

2606
01:58:35,408 --> 01:58:38,529
at some cool things we can do with it in

2607
01:58:36,819 --> 01:58:42,988
a moment but first of all let's train a

2608
01:58:38,529 --> 01:58:46,779
model where this model is not learning a

2609
01:58:42,988 --> 01:58:49,448
category a one hotted coded ID where

2610
01:58:46,779 --> 01:58:52,179
every category is equally far from every

2611
01:58:49,448 --> 01:58:56,319
other category let's instead trainer

2612
01:58:52,179 --> 01:58:59,710
model where we're finding the dependent

2613
01:58:56,319 --> 01:59:01,840
variable which is a word vector so what

2614
01:58:59,710 --> 01:59:03,969
word vector well obviously the word

2615
01:59:01,840 --> 01:59:06,520
vector for the word you want right so if

2616
01:59:03,969 --> 01:59:09,819
it's Corgi let's train it to create a

2617
01:59:06,520 --> 01:59:11,560
word vector that's that's the Corgi work

2618
01:59:09,819 --> 01:59:13,210
that don't if it's a jumbo jet let's

2619
01:59:11,560 --> 01:59:15,010
train it with a dependent variable that

2620
01:59:13,210 --> 01:59:18,550
says this is the word vector for a jumbo

2621
01:59:15,010 --> 01:59:19,599
jet okay so as I said it's now

2622
01:59:18,550 --> 01:59:24,090
shockingly easy

2623
01:59:19,599 --> 01:59:26,550
okay so let's grab the fart the fasttech

2624
01:59:24,090 --> 01:59:28,949
word vectors again load the men we only

2625
01:59:26,550 --> 01:59:31,170
need English this time right and so

2626
01:59:28,948 --> 01:59:36,539
here's an example of the word vector for

2627
01:59:31,170 --> 01:59:38,699
King but it's just a 300 numbers so for

2628
01:59:36,539 --> 01:59:41,189
example you know little J Jeremy and big

2629
01:59:38,698 --> 01:59:43,618
J Jeremy have a correlation to point six

2630
01:59:41,189 --> 01:59:46,289
I don't like bananas at all this is good

2631
01:59:43,618 --> 01:59:48,539
banana and Jeremy point one four right

2632
01:59:46,289 --> 01:59:51,060
so like words that you would expect to

2633
01:59:48,539 --> 01:59:52,769
be correlated are correlated in words

2634
01:59:51,060 --> 01:59:54,480
that should be as far away from each

2635
01:59:52,770 --> 01:59:55,830
other as possible unfortunately they're

2636
01:59:54,479 --> 01:59:56,879
still slightly correlated but not so

2637
01:59:55,829 --> 02:00:03,800
much right

2638
01:59:56,880 --> 02:00:06,300
so let's now grab all of the imagenet

2639
02:00:03,800 --> 02:00:09,060
classes because we actually want to know

2640
02:00:06,300 --> 02:00:11,969
you know which one's Corgi and which

2641
02:00:09,060 --> 02:00:13,440
ones jumbo jet so we've got we've got a

2642
02:00:11,969 --> 02:00:17,789
list of all of those up on files doc

2643
02:00:13,439 --> 02:00:20,609
bastard AI we can grab them and that's

2644
02:00:17,789 --> 02:00:23,010
also grab a list of all of the nouns in

2645
02:00:20,609 --> 02:00:26,309
English which I've made available here

2646
02:00:23,010 --> 02:00:29,280
as well okay so here are the names of

2647
02:00:26,310 --> 02:00:31,610
each of the thousand imagenet classes

2648
02:00:29,279 --> 02:00:37,219
and here are all of the nouns in English

2649
02:00:31,609 --> 02:00:39,569
according to work net which is a popular

2650
02:00:37,219 --> 02:00:42,270
thing for kind of representing what

2651
02:00:39,569 --> 02:00:50,880
words are or not so we can now go ahead

2652
02:00:42,270 --> 02:00:54,360
and load that list of nouns and sorry

2653
02:00:50,880 --> 02:00:56,279
load the list of imagenet classes turn

2654
02:00:54,359 --> 02:00:59,848
that into a dictionary so these are the

2655
02:00:56,279 --> 02:01:01,889
class IDs for the 1000 images that are

2656
02:00:59,849 --> 02:01:05,460
in the competition data set they're at a

2657
02:01:01,889 --> 02:01:08,909
thousand okay so here's an example and

2658
02:01:05,460 --> 02:01:12,989
0-100 Allah is attentively is a kind of

2659
02:01:08,908 --> 02:01:15,420
fish let's do the same thing for all

2660
02:01:12,988 --> 02:01:17,549
those word net nouns and you can see

2661
02:01:15,420 --> 02:01:21,449
actually it turns out that image net is

2662
02:01:17,550 --> 02:01:24,020
using word net class names so that makes

2663
02:01:21,448 --> 02:01:28,529
it nice and easy to map between the two

2664
02:01:24,020 --> 02:01:30,270
and word net you know most basic thing

2665
02:01:28,529 --> 02:01:32,579
is an entity and then that if it's an

2666
02:01:30,270 --> 02:01:35,340
abstraction and a physical entity could

2667
02:01:32,579 --> 02:01:37,019
be an object and so forth right so these

2668
02:01:35,340 --> 02:01:37,869
are our two worlds we've got the image

2669
02:01:37,020 --> 02:01:41,399
net thousand

2670
02:01:37,868 --> 02:01:44,438
and we got the 80 mm which are in

2671
02:01:41,399 --> 02:01:46,030
wordnet so we want to map the two

2672
02:01:44,439 --> 02:01:47,619
together and which is as simple as

2673
02:01:46,029 --> 02:01:50,078
creating a couple of dictionaries to map

2674
02:01:47,618 --> 02:01:53,228
them based on the on the scene set ID or

2675
02:01:50,078 --> 02:01:58,918
the web net ID and it turns out that 49

2676
02:01:53,229 --> 02:01:58,918
thousand four hundred and sixty nine

2677
02:02:00,059 --> 02:02:18,399
let's see since set - oh okay so what I

2678
02:02:13,988 --> 02:02:21,098
need to do now is grab the 80 mm nouns

2679
02:02:18,399 --> 02:02:24,159
in word net and try and look them up in

2680
02:02:21,099 --> 02:02:27,340
fast text okay and so I've managed to

2681
02:02:24,158 --> 02:02:29,078
look up 49 thousand of them in fast text

2682
02:02:27,340 --> 02:02:32,110
all right so I've now got a dictionary

2683
02:02:29,078 --> 02:02:35,349
that goes from sin set ID which is what

2684
02:02:32,109 --> 02:02:37,748
wordnet calls them to word vectors okay

2685
02:02:35,349 --> 02:02:42,489
so that's what this dictionary yes sin -

2686
02:02:37,748 --> 02:02:47,429
sin set to work vector and I've also got

2687
02:02:42,488 --> 02:02:51,698
the same thing specifically for the 1000

2688
02:02:47,429 --> 02:02:57,219
word net classes so save them away

2689
02:02:51,698 --> 02:02:59,348
that's fine now I grab all of the image

2690
02:02:57,219 --> 02:03:02,019
net which you can actually download from

2691
02:02:59,349 --> 02:03:04,418
cable now if you look at the cackle

2692
02:03:02,019 --> 02:03:06,458
image net localization competition that

2693
02:03:04,418 --> 02:03:10,029
contains the entirety of the image net

2694
02:03:06,458 --> 02:03:15,188
classifications as well it's got a

2695
02:03:10,029 --> 02:03:20,288
validation set of 28,650 items in it and

2696
02:03:15,189 --> 02:03:22,899
so i can basically just grab for every

2697
02:03:20,288 --> 02:03:26,578
image in image net I can grab using that

2698
02:03:22,899 --> 02:03:29,860
sin set to work vector grab it's its

2699
02:03:26,578 --> 02:03:33,359
word net sorry it's a fast text word

2700
02:03:29,859 --> 02:03:37,658
vector and I can now stick that into

2701
02:03:33,359 --> 02:03:42,339
this image vectors array stack that all

2702
02:03:37,658 --> 02:03:44,918
up into a single matrix and save that

2703
02:03:42,340 --> 02:03:49,059
away and so now what I've got is

2704
02:03:44,918 --> 02:03:51,179
something for every image net image

2705
02:03:49,059 --> 02:03:53,998
they've also got the

2706
02:03:51,179 --> 02:03:56,248
fast text word vector that it's

2707
02:03:53,998 --> 02:03:59,880
associated with like just by looking up

2708
02:03:56,248 --> 02:04:02,880
you know the the sin set ID going to

2709
02:03:59,880 --> 02:04:05,969
word net then going to first text and

2710
02:04:02,880 --> 02:04:10,889
grabbing though the the word vector okay

2711
02:04:05,969 --> 02:04:13,529
and so here's a cool trick I can now

2712
02:04:10,889 --> 02:04:15,328
create a model data object which is

2713
02:04:13,529 --> 02:04:18,779
specifically it's an image classifier

2714
02:04:15,328 --> 02:04:20,188
data object and I've got this in court

2715
02:04:18,779 --> 02:04:22,170
from names an array I'm not sure if

2716
02:04:20,189 --> 02:04:24,659
we've used it before but we can pass it

2717
02:04:22,170 --> 02:04:28,498
a list of file names and so these are

2718
02:04:24,658 --> 02:04:31,618
all of the file names in an image net

2719
02:04:28,498 --> 02:04:33,658
and we can just pass it an array of our

2720
02:04:31,618 --> 02:04:37,828
dependent variables and so this is all

2721
02:04:33,658 --> 02:04:39,629
of the fast text word vectors right and

2722
02:04:37,828 --> 02:04:43,288
then I can pass in the validation

2723
02:04:39,630 --> 02:04:45,269
indexes which in this case is just all

2724
02:04:43,288 --> 02:04:47,518
of the last IDs I need to make sure that

2725
02:04:45,269 --> 02:04:50,280
they're the same as image net users

2726
02:04:47,519 --> 02:04:53,248
otherwise I'll be cheating okay and then

2727
02:04:50,279 --> 02:04:55,559
I pass in continuous equals true which

2728
02:04:53,248 --> 02:04:57,359
means this puts a lie again to this

2729
02:04:55,559 --> 02:04:59,639
image classifier data is now really an

2730
02:04:57,359 --> 02:05:02,248
image regressive data so continuous

2731
02:04:59,639 --> 02:05:04,828
equals true means don't one-hot encode

2732
02:05:02,248 --> 02:05:07,380
my outputs but treat them just as

2733
02:05:04,828 --> 02:05:10,259
continuous values so now I've got a

2734
02:05:07,380 --> 02:05:12,800
model data object that contains all of

2735
02:05:10,260 --> 02:05:16,079
my file names and for every file name a

2736
02:05:12,800 --> 02:05:18,900
continuous array representing the word

2737
02:05:16,078 --> 02:05:21,509
vector for that so I have an X I have a

2738
02:05:18,899 --> 02:05:23,698
Y so I have data now I need an

2739
02:05:21,510 --> 02:05:26,458
architecture and the last function that

2740
02:05:23,698 --> 02:05:30,328
once I've got that I should be done so

2741
02:05:26,458 --> 02:05:32,729
let's create an architecture and so we

2742
02:05:30,328 --> 02:05:34,649
can roll revise this next week but

2743
02:05:32,729 --> 02:05:36,659
basically we can use the tricks we've

2744
02:05:34,649 --> 02:05:39,299
learnt so far but it's actually

2745
02:05:36,658 --> 02:05:43,708
incredibly simple fast AI has a ComNet

2746
02:05:39,300 --> 02:05:46,559
builder which is what when you say you

2747
02:05:43,708 --> 02:05:49,498
know come flow no dot pre-trained it

2748
02:05:46,559 --> 02:05:51,208
calls this and you basically say okay

2749
02:05:49,498 --> 02:05:55,228
what architecture do you want so we're

2750
02:05:51,208 --> 02:05:56,788
going to use ResNet 50 how many classes

2751
02:05:55,229 --> 02:05:58,979
do you want in this case it's not really

2752
02:05:56,788 --> 02:06:01,259
classes it's how many outputs do you

2753
02:05:58,979 --> 02:06:04,610
want which is the length of the fast

2754
02:06:01,260 --> 02:06:05,600
text word vector that's 300

2755
02:06:04,609 --> 02:06:07,399
obviously it's not model class

2756
02:06:05,600 --> 02:06:07,789
classification it's not classification

2757
02:06:07,399 --> 02:06:09,859
at all

2758
02:06:07,789 --> 02:06:14,079
is it regression yes it is regression

2759
02:06:09,859 --> 02:06:16,579
okay and then you can just say all right

2760
02:06:14,079 --> 02:06:18,198
what fully connected layers do you want

2761
02:06:16,579 --> 02:06:20,269
so I'm just going to add one fully

2762
02:06:18,198 --> 02:06:22,219
connected layer hidden layer of length a

2763
02:06:20,270 --> 02:06:25,580
thousand and twenty four why a thousand

2764
02:06:22,219 --> 02:06:30,289
and twenty four well I've got the the

2765
02:06:25,579 --> 02:06:32,359
last layer of resin 850 is I think it's

2766
02:06:30,289 --> 02:06:34,779
a thousand twenty four long the final

2767
02:06:32,359 --> 02:06:37,009
output I need is three hundred long I

2768
02:06:34,779 --> 02:06:38,658
obviously need my penultimate layer to

2769
02:06:37,010 --> 02:06:40,639
be longer than three hundred otherwise

2770
02:06:38,658 --> 02:06:42,769
it's not enough information so I kind of

2771
02:06:40,639 --> 02:06:44,779
just picked something a bit bigger maybe

2772
02:06:42,770 --> 02:06:46,580
different numbers would be better but

2773
02:06:44,779 --> 02:06:48,679
this worked for me

2774
02:06:46,579 --> 02:06:50,029
how much dropout do you want I found

2775
02:06:48,679 --> 02:06:52,520
that the default dropout I was

2776
02:06:50,029 --> 02:06:54,729
consistently under fitting so I just

2777
02:06:52,520 --> 02:06:58,610
decreased the dropout from 0.5 to 0.2

2778
02:06:54,729 --> 02:07:02,089
and so this is now a convolutional

2779
02:06:58,609 --> 02:07:03,469
neural network that does does not have

2780
02:07:02,090 --> 02:07:04,850
any softmax or anything like that

2781
02:07:03,469 --> 02:07:09,590
because it's regression it's just a

2782
02:07:04,850 --> 02:07:13,750
linear layer at the end and yeah that's

2783
02:07:09,590 --> 02:07:16,579
basically it that that's that's my model

2784
02:07:13,750 --> 02:07:19,488
so I can create a common floater from

2785
02:07:16,579 --> 02:07:22,868
that model give it an optimization

2786
02:07:19,488 --> 02:07:25,609
function so now all I need I've got data

2787
02:07:22,868 --> 02:07:27,319
I've got an architecture right so the

2788
02:07:25,609 --> 02:07:30,529
architecture because I said I've got

2789
02:07:27,319 --> 02:07:31,729
this many three hundred outputs it knows

2790
02:07:30,529 --> 02:07:33,948
that there are three hundred outputs

2791
02:07:31,729 --> 02:07:37,669
because that's the size of this array

2792
02:07:33,948 --> 02:07:40,609
right so now all I need is a loss

2793
02:07:37,670 --> 02:07:43,069
function now the default loss function

2794
02:07:40,609 --> 02:07:46,819
for regression is l1 loss so the

2795
02:07:43,069 --> 02:07:51,139
absolute differences that's not bad

2796
02:07:46,819 --> 02:07:54,590
right but unfortunately in really high

2797
02:07:51,139 --> 02:07:56,060
dimensional spaces anybody whose could

2798
02:07:54,590 --> 02:07:57,350
have studied the bit of machine learning

2799
02:07:56,060 --> 02:07:59,060
probably knows this in really high

2800
02:07:57,350 --> 02:08:01,100
dimensional spaces in this case it's

2801
02:07:59,060 --> 02:08:03,800
three hundred dimensional and basically

2802
02:08:01,100 --> 02:08:05,260
everything is on the outside okay and

2803
02:08:03,800 --> 02:08:09,469
when everything's on the outside

2804
02:08:05,260 --> 02:08:12,770
distance is it's not meaningless but

2805
02:08:09,469 --> 02:08:15,289
it's it's a little bit awkward like

2806
02:08:12,770 --> 02:08:18,440
things you know things can things tend

2807
02:08:15,289 --> 02:08:20,060
to be close together or fire

2808
02:08:18,439 --> 02:08:21,589
doesn't really mean much in these really

2809
02:08:20,060 --> 02:08:24,920
high dimensional spaces but everything's

2810
02:08:21,590 --> 02:08:27,380
on the edge right what does mean

2811
02:08:24,920 --> 02:08:29,569
something though is that if one things

2812
02:08:27,380 --> 02:08:32,109
on the edge over here and one things on

2813
02:08:29,569 --> 02:08:34,939
the edge over here you can form an angle

2814
02:08:32,109 --> 02:08:38,149
between those vectors and the angle is

2815
02:08:34,939 --> 02:08:41,449
meaningful right and so that's why we

2816
02:08:38,149 --> 02:08:43,759
use a cosine similarity when we're

2817
02:08:41,449 --> 02:08:46,220
basically looking for like how close or

2818
02:08:43,760 --> 02:08:48,199
far apart are things in high dimensional

2819
02:08:46,220 --> 02:08:50,300
spaces right and if you haven't seen

2820
02:08:48,199 --> 02:08:52,039
cosine similarity before it's basically

2821
02:08:50,300 --> 02:08:56,289
the same as you're fitting in distance

2822
02:08:52,039 --> 02:08:59,300
but it's normalized to be basically a

2823
02:08:56,289 --> 02:09:01,579
unit norm that's so it basically divided

2824
02:08:59,300 --> 02:09:03,350
by the length so we don't care about the

2825
02:09:01,579 --> 02:09:06,019
length of the vector we only care about

2826
02:09:03,350 --> 02:09:09,530
its angle okay so there's a there's a

2827
02:09:06,020 --> 02:09:11,210
bunch of like stuff that you could

2828
02:09:09,529 --> 02:09:12,979
easily learn in a couple of hours but

2829
02:09:11,210 --> 02:09:15,670
but if you haven't seen it before it's a

2830
02:09:12,979 --> 02:09:17,839
bit mysterious for now just know that

2831
02:09:15,670 --> 02:09:19,899
loss functions in high dimensional

2832
02:09:17,840 --> 02:09:23,270
spaces where you're trying to find

2833
02:09:19,899 --> 02:09:26,089
similarity you you care about angle and

2834
02:09:23,270 --> 02:09:28,070
you don't care about distance okay if

2835
02:09:26,090 --> 02:09:30,380
you didn't use this custom loss function

2836
02:09:28,069 --> 02:09:33,500
it would still work I tried it it's just

2837
02:09:30,380 --> 02:09:36,230
a little bit less good okay so we've got

2838
02:09:33,500 --> 02:09:37,869
an architecture we've got data we've got

2839
02:09:36,229 --> 02:09:39,049
a loss function therefore we're done

2840
02:09:37,869 --> 02:09:41,869
okay

2841
02:09:39,050 --> 02:09:44,510
so we can go ahead and fit now I'm

2842
02:09:41,869 --> 02:09:46,909
training on all of imagenet right that's

2843
02:09:44,510 --> 02:09:48,739
going to take a long time so pre-compute

2844
02:09:46,909 --> 02:09:50,420
equals true as your friend okay you

2845
02:09:48,739 --> 02:09:52,159
remember precompute equals true that's

2846
02:09:50,420 --> 02:09:53,989
that thing we learnt ages ago that

2847
02:09:52,159 --> 02:09:56,710
caches the output with the final

2848
02:09:53,989 --> 02:10:00,319
convolutional layer that and just trains

2849
02:09:56,710 --> 02:10:02,539
the fully connected bit yeah and like

2850
02:10:00,319 --> 02:10:05,599
even with pre compute equals true it

2851
02:10:02,539 --> 02:10:09,560
takes like three minutes to train an

2852
02:10:05,600 --> 02:10:11,329
epoch on all of imagenet so I trained it

2853
02:10:09,560 --> 02:10:12,950
for a while I trained it for a while

2854
02:10:11,329 --> 02:10:14,779
longer so it's like an hour's worth of

2855
02:10:12,949 --> 02:10:17,989
training right but it's pretty cool that

2856
02:10:14,779 --> 02:10:20,179
you know with fast AI we can train you

2857
02:10:17,989 --> 02:10:23,179
know a new custom head basically on all

2858
02:10:20,180 --> 02:10:27,020
of imagenet for 48 bucks you know in an

2859
02:10:23,180 --> 02:10:31,260
arrow so okay and so at the end of all

2860
02:10:27,020 --> 02:10:36,540
that we can now say all right

2861
02:10:31,260 --> 02:10:38,570
grab the 1000 images all right and let's

2862
02:10:36,539 --> 02:10:42,449
predict on our whole validation set

2863
02:10:38,569 --> 02:10:44,369
right and let's just take a look at a

2864
02:10:42,449 --> 02:10:46,769
few pictures okay so here's a look at

2865
02:10:44,369 --> 02:10:48,449
you know a few pictures and because the

2866
02:10:46,770 --> 02:10:50,460
validation set is ordered you know

2867
02:10:48,449 --> 02:10:53,010
they're all all the stuff is the same

2868
02:10:50,460 --> 02:10:56,640
type as in the same place I don't know

2869
02:10:53,010 --> 02:10:59,369
what this thing is and what we can now

2870
02:10:56,640 --> 02:11:01,470
do is we can now use nearest neighbors

2871
02:10:59,369 --> 02:11:03,840
search all right so nearest neighbors

2872
02:11:01,470 --> 02:11:06,360
search means you know here's one 300

2873
02:11:03,840 --> 02:11:07,920
dimensional vector here's a whole lot of

2874
02:11:06,359 --> 02:11:10,769
other three-dimensional vectors which

2875
02:11:07,920 --> 02:11:12,000
things is it closest to Wow and normally

2876
02:11:10,770 --> 02:11:13,140
that takes a very long time because you

2877
02:11:12,000 --> 02:11:15,119
have to look through every 300

2878
02:11:13,140 --> 02:11:18,360
dimensional vector caplets at distance

2879
02:11:15,119 --> 02:11:20,880
and find out how far away it is okay but

2880
02:11:18,359 --> 02:11:24,630
there's an amazing almost unknown

2881
02:11:20,880 --> 02:11:27,060
library quote NMS Lib that that does

2882
02:11:24,630 --> 02:11:29,520
that incredibly fast like almost

2883
02:11:27,060 --> 02:11:30,840
nobody's heard of it some of you may

2884
02:11:29,520 --> 02:11:33,240
have tried other nearest neighbors

2885
02:11:30,840 --> 02:11:35,400
libraries I guarantee this is faster

2886
02:11:33,239 --> 02:11:36,840
than what you're using I can tell you

2887
02:11:35,399 --> 02:11:39,689
that because it's been benched much like

2888
02:11:36,840 --> 02:11:42,659
by people who do this stuff for a living

2889
02:11:39,689 --> 02:11:45,149
this is by far the fastest on every

2890
02:11:42,659 --> 02:11:47,340
possible dimension right so this is

2891
02:11:45,149 --> 02:11:49,469
basically a super fast way we basically

2892
02:11:47,340 --> 02:11:51,810
look here this is angular distance right

2893
02:11:49,470 --> 02:11:54,180
so we want to create an index on angular

2894
02:11:51,810 --> 02:11:57,570
distance and we're going to do it on all

2895
02:11:54,180 --> 02:11:59,520
of our imagenet word vectors right

2896
02:11:57,569 --> 02:12:02,009
adding a whole batch create the index

2897
02:11:59,520 --> 02:12:03,660
and now I can query a bunch of vectors

2898
02:12:02,010 --> 02:12:06,300
all at once get there ten nearest

2899
02:12:03,659 --> 02:12:07,829
neighbors users Bodi threading it's it's

2900
02:12:06,300 --> 02:12:09,900
absolutely fantastic

2901
02:12:07,829 --> 02:12:12,630
this library okay you can install it

2902
02:12:09,899 --> 02:12:14,789
from pip it just works

2903
02:12:12,630 --> 02:12:17,670
and it tells you how far away they are

2904
02:12:14,789 --> 02:12:20,159
and their indexes right and so we can

2905
02:12:17,670 --> 02:12:23,489
now go through and print out the top

2906
02:12:20,159 --> 02:12:26,970
three so it turns out that bird actually

2907
02:12:23,489 --> 02:12:28,909
is a limpkin okay so here are there this

2908
02:12:26,970 --> 02:12:31,560
is the top three for each one

2909
02:12:28,909 --> 02:12:33,059
interestingly this one doesn't say it's

2910
02:12:31,560 --> 02:12:35,730
a limpkin and I looked it up it's the

2911
02:12:33,060 --> 02:12:38,160
fourth one I don't know much about birds

2912
02:12:35,729 --> 02:12:41,909
but like everything else here is brown

2913
02:12:38,159 --> 02:12:43,680
with white spots that's not so I don't

2914
02:12:41,909 --> 02:12:45,389
know if that's actually a limb tune or

2915
02:12:43,680 --> 02:12:47,440
if there's the mislabel but I

2916
02:12:45,390 --> 02:12:50,200
sure as hell doesn't look like the other

2917
02:12:47,439 --> 02:12:54,250
birds so you know I thought that was

2918
02:12:50,199 --> 02:12:55,300
pretty interesting that yeah it's kind

2919
02:12:54,250 --> 02:12:57,579
of saying like I don't think it's that

2920
02:12:55,300 --> 02:12:59,079
now this is not a particularly hard

2921
02:12:57,579 --> 02:13:00,789
thing to do because it's only a thousand

2922
02:12:59,079 --> 02:13:03,430
imagenet classes it is not doing

2923
02:13:00,789 --> 02:13:06,460
anything new right but what if we now

2924
02:13:03,430 --> 02:13:08,260
bring in the entirety of wordnet and we

2925
02:13:06,460 --> 02:13:11,920
now say which of those forty-five

2926
02:13:08,260 --> 02:13:14,770
thousand things as a closest to exactly

2927
02:13:11,920 --> 02:13:17,859
the same right so it's now searching all

2928
02:13:14,770 --> 02:13:19,720
of wordnet right so now like let's do

2929
02:13:17,859 --> 02:13:21,880
something a bit different which is take

2930
02:13:19,720 --> 02:13:23,710
all of our predictions right so

2931
02:13:21,880 --> 02:13:30,130
basically take our whole validation set

2932
02:13:23,710 --> 02:13:33,460
of images and create a KNN index of the

2933
02:13:30,130 --> 02:13:35,079
image representations because remember

2934
02:13:33,460 --> 02:13:41,829
it's predicting things that are meant to

2935
02:13:35,079 --> 02:13:45,130
be word vectors and now let's grab the

2936
02:13:41,829 --> 02:13:49,960
fast text vector for boat and boat is

2937
02:13:45,130 --> 02:13:53,609
not an image net concept right and yet I

2938
02:13:49,960 --> 02:13:56,020
can now find all of the images in my

2939
02:13:53,609 --> 02:13:57,729
predicted word vectors in my validation

2940
02:13:56,020 --> 02:14:00,670
set that are closest to the word boat

2941
02:13:57,729 --> 02:14:04,389
and it works even though though it's not

2942
02:14:00,670 --> 02:14:06,789
something that was ever trained on what

2943
02:14:04,390 --> 02:14:10,329
if we now take engine's vector and boats

2944
02:14:06,789 --> 02:14:11,829
vector and take their average and what

2945
02:14:10,329 --> 02:14:14,380
if we now look in our nearest neighbors

2946
02:14:11,829 --> 02:14:17,680
for that these are boats with engines I

2947
02:14:14,380 --> 02:14:19,420
mean yes this is this is actually a boat

2948
02:14:17,680 --> 02:14:21,789
with an engine it just happens to have

2949
02:14:19,420 --> 02:14:24,340
wings on as well right

2950
02:14:21,789 --> 02:14:27,069
by the way sail is not an image net

2951
02:14:24,340 --> 02:14:28,840
thing boat is not an image net thing

2952
02:14:27,069 --> 02:14:31,630
here's the average of two things that

2953
02:14:28,840 --> 02:14:35,130
are not image net things and yet with

2954
02:14:31,630 --> 02:14:37,810
one exception it's bound me to sailboats

2955
02:14:35,130 --> 02:14:40,300
well okay let's do something else crazy

2956
02:14:37,810 --> 02:14:43,900
let's open up an image in the validation

2957
02:14:40,300 --> 02:14:45,750
set here it is hey I don't know what it

2958
02:14:43,899 --> 02:14:48,369
is

2959
02:14:45,750 --> 02:14:51,250
let's call predict array on that image

2960
02:14:48,369 --> 02:14:54,189
to get you know it's kind of like word

2961
02:14:51,250 --> 02:14:55,720
victor like thing and let's do a nearest

2962
02:14:54,189 --> 02:14:58,569
neighbors search on all the other images

2963
02:14:55,720 --> 02:14:59,060
and here's all the other images of

2964
02:14:58,569 --> 02:15:03,279
whatever

2965
02:14:59,060 --> 02:15:06,200
that is that so you can see this is like

2966
02:15:03,279 --> 02:15:08,929
crazy we've trained a thing on all of

2967
02:15:06,199 --> 02:15:10,699
imagenet in an hour using like a custom

2968
02:15:08,930 --> 02:15:13,970
head that required basically like two

2969
02:15:10,699 --> 02:15:15,500
lines of code and these things like run

2970
02:15:13,970 --> 02:15:19,250
in like 300 milliseconds to do these

2971
02:15:15,500 --> 02:15:20,960
searches like I I actually taught this

2972
02:15:19,250 --> 02:15:21,500
basic idea last year as well but it was

2973
02:15:20,960 --> 02:15:23,449
in chaos

2974
02:15:21,500 --> 02:15:25,159
and it was just like pages and pages and

2975
02:15:23,449 --> 02:15:26,539
pages of code and everything took a long

2976
02:15:25,159 --> 02:15:28,430
time and it's complicated

2977
02:15:26,539 --> 02:15:29,899
and back then I kind of said yeah I

2978
02:15:28,430 --> 02:15:31,820
can't begin to think all the stuff you

2979
02:15:29,899 --> 02:15:34,309
could do with this as I don't think

2980
02:15:31,819 --> 02:15:36,019
anybody's really thought deeply about

2981
02:15:34,310 --> 02:15:38,690
this yet but I think it's fascinating

2982
02:15:36,020 --> 02:15:41,300
and so go back and read the devise paper

2983
02:15:38,689 --> 02:15:44,329
because like Andrea had a whole bunch of

2984
02:15:41,300 --> 02:15:47,659
other thoughts and now that it's so easy

2985
02:15:44,329 --> 02:15:49,670
to do hopefully people will will dig

2986
02:15:47,659 --> 02:15:52,909
into this now because I think it's crazy

2987
02:15:49,670 --> 02:15:55,619
and amazing all right thanks everybody

2988
02:15:52,909 --> 02:15:59,068
see you next week

2989
02:15:55,619 --> 02:15:59,068
[Applause]

